{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving Convnets to Classify Labeled Depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "import ipywidgets\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imsave\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import outputer\n",
    "import improc\n",
    "import convnet\n",
    "import mutate\n",
    "import convevo\n",
    "import darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For use during development\n",
    "reload (improc)\n",
    "reload (convnet)\n",
    "reload (mutate)\n",
    "reload (convevo)\n",
    "reload (darwin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate Images\n",
    "Image names are sequential, so add every tenth image to the validation set based on filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training, test = improc.enumerate_images(\"captures\")\n",
    "\n",
    "print(\"Training:\", len(training), \"Test:\", len(test))\n",
    "print(training[:2])\n",
    "print(test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "Each image file contains a color image (top half), and an encoded depth image (bottom half)\n",
    "<img src=\"testing/IMG_2114.PNG\">\n",
    "* Note: The image may also contain the orientation data. If so it is encoded in the first two pixels of the depth image. If the first pixel of the depth image is red, the second has the x, y, z, w quaternion components encoded in the r,g,b,a values.\n",
    "\n",
    "The improc module contains functions for splitting the image, decoding the depth back into floating point millimeters, and for filling in gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_image, example_depth, example_attitude = improc.load_image(\"testing/IMG_2114.PNG\")\n",
    "plt.imshow(example_image)\n",
    "print(example_image.shape, example_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_depth)\n",
    "print(example_depth.shape, example_depth.dtype)\n",
    "print(example_attitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_lab = improc.rgb2lab_normalized(example_image)\n",
    "plt.imshow(example_lab[:,:,0], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_lab[:,:,1], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Labels and Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covert depth to classification labels.\n",
    "Want more precision for nearby things, so use progressively expanding buckets for labels, so if smallest bucket has size s and each succesive bucket is larger by a factor F then:\n",
    "\n",
    "improc.MAX_DEPTH == sF<sup>0</sup> + sF<sup>1</sup> + sF<sup>2</sup> + ... + sF<sup>label count - 1</sup>\n",
    "\n",
    "So, plug into sum of geometric series formula:\n",
    "\n",
    "improc.MAX_DEPTH == s * (1 - F<sup>label count</sup>) / (1 - F)\n",
    "\n",
    "Since there are two unknowns we can choose either the factor or the bucket size. A factor of 1.3 resulted in buckets that seemed about right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def size_for_factor(factor, buckets):\n",
    "    return improc.MAX_DEPTH * (1 - factor) / (1 - factor ** buckets)\n",
    "\n",
    "def depth_label_boundaries(factor, buckets):\n",
    "    boundaries = []\n",
    "    size_sum = 0\n",
    "    bucket_size = size_for_factor(factor, buckets)\n",
    "    for i in range(buckets):\n",
    "        size_sum += bucket_size\n",
    "        boundaries.append(size_sum)\n",
    "        bucket_size *= factor\n",
    "    return boundaries\n",
    "\n",
    "def boundary_midpoints(boundaries):\n",
    "    midpoints = np.zeros(shape=[len(boundaries)], dtype=np.float32)\n",
    "    depth = 0\n",
    "    prev_boundary = 0\n",
    "    for i, boundary in enumerate(DEPTH_BOUNDARIES):\n",
    "        midpoints[i] = (boundary + prev_boundary) / 2\n",
    "        prev_boundary = boundary\n",
    "    return midpoints\n",
    "\n",
    "DEPTH_LABEL_COUNT = 40\n",
    "DEPTH_BUCKET_SCALE_FACTOR = 1.2\n",
    "DEPTH_BOUNDARIES = depth_label_boundaries(DEPTH_BUCKET_SCALE_FACTOR, DEPTH_LABEL_COUNT)\n",
    "DEPTH_BOUNDARY_MIDPOINTS = boundary_midpoints(DEPTH_BOUNDARIES)\n",
    "\n",
    "def depth_label_index(depth):\n",
    "    for i, boundary in enumerate(DEPTH_BOUNDARIES):\n",
    "        if depth < boundary:\n",
    "            return i\n",
    "    return DEPTH_LABEL_COUNT - 1\n",
    "\n",
    "def depth_label(depth, labels=None):\n",
    "    if labels is None:\n",
    "        labels = np.zeros(shape=(DEPTH_LABEL_COUNT + 1), dtype=np.float32)\n",
    "    labels[depth_label_index(depth)] = 1\n",
    "    labels[DEPTH_LABEL_COUNT] = depth / improc.MAX_DEPTH\n",
    "    return labels\n",
    "\n",
    "def depth_for_label(labels):\n",
    "    depth = 0\n",
    "    prev_boundary = 0\n",
    "    for label, boundary in zip(labels, DEPTH_BOUNDARIES):\n",
    "        boundary_midpoint = (boundary + prev_boundary) / 2\n",
    "        depth += boundary_midpoint * label\n",
    "        prev_boundary = boundary\n",
    "    return depth\n",
    "\n",
    "def depth_for_label_normalized(labels):\n",
    "    return depth_for_label(labels) / improc.MAX_DEPTH\n",
    "\n",
    "def depths_for_labels(labels):\n",
    "    return labels * DEPTH_BOUNDARY_MIDPOINTS\n",
    "\n",
    "def depths_for_labels_normalized(labels):\n",
    "    return depths_for_labels(labels) / improc.MAX_DEPTH\n",
    "\n",
    "def depth_label_image(depths):\n",
    "    labeled = depths.copy()\n",
    "    for y in xrange(depths.shape[0]):\n",
    "        for x in xrange(depths.shape[1]):\n",
    "            labeled[y,x] = depth_label_index(depths[y,x])\n",
    "    return labeled\n",
    "\n",
    "# Precomputed via improc.compute_mean_depth(training)\n",
    "# Actually it should 1680.24, value below is actually the mean of the image means.\n",
    "# Keeping this value as it was what was used in the experiments to date,\n",
    "# and it is close to the correct value.\n",
    "MEAN_DEPTH = np.float32(1688.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(DEPTH_BOUNDARIES[:5])\n",
    "print(\"Mean depth label:\", depth_label(MEAN_DEPTH), np.argmax(depth_label(MEAN_DEPTH)))\n",
    "print(\"Zero depth label:\", depth_label(0)[0], depth_label(0)[-1])\n",
    "print(\"Max depth label:\", depth_label(improc.MAX_DEPTH)[-2:])\n",
    "roundtrip_mean = depth_for_label(depth_label(MEAN_DEPTH))\n",
    "print(\"Roundtrip mean depth:\", roundtrip_mean, np.argmax(depth_label(roundtrip_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up cache directory.\n",
    "depth_image_cache_path = outputer.setup_directory(\"temp\", \"cache\")\n",
    "\n",
    "def linear_order(height_span, width_span):\n",
    "    pixel_indices = []\n",
    "    for y in range(height_span):\n",
    "        for x in range(width_span):\n",
    "            pixel_indices.append((y, x))\n",
    "    return pixel_indices\n",
    "\n",
    "class ImageSampler(object):\n",
    "    \"\"\"Wrap an image for sampling.\"\"\"\n",
    "    def __init__(self, image_file,\n",
    "                 sample_height, sample_width,\n",
    "                 half_valid_check=2, tolerance=0):\n",
    "        # Process the image or grab it from the cache.\n",
    "        # image is normalized CIELAB, depth is not normalized.\n",
    "        self.image, self.depth = improc.process_cached(depth_image_cache_path, image_file)\n",
    "        self.index = 0\n",
    "        self.pixel_index = (0, 0)\n",
    "        self.sample_height = sample_height\n",
    "        self.sample_width = sample_width\n",
    "        self.depth_offset_y = (sample_height + 1) / 2\n",
    "        self.depth_offset_x = (sample_width + 1) / 2\n",
    "        self.height = self.image.shape[0]        \n",
    "        self.width = self.image.shape[1]\n",
    "        self.half_valid_check = half_valid_check\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "    def depth_value(self, y, x):\n",
    "        return self.depth[y + self.depth_offset_y, x + self.depth_offset_x]\n",
    "        \n",
    "    def sample(self, inputs, labels, index):\n",
    "        self.sample_at(self.pixel_index, inputs, labels, index)\n",
    "        self.advance()\n",
    "        \n",
    "    def sample_at(self, pixel, inputs, labels, index):\n",
    "        y, x = pixel\n",
    "        patch = self.image[y : y + self.sample_height, x : x + self.sample_width]\n",
    "        inputs[index] = patch\n",
    "        depth = self.depth_value(y, x)\n",
    "        if np.isnan(depth):\n",
    "            return False\n",
    "        depth_label(depth, labels[index])\n",
    "        return True\n",
    "    \n",
    "    def setup_sample_order(self, sample_orders, entropy):\n",
    "        height_span = self.height - self.sample_height\n",
    "        width_span = self.width - self.sample_width\n",
    "        cached = sample_orders.get((height_span, width_span))\n",
    "        if cached:\n",
    "            return cached\n",
    "\n",
    "        pixel_indices = linear_order(height_span, width_span)\n",
    "        mutate.fisher_yates_shuffle(pixel_indices, entropy)\n",
    "        sample_orders[(height_span, width_span)] = pixel_indices\n",
    "        return pixel_indices\n",
    "        \n",
    "    def advance(self):\n",
    "        self.index += 1\n",
    "    \n",
    "    def next_sample(self, sample_orders, entropy):\n",
    "        c = self.half_valid_check\n",
    "        order = self.setup_sample_order(sample_orders, entropy)\n",
    "        while self.index < len(order):\n",
    "            self.pixel_index = order[self.index]\n",
    "            depth_y = self.pixel_index[0] + self.depth_offset_y\n",
    "            depth_x = self.pixel_index[1] + self.depth_offset_x\n",
    "            # Check that the sample is from a clean part of the image.\n",
    "            sum = np.sum(np.isnan(self.depth[depth_y - c : depth_y + c,\n",
    "                                             depth_x - c: depth_x + c]))\n",
    "            if sum <= self.tolerance:\n",
    "                return True\n",
    "            self.advance()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BatchSampler(object):\n",
    "    \"\"\"Created sample batches for a set of image files\"\"\"\n",
    "    def __init__(self, image_files, sample_height, sample_width, samplers_count=100):\n",
    "        self.files = image_files\n",
    "        self.samplers_count = samplers_count\n",
    "        self.sample_height = sample_height\n",
    "        self.sample_width = sample_width\n",
    "        self.sample_orders = {}\n",
    "        self.reset()\n",
    "    \n",
    "    # Access or initialize the specified sampler.\n",
    "    def sampler(self, index, entropy):\n",
    "        sampler = self.samplers[index]\n",
    "        if sampler and not sampler.next_sample(self.sample_orders, entropy):\n",
    "            sampler = None\n",
    "\n",
    "        while sampler is None:\n",
    "            path = self.files[self.file_index]\n",
    "            sampler = ImageSampler(path, self.sample_height, self.sample_width)\n",
    "            self.file_index = (self.file_index + 1) % len(self.files)\n",
    "            if not sampler.next_sample(self.sample_orders, entropy):\n",
    "                sampler = None\n",
    "                print (\"No samples in\", path)\n",
    "            else:\n",
    "                self.samplers[index] = sampler\n",
    "        return sampler\n",
    "    \n",
    "    # Get the next single sample.\n",
    "    def sample(self, inputs, labels, index, entropy):\n",
    "        sampler = self.sampler(self.sample_index, entropy)\n",
    "\n",
    "        self.sample_index = (self.sample_index + 1) % len(self.samplers)\n",
    "        sampler.sample(inputs, labels, index)\n",
    "    \n",
    "    # Get the next batch of samples.\n",
    "    def sample_batch(self, inputs, labels, batch_size, entropy):\n",
    "        labels.fill(0)\n",
    "        for b in xrange(batch_size):\n",
    "            self.sample(inputs, labels, b, entropy)\n",
    "            \n",
    "    def reset(self):\n",
    "        self.sample_index = 0\n",
    "        self.file_index = 0\n",
    "        self.samplers = [None] * self.samplers_count\n",
    "    \n",
    "    # Force load all the samplers.\n",
    "    def fill_and_pickle(self, path, entropy):\n",
    "        for i in range(self.samplers_count):\n",
    "            sampler = self.sampler(i, entropy)\n",
    "\n",
    "        try:\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(self, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to', path, ':', e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth label and batching examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(depth_label_image(example_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del example_image\n",
    "del example_depth\n",
    "del example_lab\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 101\n",
    "batcher = BatchSampler([\"testing/IMG_2114.PNG\", \"testing/IMG_3410.PNG\"],\n",
    "                       SAMPLE_SIZE, SAMPLE_SIZE, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "inputs = np.ones(shape=(BATCH_SIZE, SAMPLE_SIZE, SAMPLE_SIZE, improc.COLOR_CHANNELS),\n",
    "                 dtype=np.float32)\n",
    "labels = np.zeros(shape=(BATCH_SIZE, DEPTH_LABEL_COUNT + 1), dtype=np.float32)\n",
    "\n",
    "for _ in xrange(100):\n",
    "    batcher.sample_batch(inputs, labels, BATCH_SIZE, random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(inputs[1,:,:,0], cmap='Greys_r')\n",
    "print(inputs[1].shape)\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"image_size\": (101, 101, improc.COLOR_CHANNELS),\n",
    "    \"depth_labels\": DEPTH_LABEL_COUNT,\n",
    "    \"train_files\": np.array(training),\n",
    "    \"test_files\": np.array(sorted(test))\n",
    "}\n",
    "\n",
    "del training\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_cross_validation(\n",
    "    data,\n",
    "    train_count, valid_count, test_count=None,\n",
    "    label_count=None, entropy=random\n",
    "):\n",
    "    \"\"\"Shuffle the data and split off training, validation and test sets.\"\"\"\n",
    "    cross_data = data.copy()\n",
    "    \n",
    "    if label_count:\n",
    "        cross_data[\"depth_labels\"] = label_count\n",
    "\n",
    "    paths = cross_data[\"train_files\"][:]\n",
    "    mutate.fisher_yates_shuffle(paths, entropy)\n",
    "\n",
    "    cross_data[\"train_files\"] = paths[:train_count]\n",
    "    cross_data[\"valid_files\"] = paths[train_count:train_count + valid_count]\n",
    "\n",
    "    if test_count is not None:\n",
    "        cross_data[\"test_files\"] = data[\"test_files\"][:test_count]\n",
    "\n",
    "    return cross_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batcher Caching\n",
    "The evolutionary process will involve running many graphs with the same data. To make this as efficent as possible, these are used cache and restore the processed batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_batch(data, set_name, samplers, entropy):\n",
    "    path = os.path.join(\"temp\", set_name + \".pickle\")\n",
    "    files = data[set_name + \"_files\"]\n",
    "    image_size = data[\"image_size\"]\n",
    "    batcher = BatchSampler(files, image_size[0], image_size[1], samplers)\n",
    "    batcher.fill_and_pickle(path, entropy)\n",
    "    del batcher\n",
    "    gc.collect()\n",
    "    return path\n",
    "\n",
    "def load_batcher(pickle_batches, set_name):\n",
    "    if pickle_batches:\n",
    "        path = pickle_batches.get(set_name)\n",
    "        if path:\n",
    "            with open(path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_data = setup_cross_validation(\n",
    "    data_files, 0, 100, None,\n",
    "    label_count=DEPTH_LABEL_COUNT, entropy=random.Random(24601)\n",
    ")\n",
    "pickle_size = pickle_data[\"image_size\"]\n",
    "pickle_files = pickle_data[\"valid_files\"]\n",
    "pickle_sampler = BatchSampler(pickle_files,pickle_size[0],pickle_size[1],len(pickle_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_sampler.fill_and_pickle(\"temp/depth_valid.pickle\", random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"temp/depth_valid.pickle\", 'rb') as f:\n",
    "    loaded_sampler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "inputs = np.ones(shape=(BATCH_SIZE, pickle_size[0], pickle_size[1], improc.COLOR_CHANNELS),\n",
    "                 dtype=np.float32)\n",
    "labels = np.zeros(shape=(BATCH_SIZE, DEPTH_LABEL_COUNT + 1), dtype=np.float32)\n",
    "\n",
    "for _ in xrange(500):\n",
    "    loaded_sampler.sample_batch(inputs, labels, BATCH_SIZE, random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del pickle_data\n",
    "del pickle_files\n",
    "del pickle_sampler\n",
    "del loaded_sampler\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_input_shape(batch_size, image_shape):\n",
    "    return (batch_size,) + image_shape\n",
    "\n",
    "def batch_output_shape(batch_size, label_count):\n",
    "    return (batch_size, label_count + 1)\n",
    "\n",
    "def setup_graph(\n",
    "    batch_size,\n",
    "    image_shape,\n",
    "    label_count,\n",
    "    regress_factor,\n",
    "    stack\n",
    "):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        input_shape = batch_input_shape(batch_size, image_shape)\n",
    "        output_shape = batch_output_shape(batch_size, label_count)\n",
    "        train   = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        targets = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        verify  = tf.placeholder(tf.float32, shape=input_shape)\n",
    "\n",
    "        operations = stack.construct(input_shape)\n",
    "        l2_loss = convnet.setup(operations)\n",
    "\n",
    "        result = convnet.connect_model(train, operations, True)[-1]\n",
    "        \n",
    "        depth_label = tf.slice(targets, [0, label_count], [batch_size, 1])\n",
    "        depths      = tf.slice(result, [0, label_count], [batch_size, 1])\n",
    "        labels = tf.slice(targets, [0, 0], [batch_size, label_count])\n",
    "        logits = tf.slice(result, [0, 0], [batch_size, label_count])\n",
    "\n",
    "        loss = l2_loss\n",
    "        if regress_factor >= 0:\n",
    "            loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))\n",
    "        else:\n",
    "            regress_factor = -regress_factor\n",
    "\n",
    "        if regress_factor > 0:\n",
    "            loss += regress_factor * tf.reduce_mean(\n",
    "                tf.squared_difference(depths, depth_label)\n",
    "            )\n",
    "\n",
    "        verify_result = convnet.connect_model(verify,  operations, False)[-1]\n",
    "        verify_logits = tf.slice(verify_result, [0, 0], [batch_size, label_count])\n",
    "        verify_depths = tf.slice(verify_result, [0, label_count], [batch_size, 1])\n",
    "\n",
    "        verify_depths = tf.maximum(verify_depths, 0)\n",
    "        verify_depths = tf.minimum(verify_depths, 1)\n",
    "        \n",
    "        info = {\n",
    "            \"graph\": graph,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"train\": train,\n",
    "            \"targets\": targets,\n",
    "            \"depths\": depths,\n",
    "            \"loss\": loss,\n",
    "            \"optimizer\": stack.construct_optimizer(loss),\n",
    "            \"predictions\": tf.nn.softmax(logits),\n",
    "            \"verify\": verify,\n",
    "            \"verify_predictions\": tf.nn.softmax(verify_logits),\n",
    "            \"verify_depths\": verify_depths,\n",
    "            \"saver\": tf.train.Saver()\n",
    "        }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    correct_predictions = np.argmax(predictions, 1) == np.argmax(labels, 1)\n",
    "    return (100.0 * np.sum(correct_predictions) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_depth_error(depths, labels):\n",
    "    return np.mean(np.absolute(depths[:,0] - labels[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_result(loss, predictions, depths, labels):\n",
    "    return (loss, accuracy(predictions, labels[:,0:-1]), mean_depth_error(depths, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_batch_info(\n",
    "    context, score, predictions, depths, labels, verbose, print_count=20, depth_print=10\n",
    "):\n",
    "    print(context, \"accuracy: %.1f%%\" % score[1])\n",
    "    if verbose:\n",
    "        print(np.argmax(predictions[0:print_count],1))\n",
    "        print(np.argmax(labels[0:print_count,0:-1],1))\n",
    "        print(context, \"average depth error:\", score[2])\n",
    "        print(depths[0:depth_print,0])\n",
    "        print(labels[0:depth_print,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_accuracy(\n",
    "    context, session, graph, batcher, entropy, inputs, labels, batch_size, count, verbose\n",
    "):\n",
    "    total_accuracy = 0\n",
    "    total_depth = 0\n",
    "    for b in xrange(count):\n",
    "        batcher.sample_batch(inputs, labels, batch_size, entropy)\n",
    "        targets = [graph[\"verify_predictions\"], graph[\"verify_depths\"]]\n",
    "        predictions, depths = session.run(targets, feed_dict={graph[\"verify\"] : inputs})\n",
    "        total_accuracy += accuracy(predictions, labels) / float(count)\n",
    "        total_depth += mean_depth_error(depths, labels) / float(count)\n",
    "    \n",
    "    score = (0, total_accuracy, total_depth)\n",
    "    print_batch_info(context, score, predictions, depths, labels, verbose)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_graph(\n",
    "    graph_info,\n",
    "    data,\n",
    "    step_count,\n",
    "    valid_count,\n",
    "    test_count=0,\n",
    "    batch_sampler_count=1000,\n",
    "    report_every=50,\n",
    "    verbose=True,\n",
    "    accuracy_minimum=None, # Minimimum validation percent accuracy for early abort\n",
    "    pickle_batches=None, # pickle files for training and validation batchers\n",
    "    tracker=None,\n",
    "    entropy=random\n",
    "):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "\n",
    "        # Optionally restore graph parameters from disk.\n",
    "        convnet.restore_model(graph_info, session)\n",
    "\n",
    "        # Set up space for graph inputs / feed values\n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        depth_labels = data[\"depth_labels\"]\n",
    "        height, width, _ = data[\"image_size\"]\n",
    "        inputs = np.zeros(shape=batch_input_shape(batch_size, data[\"image_size\"]),\n",
    "                          dtype=np.float32)\n",
    "        labels = np.zeros(shape=batch_output_shape(batch_size, depth_labels),\n",
    "                          dtype=np.float32)\n",
    "\n",
    "        # Construct or unpickle training batcher.\n",
    "        train_batcher = load_batcher(pickle_batches, \"train\")\n",
    "        if not train_batcher:\n",
    "            train_batcher = BatchSampler(\n",
    "                data[\"train_files\"], height, width, batch_sampler_count\n",
    "            )\n",
    "\n",
    "        score = (0,1)\n",
    "\n",
    "        try:\n",
    "            for step in xrange(step_count + 1):\n",
    "                if tracker:\n",
    "                    tracker.update_progress(step)\n",
    "\n",
    "                # Generate a batch\n",
    "                train_batcher.sample_batch(inputs, labels, batch_size, entropy)\n",
    "                \n",
    "                # Graph targets\n",
    "                run_targets = [\n",
    "                    graph_info[\"optimizer\"],\n",
    "                    graph_info[\"loss\"],\n",
    "                    graph_info[\"predictions\"],\n",
    "                    graph_info[\"depths\"]\n",
    "                ]\n",
    "                \n",
    "                # Graph inputs:\n",
    "                feed_dict = {graph_info[\"train\"] : inputs, graph_info[\"targets\"] : labels}\n",
    "                _, loss, predictions, depths = session.run(run_targets,feed_dict=feed_dict)\n",
    "                \n",
    "                # Keep track of and possibly display score.\n",
    "                batch_score = score_result(loss, predictions, depths, labels)\n",
    "                if tracker:\n",
    "                    tracker.record_score(batch_score)\n",
    "\n",
    "                if np.isnan(loss):\n",
    "                    print(\"Error computing loss at step\", step)\n",
    "                    print_batch_info(\"Minibatch\", batch_score, predictions,\n",
    "                                     depths, labels, True)\n",
    "                    return 0\n",
    "                if (step % report_every == 0):\n",
    "                    if verbose:\n",
    "                        print(\"Minibatch loss at step\", step, \":\", loss)\n",
    "                        print_batch_info(\"Minibatch\", batch_score, predictions,\n",
    "                                         depths, labels, True)\n",
    "\n",
    "                    # Evaluate the validation data.\n",
    "                    valid_batcher = load_batcher(pickle_batches, \"valid\")\n",
    "                    if not valid_batcher:\n",
    "                        valid_files = data[\"valid_files\"]\n",
    "                        valid_batcher = BatchSampler(\n",
    "                            valid_files, height, width, len(valid_files)\n",
    "                        )\n",
    "                    valid_score = batch_accuracy(\n",
    "                        \"Validation\", session, graph_info, valid_batcher, entropy,\n",
    "                        inputs, labels, batch_size, valid_count, verbose\n",
    "                    )\n",
    "                    del valid_batcher\n",
    "                    score = valid_score[1:]\n",
    "                    if accuracy_minimum and step > 0 and valid_score[1] < accuracy_minimum:\n",
    "                        print(\"Early out.\")\n",
    "                        break\n",
    "\n",
    "            # Evaluate the test data, if any.\n",
    "            if test_count > 0:\n",
    "                test_batcher = BatchSampler(data[\"test_files\"], height, width)\n",
    "                valid_accuracy = batch_accuracy(\n",
    "                    \"Test\", session, graph_info, test_batcher, entropy,\n",
    "                    inputs, labels, batch_size, test_count, verbose\n",
    "                )\n",
    "\n",
    "            return score\n",
    "        finally:\n",
    "            # Optionally save out graph parameters to disk.\n",
    "            convnet.save_model(graph_info, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_accuracy_metric(valid_accuracy, valid_depth_error, train_results):\n",
    "    return valid_accuracy\n",
    "\n",
    "def valid_error_metric(valid_accuracy, valid_depth_error, train_results):\n",
    "    return valid_depth_error\n",
    "\n",
    "def train_accuracy_metric(valid_accuracy, valid_depth_error, train_results):\n",
    "    result_count = min(len(train_results), 1000)\n",
    "    return sum(accuracy for _, accuracy, _ in train_results[-result_count:]) / result_count\n",
    "\n",
    "def train_depth_error_metric(valid_accuracy, valid_depth_error, train_results):\n",
    "    result_count = min(len(train_results), 1000)\n",
    "    error = sum(error for _, _, error in train_results[-result_count:]) / result_count\n",
    "    return max(0, 1 - error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_path = outputer.setup_directory(\"temp\", \"classy_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_eval(\n",
    "    batch_size=20,\n",
    "    eval_steps=10000,\n",
    "    valid_steps=500,\n",
    "    regress_factor=1.0,\n",
    "    report_every=None,\n",
    "    reuse_cross=False,\n",
    "    metric=valid_accuracy_metric,\n",
    "    entropy=random\n",
    "):\n",
    "    pickle_batches = {}\n",
    "    train_count = 9700\n",
    "    valid_count = 400\n",
    "    batch_sampler_count = min(801, eval_steps * batch_size)\n",
    "    test_count = None\n",
    "    \n",
    "    #if reusing data, set up training and test data, and pickle batchers for efficiency.\n",
    "    if reuse_cross:\n",
    "        redata = setup_cross_validation(\n",
    "            data_files, train_count, valid_count, test_count,\n",
    "            label_count=DEPTH_LABEL_COUNT, entropy=entropy\n",
    "        )\n",
    "        pickle_batches[\"valid\"] = pickle_batch(\n",
    "            redata, \"valid\", len(redata[\"valid_files\"]), entropy\n",
    "        )\n",
    "        print(\"Pickled Validation\")\n",
    "        pickle_batches[\"train\"] = pickle_batch(\n",
    "            redata, \"train\", batch_sampler_count, entropy\n",
    "        )\n",
    "        print(\"Pickled Training\")\n",
    "        \n",
    "    progress_tracker = outputer.ProgressTracker(\n",
    "        [\"Loss\", \"Accuracy\", \"Error\"], eval_steps, results_path, convevo.serialize\n",
    "    )\n",
    "  \n",
    "    def evaluate(stack, eval_entropy):\n",
    "        # If not reusing data, generate training and validation sets\n",
    "        if not reuse_cross:\n",
    "            data = setup_cross_validation(\n",
    "                data_files, train_count, valid_count, test_count,\n",
    "                label_count=DEPTH_LABEL_COUNT, entropy=eval_entropy\n",
    "            )\n",
    "            pickle_batches[\"valid\"] = pickle_batch(\n",
    "                data, \"valid\", len(data[\"valid_files\"]), eval_entropy\n",
    "            )\n",
    "            print(\"Pickled Validation\")\n",
    "        else:\n",
    "            data = redata\n",
    "            \n",
    "        progress_tracker.setup_eval(stack)\n",
    "\n",
    "        # Set up the Tensorflow graph\n",
    "        try:\n",
    "            graph_info = setup_graph(\n",
    "                batch_size,\n",
    "                data[\"image_size\"],\n",
    "                data[\"depth_labels\"],\n",
    "                regress_factor,\n",
    "                stack\n",
    "            )\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            progress_tracker.error(sys.exc_info())\n",
    "            return -10\n",
    "       \n",
    "        progress_tracker.start_eval(graph_info)\n",
    "    \n",
    "        # Run the graph\n",
    "        try:\n",
    "            valid_accuracy, valid_depth_error = run_graph(\n",
    "                graph_info,\n",
    "                data,\n",
    "                eval_steps,\n",
    "                valid_count=valid_steps,\n",
    "                batch_sampler_count=batch_sampler_count,\n",
    "                report_every=report_every if report_every else eval_steps/4,\n",
    "                verbose=True,\n",
    "                accuracy_minimum=None,\n",
    "                pickle_batches=pickle_batches,\n",
    "                tracker=progress_tracker,\n",
    "                entropy=eval_entropy\n",
    "            )\n",
    "            if metric:\n",
    "                return metric(valid_accuracy, valid_depth_error, progress_tracker.results)\n",
    "            return valid_accuracy\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            progress_tracker.error(sys.exc_info())\n",
    "            return -1\n",
    "        finally:\n",
    "            progress_tracker.output()\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of components in isoloation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_data = setup_cross_validation(data_files,9700,400,1000,label_count=DEPTH_LABEL_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "conv_layers = [\n",
    "    (\"conv_bias\", 20, 2, 10, \"SAME\", True),\n",
    "    (\"conv_bias\", 10, 5, 20, \"SAME\", True),\n",
    "    (\"conv_bias\",  5, 2, 40, \"SAME\", True)\n",
    "]\n",
    "hidden_sizes = [400, 100, cross_data[\"depth_labels\"] + 1]\n",
    "optimizer = convevo.Optimizer(\"GradientDescent\", 0.01)\n",
    "optimizer.default_parameters()\n",
    "prototype = convevo.create_stack(conv_layers,[],True,hidden_sizes,0.0, 0.05, 0.0,optimizer)\n",
    "prototype.reseed(random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prototype_graph = setup_graph(\n",
    "    batch_size,\n",
    "    cross_data[\"image_size\"],\n",
    "    cross_data[\"depth_labels\"],\n",
    "    1.0,\n",
    "    prototype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    prototype_graph, cross_data, 1000,\n",
    "    valid_count=200, report_every=500, verbose=True, entropy=random.Random(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(convevo.serialize(prototype))\n",
    "prototype_entropy = random.Random(42)\n",
    "prototype_eval = make_eval(\n",
    "    batch_size=100,\n",
    "    eval_steps=100,\n",
    "    valid_steps=20,\n",
    "    regress_factor=1.0,\n",
    "    reuse_cross=True,\n",
    "    entropy=prototype_entropy\n",
    ")\n",
    "prototype_eval(prototype, prototype_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del cross_data\n",
    "del conv_layers\n",
    "del hidden_sizes\n",
    "del prototype_graph\n",
    "del prototype_eval\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving Convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prototypes = [prototype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population,_,_ = convevo.load_population(\"testing/color_quad_run.xml\", False)\n",
    "prototypes = population[:5]\n",
    "print(len(prototypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prototypes = [\n",
    "    convevo.load_stack(\"testing/candidate1.xml\"),\n",
    "    convevo.load_stack(\"testing/candidate2.xml\"),\n",
    "    convevo.load_stack(\"testing/candidate3.xml\"),\n",
    "    convevo.load_stack(\"testing/candidate4.xml\"),\n",
    "    convevo.load_stack(\"testing/candidate5.xml\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with outputer.TeeOutput(os.path.join(\"temp\", outputer.timestamp(\"Depth_Evolve_\", \"txt\"))):\n",
    "    mutate_seed = random.randint(1, 100000)\n",
    "    print(\"Mutate Seed:\", mutate_seed)\n",
    "    mutate_entropy = random.Random(mutate_seed)\n",
    "    eval_seed = random.randint(1, 100000)\n",
    "    print(\"Eval Seed:\", eval_seed)\n",
    "    eval_entropy = random.Random(eval_seed)\n",
    "\n",
    "    population_size = 10\n",
    "    generations = 5\n",
    "    batch_size = 100\n",
    "\n",
    "    breed_options = {\n",
    "        \"input_shape\": batch_input_shape(batch_size, data_files[\"image_size\"]),\n",
    "        \"output_shape\": batch_output_shape(batch_size, data_files[\"depth_labels\"])\n",
    "    }\n",
    "\n",
    "    for stack in prototypes:\n",
    "        stack.make_safe(breed_options[\"input_shape\"], breed_options[\"output_shape\"])\n",
    "\n",
    "    evaluator = make_eval(\n",
    "        batch_size=batch_size, eval_steps=40000, valid_steps=1000, regress_factor=1.0,\n",
    "        reuse_cross=True, metric=None, entropy=eval_entropy\n",
    "    )\n",
    "    charles = darwin.Darwin(convevo.serialize, evaluator, convevo.breed)\n",
    "    charles.init_population(prototypes, population_size, False,\n",
    "                            breed_options, mutate_entropy)\n",
    "\n",
    "    for g in range(generations):\n",
    "        print(\"Generation\", g)\n",
    "        results = charles.evaluate(eval_entropy)\n",
    "        convevo.output_results(results, \"temp\", outputer.timestamp() + \".xml\",\n",
    "                               mutate_seed, eval_seed)\n",
    "        charles.repopulate(population_size, 0.3, 3, results, breed_options, mutate_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = darwin.descending_score(charles.history.values())\n",
    "convevo.output_results(results, \"testing\", \"candidates_evolve_run.xml\",\n",
    "                       mutate_seed, eval_seed)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Evaluation\n",
    "Do a long training run for the best graph to date. Note: on my GPU accelerated machine, this takes 5 days to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "candidate = convevo.load_stack(\"testing/candidate6.xml\")\n",
    "candidate.make_safe(\n",
    "    batch_input_shape(BATCH_SIZE, data_files[\"image_size\"]),\n",
    "    batch_output_shape(BATCH_SIZE, data_files[\"depth_labels\"])\n",
    ")\n",
    "print(convevo.serialize(candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate_evaluator = make_eval(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    eval_steps=10000000,\n",
    "    valid_steps=100000,\n",
    "    regress_factor=1.0,\n",
    "    report_every=500000,\n",
    "    reuse_cross=False,\n",
    "    metric=None,\n",
    "    entropy=random.Random(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with outputer.TeeOutput(os.path.join(\"temp\", \"candidate6_results.txt\")):\n",
    "    candidate_evaluator(candidate, random.Random(57))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test reloading the resulting graph for additional training/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with outputer.TeeOutput(os.path.join(\"temp\", \"candidate6_retest.txt\")):\n",
    "    candidate = convevo.load_stack(\"testing/candidate6.xml\")\n",
    "    candidate_reevaluator = make_eval(\n",
    "        batch_size=100, eval_steps=10000, valid_steps=10000, regress_factor=1.0,\n",
    "        reuse_cross=False, metric=None, entropy=random.Random(42)\n",
    "    )\n",
    "    candidate.checkpoint_path(\"testing/candidate6/full/2016-06-11~15_23_44_712.ckpt\")\n",
    "    candidate_reevaluator(candidate, random.Random(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Candidate Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates for non-NaN pixels:\n",
    "* accuracy score,\n",
    "* mean depth error for the predicted depth,\n",
    "* mean depth error for the softmax predicted label converted to a depth via:\n",
    "  * sum(midpoint of bucket * softmax value for bucket).\n",
    "* mean depth error for the bucket midpoint corresponding to the argmax of the predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_score(labels, predictions, depths, count):\n",
    "    is_finite = np.isfinite(labels[:count,-1])\n",
    "    where_valid = np.where(is_finite)\n",
    "    count = np.count_nonzero(is_finite)\n",
    "    if count:\n",
    "        score = accuracy(predictions[where_valid], labels[where_valid])\n",
    "        error = mean_depth_error(depths[where_valid], labels[where_valid])\n",
    "        \n",
    "        valid_predictions = predictions[where_valid]\n",
    "        label_depths = np.sum(depths_for_labels_normalized(valid_predictions), axis=1)\n",
    "        label_error = mean_depth_error(label_depths[:,np.newaxis], labels[where_valid])\n",
    "\n",
    "        argmax_predictions = np.argmax(valid_predictions, axis=1)\n",
    "        argmax_depths = DEPTH_BOUNDARY_MIDPOINTS[argmax_predictions] / improc.MAX_DEPTH\n",
    "        argmax_error = mean_depth_error(argmax_depths[:,np.newaxis], labels[where_valid])\n",
    "        \n",
    "        return score*count, error*count, label_error*count, argmax_error*count, count\n",
    "    return 0, 0, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Validate the test_score function.\n",
    "def check_test_score():\n",
    "    test_batch_size = 10\n",
    "    test_labels = np.zeros(shape=batch_output_shape(test_batch_size, DEPTH_LABEL_COUNT),\n",
    "                           dtype=np.float32)\n",
    "    test_depths = np.zeros(shape=(test_batch_size,1), dtype=np.float32)\n",
    "    for l in range(test_batch_size):\n",
    "        test_depth = improc.MAX_DEPTH * l / float(test_batch_size)\n",
    "        depth_label(test_depth, test_labels[l])\n",
    "        test_depths[l, 0] = test_labels[l,-1]\n",
    "\n",
    "    test_predictions = np.copy(test_labels)[:,:-1]\n",
    "    test_predictions[0, 10] = 0.5\n",
    "\n",
    "    test_labels[2] = np.nan\n",
    "\n",
    "    score = test_score(test_labels, test_predictions, test_depths, 7)\n",
    "    print(score)\n",
    "    print([s / score[-1] for s in score[:-1]])\n",
    "check_test_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the test images in the provided data set, compute metrics for full images, and generate the corresponding image for the output depth and either the linear combination of the labeled softmax depth output, or the argmax labeled depth output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_test_images(graph_info, data, output_path):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "\n",
    "        # restore graph parameters from disk.\n",
    "        convnet.restore_model(graph_info, session)\n",
    "        \n",
    "        # Set up space for graph inputs / feed values\n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        depth_labels = data[\"depth_labels\"]\n",
    "        image_size = data[\"image_size\"]\n",
    "        inputs = np.zeros(shape=batch_input_shape(batch_size, image_size),\n",
    "                          dtype=np.float32)\n",
    "        labels = np.zeros(shape=batch_output_shape(batch_size, depth_labels),\n",
    "                          dtype=np.float32)\n",
    "        nan_label = np.array([np.nan]*labels.shape[-1], dtype=np.float32)\n",
    "        \n",
    "        source_image_size = (480, 640)\n",
    "        height_span = source_image_size[0] - image_size[0]\n",
    "        width_span = source_image_size[1] - image_size[1]\n",
    "        pixel_order = np.array(linear_order(height_span, width_span))\n",
    "        \n",
    "        files = data[\"test_files\"]\n",
    "        \n",
    "        eval_count = len(files) * len(pixel_order) / batch_size\n",
    "        progress = outputer.show_progress(\"Evaluation Steps:\", eval_count)\n",
    "        \n",
    "        eval_count = 0;\n",
    "        all_scores = {}\n",
    "\n",
    "        for image_path in files:\n",
    "            sampler = ImageSampler(image_path, image_size[0], image_size[1])\n",
    "            if output_path:\n",
    "                raw_depths = ndimage.imread(image_path)\n",
    "                label_depths = np.copy(raw_depths)\n",
    "                argmax_depths = np.copy(raw_depths)\n",
    "            image_scores = np.zeros(shape=(5,), dtype=np.float32)\n",
    "            gc.collect()\n",
    "            \n",
    "            for column in xrange(width_span):\n",
    "                # Update progress\n",
    "                eval_count += 1\n",
    "                progress.value = eval_count\n",
    "                \n",
    "                # Generate a batch and run the graph\n",
    "                batch_pixels = pixel_order[column * height_span:(column+1) * height_span,:]\n",
    "                labels.fill(0)\n",
    "                for i, pixel in enumerate(batch_pixels):\n",
    "                    if not sampler.sample_at(pixel, inputs, labels, i):\n",
    "                        labels[i] = nan_label\n",
    "\n",
    "                targets = [graph_info[\"verify_predictions\"],\n",
    "                           graph_info[\"verify_depths\"]]\n",
    "                predictions, depths = session.run(\n",
    "                    targets, feed_dict={graph_info[\"verify\"] : inputs}\n",
    "                )\n",
    "                \n",
    "                if output_path:\n",
    "                    sy = (raw_depths.shape[0] + image_size[0]) / 2\n",
    "                    ey = sy + height_span\n",
    "                    ix = (image_size[0] / 2) + column\n",
    "                    raw_depths[sy:ey, ix] = improc.encode_normalized_depths(depths)\n",
    "                    label_depths[sy:ey, ix] = improc.encode_normalized_depths(\n",
    "                        depths_for_labels_normalized(predictions[:,:-1])\n",
    "                    )\n",
    "                    argmax_predictions = np.argmax(predictions[:,:-1], axis=1)\n",
    "                    argmax_depths[sy:ey, ix] = improc.encode_normalized_depths(\n",
    "                        DEPTH_BOUNDARY_MIDPOINTS[argmax_predictions] / improc.MAX_DEPTH\n",
    "                    )\n",
    "                        \n",
    "                image_scores += test_score(labels, predictions, depths, len(batch_pixels))\n",
    "            \n",
    "            image_name, ext = os.path.splitext(os.path.basename(image_path))\n",
    "            all_scores[image_name] = image_scores\n",
    "            print(\"Image scores for\", image_name, image_scores[:-1] / image_scores[-1])\n",
    "            if output_path:\n",
    "                outputs = [\n",
    "                    (raw_depths, \"_depth\"),\n",
    "                    (label_depths, \"_softmax\"),\n",
    "                    (argmax_depths, \"_argmax\")\n",
    "                ]\n",
    "                for image, postfix in outputs:\n",
    "                    imsave(os.path.join(output_path, image_name + postfix + \".png\"), image)\n",
    "        return all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the test results as a CSV file, and find the min/max for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output_test_scores(test_scores, test_data, path):\n",
    "    with outputer.TeeOutput(path):\n",
    "        titles = [\"Name\", \"Accuracy\", \"Error\", \"Label Error\", \"Argmax Error\", \"Count\"]\n",
    "        total = np.zeros(shape=(5,), dtype=np.float32)\n",
    "        lines = [titles]\n",
    "        for image_path in test_data[\"test_files\"]:\n",
    "            image_name, ext = os.path.splitext(os.path.basename(image_path))\n",
    "            scores = test_scores[image_name]\n",
    "            total += scores\n",
    "            line = [image_name]\n",
    "            line.extend(scores[:-1] / scores[-1])\n",
    "            line.append(scores[-1])\n",
    "            lines.append(line)\n",
    "        line = [\"Total\"]\n",
    "        line.extend(total[:-1] / total[-1])\n",
    "        line.append(total[-1])\n",
    "        lines.append(line)\n",
    "\n",
    "        text = \"\\n\".join(\",\".join(str(v) for v in line) for line in lines)\n",
    "        print(text)\n",
    "\n",
    "        for i in range(1, 5):\n",
    "            sorted_lines = sorted(lines[1:-1], key=lambda l: l[i])\n",
    "            print(titles[i] + \" high\")\n",
    "            print(\",\".join([str(v) for v in sorted_lines[-1]]))\n",
    "            print(titles[i] + \" low\")\n",
    "            print(\",\".join([str(v) for v in sorted_lines[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructs a simple graph that just computes the output label and depth corresponding to a constant depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_constant_depth(batch_size, image_shape, label_count, value):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        verify  = tf.placeholder(tf.float32,\n",
    "                                 shape=batch_input_shape(batch_size, image_shape))\n",
    "        mean_label = tf.one_hot(depth_label_index(value), label_count, np.float32(1), 0)\n",
    "        mean_label = tf.reshape(mean_label, (1, DEPTH_LABEL_COUNT))\n",
    "        return {\n",
    "            \"graph\": graph,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"verify\": verify,\n",
    "            \"verify_predictions\": tf.tile(mean_label, [batch_size, 1]),\n",
    "            \"verify_depths\": tf.fill([batch_size, 1], value / improc.MAX_DEPTH)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the test scores resulting from just predicting the mean for every pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with outputer.TeeOutput(os.path.join(\"temp\", \"guess_mean_test.txt\")):\n",
    "    mean_graph = predict_constant_depth(\n",
    "        100, data_files[\"image_size\"], DEPTH_LABEL_COUNT, MEAN_DEPTH\n",
    "    )\n",
    "    test_data = setup_cross_validation(\n",
    "        data_files, 0, 0, 1123, label_count=DEPTH_LABEL_COUNT\n",
    "    )\n",
    "    mean_test_scores = compute_test_images(\n",
    "        mean_graph, test_data, False, None\n",
    "    )\n",
    "\n",
    "output_test_scores(mean_test_scores, test_data, \"temp/mean_test_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and score the candidate graph for the full test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_candidate_stack(stack_path, output_path, output_images):\n",
    "    batch_size = 480 - data_files[\"image_size\"][0]\n",
    "\n",
    "    with outputer.TeeOutput(os.path.join(output_path, \"full_test.txt\")):\n",
    "        candidate = convevo.load_stack(stack_path)\n",
    "        test_data = setup_cross_validation(\n",
    "            data_files, 0, 0, 10, label_count=DEPTH_LABEL_COUNT\n",
    "        )\n",
    "        candidate_graph = setup_graph(\n",
    "            batch_size, test_data[\"image_size\"], test_data[\"depth_labels\"], 1.0, candidate\n",
    "        )\n",
    "        convnet.setup_restore_model(\n",
    "            candidate_graph, candidate.checkpoint_path()\n",
    "        )\n",
    "        test_scores = compute_test_images(\n",
    "            candidate_graph, test_data, output_path if output_images else None\n",
    "        )\n",
    "    output_test_scores(\n",
    "        test_scores, test_data, os.path.join(output_path, \"full_test_scores.csv\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate6_results_path = outputer.setup_directory(\"temp/candidate6\")\n",
    "test_candidate_stack(\"testing/candidate6.xml\", candidate6_results_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
