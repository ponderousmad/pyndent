{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/29772158/make-ipython-notebook-print-in-real-time\n",
    "oldsysstdout = sys.stdout\n",
    "class flushfile():\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __getattr__(self,name): \n",
    "        return object.__getattribute__(self.f, name)\n",
    "    def write(self, x):\n",
    "        self.f.write(x)\n",
    "        self.f.flush()\n",
    "    def flush(self):\n",
    "        self.f.flush()\n",
    "sys.stdout = flushfile(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate Images\n",
    "Image names are sequential, so add every tenth image to the validation set based on filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "test = []\n",
    "\n",
    "for root, dirs, files in os.walk('captures'):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        low_name = name.lower()\n",
    "        # Find all the image files, split into test and training.\n",
    "        if low_name.endswith(\".png\"):\n",
    "            if low_name.endswith(\"0.png\"):\n",
    "                test.append(path)\n",
    "            else:\n",
    "                training.append(path)\n",
    "\n",
    "print(\"Training:\", len(training), \"Test:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "Each image file contains a color image (top half), and an encoded depth image (bottom half)\n",
    "<img src=\"captures/testing/IMG_2114.PNG\">\n",
    "* Note: The image may also contain the orientation data. If so it is encoded in the first two pixels of the depth image. If the first pixel is red, the second has the x, y, z, w quaternion components encoded in the r,g,b,a values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(image):\n",
    "    \"\"\"Split the image data into the top and bottom half.\"\"\"\n",
    "    split_height = image.shape[0] / 2\n",
    "    return image[:split_height], image[split_height:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_depth(image):\n",
    "    \"\"\"12 bits of depth in millimeters is encoded with 6 bits in red and 3 bits in each of green and blue.\"\"\"\n",
    "    BYTE_MAX = 255\n",
    "    CHANNEL_MAX = 8.0\n",
    "    MAX_RED_VALUE = BYTE_MAX - CHANNEL_MAX\n",
    "    CHANNELS_MAX = CHANNEL_MAX * CHANNEL_MAX\n",
    "    orientation = [1, 0, 0, 0] # default orientation if not present in image.\n",
    "    \n",
    "    if np.array_equal(image[0, 0], [BYTE_MAX, 0, 0, BYTE_MAX]):\n",
    "        # Orientation quaternion is present.\n",
    "        pixel = image[0, 1]\n",
    "        for c in range(len(orientation)):\n",
    "            orientation[c] = ((2.0 * pixel[c]) / BYTE_MAX) - 1\n",
    "\n",
    "        # Clear out the pixels so they don't get interepreted as depth.\n",
    "        image[0, 0] = [0, 0, 0, BYTE_MAX]\n",
    "        image[0, 1] = [0, 0, 0, BYTE_MAX]\n",
    "\n",
    "    red = image[:, :, 0]\n",
    "    green = image[:, :, 1]\n",
    "    blue = image[:, :, 2]\n",
    "\n",
    "    depth = ((MAX_RED_VALUE - red) * CHANNELS_MAX) + ((green - red) * CHANNEL_MAX) + (blue - red)\n",
    "    \n",
    "    # Zero in the red channel indicates the sensor provided no data.\n",
    "    depth[np.where(red == 0)] = float('nan')\n",
    "    return depth, orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill NaNs with localized stat values using mipmaps\n",
    "Combined this: http://stackoverflow.com/questions/14549696/mipmap-of-image-in-numpy\n",
    "\n",
    "With this: http://stackoverflow.com/questions/5480694/numpy-calculate-averages-with-nans-removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mipmap_imputer(image, strategy=np.mean, scales=None):\n",
    "    scales = scales if scales else [(5,5), (3,2), (2,2), (2,2), (2,2), (2,2), (2,2), (1,2)]\n",
    "    mipmaps = []\n",
    "    mipmap = image\n",
    "    for y, x in scales:\n",
    "        mipmap = mipmap.copy()\n",
    "        size = mipmap.shape\n",
    "        reshaped = mipmap.reshape(size[0] / y, y, size[1] / x, x)\n",
    "        masked = np.ma.masked_array(reshaped, np.isnan(reshaped))\n",
    "        mipmap = strategy(strategy(masked, axis=3), axis=1).filled(np.nan)\n",
    "        mipmaps.append(mipmap)\n",
    "    \n",
    "    for index, mipmap in reversed(list(enumerate(mipmaps))):\n",
    "        y, x = scales[index]\n",
    "        expanded = mipmap\n",
    "        if x > 1:\n",
    "            expanded = np.repeat(expanded, x, axis=1).reshape(expanded.shape[0], expanded.shape[1] * x)\n",
    "        if y > 1:\n",
    "            expanded = np.repeat(expanded, y, axis=0).reshape(expanded.shape[0] * y, expanded.shape[1])\n",
    "        target = mipmaps[index - 1] if index > 0 else image.copy()\n",
    "\n",
    "        nans = np.where(np.isnan(target))\n",
    "        target[nans] = expanded[nans]\n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Node/Layer Types:\n",
    "* Matrix\n",
    " * Dimensions (height, width, depth)\n",
    "* Relu\n",
    "* Dropout\n",
    " * Fraction\n",
    "* Conv\n",
    " * Dimensions (height, width, channels)\n",
    " * Stride (height, width)\n",
    " * Padding Type (same, valid)\n",
    "* Pool\n",
    " * Type (max, avg)\n",
    " * Size (height, width)\n",
    " * Stride (height, width) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = '../ud730/notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"image_size\": 28,\n",
    "    \"label_count\": 10,\n",
    "    \"channel_count\": 1\n",
    "}\n",
    "datasets[\"total_image_size\"] = datasets[\"image_size\"] * datasets[\"image_size\"]\n",
    "\n",
    "def reformat(dataset, labels, name):\n",
    "    dataset = dataset.reshape((-1, datasets[\"image_size\"], datasets[\"image_size\"], datasets[\"channel_count\"])).astype(np.float32)\n",
    "    # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "    labels = (np.arange(datasets[\"label_count\"]) == labels[:,None]).astype(np.float32)\n",
    "    print(name + \" set\", dataset.shape, labels.shape)\n",
    "    return dataset, labels\n",
    "datasets[\"train\"], datasets[\"train_labels\"] = reformat(train_dataset, train_labels, \"Training\")\n",
    "datasets[\"valid\"], datasets[\"valid_labels\"] = reformat(valid_dataset, valid_labels, \"Validation\")\n",
    "datasets[\"test\"], datasets[\"test_labels\"] = reformat(test_dataset, test_labels, \"Test\")\n",
    "\n",
    "print(datasets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_graph(graph_info, data, step_count, report_every=50):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        for step in xrange(step_count + 1):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (data[\"train_labels\"].shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = data[\"train\"][offset:(offset + batch_size), :, :, :]\n",
    "            batch_labels = data[\"train_labels\"][offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            targets = [graph_info[\"optimizer\"], graph_info[\"loss\"], graph_info[\"predictions\"]]\n",
    "            feed_dict = {graph_info[\"train\"] : batch_data, graph_info[\"labels\"] : batch_labels}\n",
    "            _, l, predictions = session.run(targets, feed_dict=feed_dict)\n",
    "            if (step % report_every == 0):\n",
    "                print(\"Minibatch loss at step\", step, \":\", l)\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(graph_info[\"valid\"].eval(), data[\"valid_labels\"]))\n",
    "        print(\"Test accuracy: %.1f%%\" % accuracy(graph_info[\"test\"].eval(), data[\"test_labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def no_parameters(options):\n",
    "    return ()\n",
    "\n",
    "def setup_matrix(options):\n",
    "    initialize_matrix = options[\"init\"]\n",
    "    size = options[\"size\"]\n",
    "    matrix = tf.Variable(initialize_matrix(size))\n",
    "    if options[\"bias\"]:\n",
    "        initialize_bias = options[\"bias_init\"]\n",
    "        bias = tf.Variable(initialize_bias(size[-1:]))\n",
    "        return (matrix, bias)\n",
    "    return (matrix,)\n",
    "\n",
    "def apply_matrix(input_node, train, parameters, options):\n",
    "    application = tf.matmul(input_node, parameters[0])\n",
    "    if len(parameters) > 1:\n",
    "        return application + parameters[1]\n",
    "    return application\n",
    "\n",
    "def apply_relu(input_node, train, parameters, options):\n",
    "    return tf.nn.relu(input_node)\n",
    "\n",
    "def apply_dropout(input_node, train, parameters, options):\n",
    "    if train:\n",
    "        return tf.nn.dropout(input_node, options[\"dropout_rate\"], seed=options[\"seed\"])\n",
    "    else:\n",
    "        return input_node\n",
    "\n",
    "def apply_conv(input_node, train, parameters, options):\n",
    "    stride = options[\"stride\"]\n",
    "    output = tf.nn.conv2d(input_node, parameters[0], [1, stride[0], stride[1], 1], padding=options[\"padding\"])\n",
    "    \n",
    "    if options[\"bias\"]:\n",
    "        output = output + parameters[1]\n",
    "        \n",
    "    return output\n",
    "\n",
    "def apply_pool(input_node, train, parameters, options):\n",
    "    if options[\"pool_type\"] == \"max\":\n",
    "        pool_function = tf.nn.max_pool\n",
    "    else:\n",
    "        pool_function = tf.nn.avg_pool\n",
    "    stride = [1, options[\"stride\"][0], options[\"stride\"][1], 1]\n",
    "    size = [1, options[\"size\"][0], options[\"size\"][1], 1]\n",
    "    return pool_function(input_node, size, stride, padding=options[\"padding\"])\n",
    "\n",
    "def apply_flatten(input_node, train, parameters, options):\n",
    "    shape = input_node.get_shape()\n",
    "    shape = [int(shape[0]), int(shape[1] * shape[2] * shape[3])]\n",
    "    return tf.reshape(input_node, shape)\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, options, parameter_setup, node_setup):\n",
    "        self.options = options\n",
    "        self.parameter_setup = parameter_setup\n",
    "        self.node_setup = node_setup\n",
    "        self.parameters = None\n",
    "        self.node = None\n",
    "        \n",
    "    def setup_parameters(self):\n",
    "        self.parameters = self.parameter_setup(self.options)\n",
    "        \n",
    "    def connect(self, input_node, train):\n",
    "        node = self.node_setup(input_node, train, self.parameters, self.options)\n",
    "        return node\n",
    "    \n",
    "def create_matrix_layer(inputs, channels, init=lambda size: tf.truncated_normal(size, stddev=0.1)):\n",
    "    in_size = inputs if isinstance(inputs, tuple) else (inputs,)\n",
    "    size = in_size + (channels,)\n",
    "    options = {\n",
    "        \"size\": size,\n",
    "        \"bias\": True,\n",
    "        \"init\": lambda size: init(size),\n",
    "        \"bias_init\": lambda size: init((channels,))\n",
    "    }\n",
    "    return Layer(options, setup_matrix, apply_matrix)\n",
    "\n",
    "def create_relu_layer():\n",
    "    return Layer({}, no_parameters, apply_relu)\n",
    "\n",
    "def create_dropout_layer(rate, seed):\n",
    "    options = {\n",
    "        \"dropout_rate\": rate,\n",
    "        \"seed\": seed\n",
    "    }\n",
    "    return Layer(options, no_parameters, apply_dropout)\n",
    "\n",
    "def create_conv_layer(patch_size, stride, in_channels, out_channels, bias=True, padding=\"SAME\"):\n",
    "    init = lambda size: tf.truncated_normal(size, stddev=0.1)\n",
    "    options = {\n",
    "        \"size\": patch_size + (in_channels, out_channels),\n",
    "        \"init\": init,\n",
    "        \"bias\": bias,\n",
    "        \"bias_init\": init,\n",
    "        \"stride\": stride,\n",
    "        \"padding\": padding\n",
    "    }\n",
    "    return Layer(options, setup_matrix, apply_conv)\n",
    "\n",
    "def create_pool_layer(strategy, patch_size, stride, channels, padding=\"SAME\"):\n",
    "    options = {\n",
    "        \"pool_type\": strategy,\n",
    "        \"size\": patch_size,\n",
    "        \"stride\": stride,\n",
    "        \"padding\": padding\n",
    "    }\n",
    "    return Layer(options, no_parameters, apply_pool)\n",
    "\n",
    "def create_flatten_layer():\n",
    "    options = {}\n",
    "    return Layer(options, no_parameters, apply_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convnet_two_layer(batch_size, patch_size, depth, hidden_size, data):\n",
    "    image_size = data[\"image_size\"]\n",
    "    label_count = data[\"label_count\"]\n",
    "    channel_count = data[\"channel_count\"]\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Input data.\n",
    "        train = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, channel_count))\n",
    "        labels= tf.placeholder(tf.float32, shape=(batch_size, label_count))\n",
    "        valid = tf.constant(data[\"valid\"])\n",
    "        test  = tf.constant(data[\"test\"])\n",
    "        \n",
    "        stride = 2\n",
    "        \n",
    "        layers = [\n",
    "            create_conv_layer((patch_size, patch_size), (stride, stride), 1, depth),\n",
    "            create_relu_layer(),\n",
    "            create_conv_layer((patch_size, patch_size), (stride, stride), depth, depth),\n",
    "            create_relu_layer(),\n",
    "            create_flatten_layer(),\n",
    "            create_matrix_layer(image_size * image_size * depth / pow(stride, 4), hidden_size),\n",
    "            create_relu_layer(),\n",
    "            create_matrix_layer(hidden_size, label_count)\n",
    "        ]\n",
    "        \n",
    "        for layer in layers:\n",
    "            layer.setup_parameters()\n",
    "        \n",
    "        def model(output, train):\n",
    "            for layer in layers:\n",
    "                output = layer.connect(output, train)\n",
    "            return output\n",
    "\n",
    "        logits = model(train, True)\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))\n",
    "        \n",
    "        info = {\n",
    "            \"graph\": graph,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"train\": train,\n",
    "            \"labels\": labels,\n",
    "            \"loss\": loss,\n",
    "            \"optimizer\": tf.train.GradientDescentOptimizer(0.05).minimize(loss),\n",
    "\n",
    "            # Predictions for the training, validation, and test data.\n",
    "            \"predictions\": tf.nn.softmax(logits),\n",
    "            \"valid\": tf.nn.softmax(model(valid, False)),\n",
    "            \"test\":  tf.nn.softmax(model(test, False))\n",
    "        }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_2conv = convnet_two_layer(batch_size=16, patch_size=5, depth=16, hidden_size=64, data=datasets)\n",
    "\n",
    "run_graph(graph_2conv, datasets, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimal_steps = 200000\n",
    "\n",
    "graph_connive = convnet_optimize(\n",
    "    batch_size=16, patch_sizes=[5,14], strides=[2,7], depths=[16,128],\n",
    "    hidden_sizes=[128,64],\n",
    "    rate_alpha=0.02, decay_rate=0.9, decay_steps=optimal_steps/4,\n",
    "    beta_loss=0.0005,\n",
    "    dropout_rate=0.5,\n",
    "    base_seed=45645,\n",
    "    data=datasets)\n",
    "\n",
    "run_graph(graph_connive, datasets, optimal_steps, report_every=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
