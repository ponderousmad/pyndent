{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/29772158/make-ipython-notebook-print-in-real-time\n",
    "oldsysstdout = sys.stdout\n",
    "class flushfile():\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __getattr__(self,name): \n",
    "        return object.__getattribute__(self.f, name)\n",
    "    def write(self, x):\n",
    "        self.f.write(x)\n",
    "        self.f.flush()\n",
    "    def flush(self):\n",
    "        self.f.flush()\n",
    "sys.stdout = flushfile(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate Images\n",
    "Image names are sequential, so add every tenth image to the validation set based on filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "validation = []\n",
    "\n",
    "for root, dirs, files in os.walk('captures'):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        low_name = name.lower()\n",
    "        # Find all the image files, split into validation and training.\n",
    "        if low_name.endswith(\".png\"):\n",
    "            if low_name.endswith(\"0.png\"):\n",
    "                validation.append(path)\n",
    "            else:\n",
    "                training.append(path)\n",
    "\n",
    "print(\"Training:\", len(training), \"Validation:\", len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "Each image file contains a color image (top half), and an encoded depth image (bottom half)\n",
    "<img src=\"captures/testing/IMG_2114.PNG\">\n",
    "* Note: The image may also contain the orientation data. If so it is encoded in the first two pixels of the depth image. If the first pixel is red, the second has the x, y, z, w quaternion components encoded in the r,g,b,a values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(image):\n",
    "    \"\"\"Split the image data into the top and bottom half.\"\"\"\n",
    "    split_height = image.shape[0] / 2\n",
    "    return image[:split_height], image[split_height:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_depth(image):\n",
    "    \"\"\"12 bits of depth in millimeters is encoded with 6 bits in red and 3 bits in each of green and blue.\"\"\"\n",
    "    BYTE_MAX = 255\n",
    "    CHANNEL_MAX = 8.0\n",
    "    MAX_RED_VALUE = BYTE_MAX - CHANNEL_MAX\n",
    "    CHANNELS_MAX = CHANNEL_MAX * CHANNEL_MAX\n",
    "    orientation = [1, 0, 0, 0] # default orientation if not present in image.\n",
    "    \n",
    "    if np.array_equal(image[0, 0], [BYTE_MAX, 0, 0, BYTE_MAX]):\n",
    "        # Orientation quaternion is present.\n",
    "        pixel = image[0, 1]\n",
    "        for c in range(len(orientation)):\n",
    "            orientation[c] = ((2.0 * pixel[c]) / BYTE_MAX) - 1\n",
    "\n",
    "        # Clear out the pixels so they don't get interepreted as depth.\n",
    "        image[0, 0] = [0, 0, 0, BYTE_MAX]\n",
    "        image[0, 1] = [0, 0, 0, BYTE_MAX]\n",
    "\n",
    "    red = image[:, :, 0]\n",
    "    green = image[:, :, 1]\n",
    "    blue = image[:, :, 2]\n",
    "\n",
    "    depth = ((MAX_RED_VALUE - red) * CHANNELS_MAX) + ((green - red) * CHANNEL_MAX) + (blue - red)\n",
    "    \n",
    "    # Zero in the red channel indicates the sensor provided no data.\n",
    "    depth[np.where(red == 0)] = float('nan')\n",
    "    return depth, orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill NaNs with localized stat values using mipmaps\n",
    "Combined this: http://stackoverflow.com/questions/14549696/mipmap-of-image-in-numpy\n",
    "\n",
    "With this: http://stackoverflow.com/questions/5480694/numpy-calculate-averages-with-nans-removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mipmap_imputer(image, strategy=np.mean, scales=None):\n",
    "    scales = scales if scales else [(5,5), (3,2), (2,2), (2,2), (2,2), (2,2), (2,2), (1,2)]\n",
    "    mipmaps = []\n",
    "    mipmap = image\n",
    "    for y, x in scales:\n",
    "        mipmap = mipmap.copy()\n",
    "        size = mipmap.shape\n",
    "        reshaped = mipmap.reshape(size[0] / y, y, size[1] / x, x)\n",
    "        masked = np.ma.masked_array(reshaped, np.isnan(reshaped))\n",
    "        mipmap = strategy(strategy(masked, axis=3), axis=1).filled(np.nan)\n",
    "        mipmaps.append(mipmap)\n",
    "    \n",
    "    for index, mipmap in reversed(list(enumerate(mipmaps))):\n",
    "        y, x = scales[index]\n",
    "        expanded = mipmap\n",
    "        if x > 1:\n",
    "            expanded = np.repeat(expanded, x, axis=1).reshape(expanded.shape[0], expanded.shape[1] * x)\n",
    "        if y > 1:\n",
    "            expanded = np.repeat(expanded, y, axis=0).reshape(expanded.shape[0] * y, expanded.shape[1])\n",
    "        target = mipmaps[index - 1] if index > 0 else image.copy()\n",
    "\n",
    "        nans = np.where(np.isnan(target))\n",
    "        target[nans] = expanded[nans]\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
