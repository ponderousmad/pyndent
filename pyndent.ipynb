{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "import outputer\n",
    "import improc\n",
    "import convnet\n",
    "import mutate\n",
    "import convevo\n",
    "import darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload (improc)\n",
    "reload (convnet)\n",
    "reload (mutate)\n",
    "reload (convevo)\n",
    "reload (darwin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate Images\n",
    "Image names are sequential, so add every tenth image to the validation set based on filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "test = []\n",
    "\n",
    "for root, dirs, files in os.walk('captures'):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        low_name = name.lower()\n",
    "        # Find all the image files, split into test and training.\n",
    "        if low_name.endswith(\".png\"):\n",
    "            if low_name.endswith(\"0.png\"):\n",
    "                test.append(path)\n",
    "            else:\n",
    "                training.append(path)\n",
    "\n",
    "print(\"Training:\", len(training), \"Test:\", len(test))\n",
    "print(training[:2])\n",
    "print(test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "Each image file contains a color image (top half), and an encoded depth image (bottom half)\n",
    "<img src=\"testing/IMG_2114.PNG\">\n",
    "* Note: The image may also contain the orientation data. If so it is encoded in the first two pixels of the depth image. If the first pixel of the depth image is red, the second has the x, y, z, w quaternion components encoded in the r,g,b,a values.\n",
    "\n",
    "The improc module contains functions for splitting the image, decoding the depth back into floating point millimeters, and for filling in gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Precomputed via compute_average_depth()\n",
    "MEAN_DEPTH = np.float32(1688.97)\n",
    "\n",
    "print(MEAN_DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth_image_cache_path = outputer.setup_directory(\"temp\", \"cache\")\n",
    "\n",
    "class ImageSampler(object):\n",
    "    \"\"\"Wrap an image for sampling.\"\"\"\n",
    "    def __init__(self, image_file):\n",
    "        # Process the image or grab it from the cache.\n",
    "        # image is normalized CIELAB, depth is not normalized.\n",
    "        self.image, self.depth = improc.process_cached(depth_image_cache_path, image_file)\n",
    "        self.depth /= improc.MAX_DEPTH\n",
    "\n",
    "    def sample(self, image_slot, depth_slot, height_offset=None, width_offset=None):\n",
    "        height = image_slot.shape[0]\n",
    "        spare_height = self.image.shape[0] - height\n",
    "        y = spare_height / 2 if height_offset is None else height_offset\n",
    "        \n",
    "        width = image_slot.shape[1]\n",
    "        spare_width = self.image.shape[1] - width\n",
    "        x = spare_width / 2 if width_offset is None else width_offset\n",
    "        \n",
    "        image_slot[:,:,:] = self.image[y : y + height, x : x + width, : image_slot.shape[-1]]\n",
    "        depth_slot[:,:,0] = self.depth[y : y + height, x : x + width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_images(image_paths, inputs, targets):\n",
    "    for i, sampler in enumerate([ImageSampler(path) for path in image_paths]):\n",
    "        sampler.sample(inputs[i], targets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_image, example_depth, example_attitude = improc.load_image(\"testing/IMG_2114.PNG\")\n",
    "plt.imshow(example_image)\n",
    "print(example_image.shape, example_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_depth)\n",
    "print(example_depth.shape, example_depth.dtype)\n",
    "print(example_attitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = ImageSampler(\"testing/IMG_2114.PNG\")\n",
    "sample_size = 100\n",
    "image_sample = np.zeros(shape=(sample_size, sample_size, 3))\n",
    "depth_sample = np.zeros(shape=(sample_size, sample_size, 1))\n",
    "sampler.sample(image_sample, depth_sample)\n",
    "\n",
    "print(image_sample.shape, image_sample.dtype)\n",
    "plt.imshow(image_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(depth_sample.reshape(sample_size, sample_size))\n",
    "print(depth_sample.shape, depth_sample.dtype)\n",
    "print(np.min(depth_sample), np.max(depth_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COLOR_CHANNELS = 3\n",
    "image_height = 480\n",
    "image_width = 640\n",
    "\n",
    "data_files = {\n",
    "    \"image_size\": (image_height, image_width, COLOR_CHANNELS),\n",
    "    \"depth_size\": (image_height, image_width, 1),\n",
    "    \"train_files\": np.array(training),\n",
    "    \"test_files\": np.array(test)\n",
    "}\n",
    "\n",
    "del training\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_cross_validation(data, train_count, valid_count, test_count=None, chunk_size=None, entropy=random):\n",
    "    cross_data = data.copy()\n",
    "    \n",
    "    if chunk_size:\n",
    "        cross_data[\"image_size\"] = chunk_size\n",
    "        cross_data[\"depth_size\"] = chunk_size[:-1] + (1,)\n",
    "\n",
    "    paths = cross_data[\"train_files\"][:]\n",
    "    mutate.fisher_yates_shuffle(paths, entropy)\n",
    "\n",
    "    cross_data[\"train_files\"] = paths[:train_count]\n",
    "    cross_data[\"valid_files\"] = paths[train_count:train_count + valid_count]\n",
    "    \n",
    "    if test_count is not None:\n",
    "        cross_data[\"test_files\"] = data[\"test_files\"][:test_count]\n",
    "    \n",
    "    return cross_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_graph(\n",
    "    batch_size,\n",
    "    image_shape,\n",
    "    target_shape,\n",
    "    layer_stack\n",
    "):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        input_shape = (batch_size,) + image_shape\n",
    "        output_shape = (batch_size,) + target_shape\n",
    "        train   = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        targets = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        verify  = tf.placeholder(tf.float32, shape=input_shape)\n",
    "\n",
    "        layers = layer_stack.construct(input_shape, output_shape)\n",
    "        l2_loss = convnet.setup_layers(layers)\n",
    "\n",
    "        results = convnet.connect_model(train, layers, True)[-1]\n",
    "        \n",
    "        # Fill NaNs in target with values from results to\n",
    "        # eliminate any contribution to the gradient\n",
    "        valid_targets = tf.select(tf.is_nan(targets), results, targets)\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.squared_difference(results, valid_targets)) + l2_loss\n",
    "        \n",
    "        info = {\n",
    "            \"graph\": graph,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"train\": train,\n",
    "            \"targets\": targets,\n",
    "            \"loss\": loss,\n",
    "            \"optimizer\": layer_stack.construct_optimizer(loss),\n",
    "\n",
    "            # Predictions for training and verification (validation or test)\n",
    "            \"predictions\": results,\n",
    "            \"verify\": verify,\n",
    "            \"verify_predictions\": convnet.connect_model(verify, layers, False)[-1]\n",
    "        }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_error(predictions, targets):\n",
    "    where_valid = np.where(np.isfinite(targets))\n",
    "    return sklearn.metrics.mean_squared_error(predictions[where_valid], targets[where_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_error(session, graph_info, files, inputs, targets, batch_size):\n",
    "    total_error = 0    \n",
    "    batch_count = len(files) / batch_size\n",
    "    for b in xrange(batch_count):\n",
    "        offset = b * batch_size\n",
    "        end = offset + batch_size\n",
    "        prepare_images(files[offset:end], inputs, targets)\n",
    "        feed_dict = {graph_info[\"verify\"]: inputs}\n",
    "        predictions = session.run([graph_info[\"verify_predictions\"]], feed_dict=feed_dict)[0]\n",
    "        total_error += prediction_error(predictions, targets) / np.float32(batch_count)\n",
    "    return total_error, predictions[-1], targets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_graph(\n",
    "    graph_info,\n",
    "    data,\n",
    "    step_count,\n",
    "    report_every=50,\n",
    "    verbose=True,\n",
    "    compute_test=False,\n",
    "    error_maximum=None\n",
    "):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        height, width, channels = data[\"image_size\"]\n",
    "        max_error = 1\n",
    "        valid_error = max_error\n",
    "        valid_data = None\n",
    "        training_files = data[\"train_files\"]\n",
    "        \n",
    "        batch_inputs = np.zeros(shape=(batch_size, height, width, channels), dtype=np.float32)\n",
    "        batch_targets = np.zeros(shape=(batch_size, height, width, 1), dtype=np.float32)\n",
    "        \n",
    "        for step in xrange(step_count + 1):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            offset = (step * batch_size) % (training_files.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_files = training_files[offset:(offset + batch_size)]\n",
    "            prepare_images(batch_files, batch_inputs, batch_targets)\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            targets = [\n",
    "                graph_info[\"optimizer\"],\n",
    "                graph_info[\"loss\"],\n",
    "                graph_info[\"predictions\"]\n",
    "            ]\n",
    "            feed_dict = {\n",
    "                graph_info[\"train\"] : batch_inputs,\n",
    "                graph_info[\"targets\"] : batch_targets\n",
    "            }\n",
    "            _, l, predictions = session.run(targets, feed_dict=feed_dict)\n",
    "            if np.isnan(l):\n",
    "                print(\"Error computing loss:\", l)\n",
    "                print(np.sum(np.isnan(predictions)))\n",
    "                return 0, None\n",
    "            if (step % report_every == 0):\n",
    "                if verbose:\n",
    "                    print(\"Minibatch loss at step\", step, \":\", l)\n",
    "                valid_error, _, _ = batch_error(\n",
    "                    session, graph_info, data[\"valid_files\"],\n",
    "                    batch_inputs, batch_targets, batch_size\n",
    "                )\n",
    "                print(\"Validation error: %.3f\" % valid_error)\n",
    "                if error_maximum and step > 0 and valid_error < error_maximum:\n",
    "                    print(\"Early out.\")\n",
    "                    break\n",
    "        results = (predictions[0], batch_targets[0], batch_inputs[0])\n",
    "        if compute_test:\n",
    "            test_results = batch_error(\n",
    "                session, graph_info, data[\"test_files\"],\n",
    "                batch_inputs, batch_targets, batch_size\n",
    "            )\n",
    "            print(\"Test error: %.3f\" % test_results[0])\n",
    "            results = results + test_results\n",
    "        return max_error - min(valid_error, max_error), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "sample_size = data_files[\"image_size\"]\n",
    "depth_size = proto_cross[\"depth_size\"]\n",
    "proto_cross = setup_cross_validation(data_files, 9800, 200, 1000, sample_size)\n",
    "conv_layers = [\n",
    "    (\"conv\",       5, 2, 10, \"SAME\", False),\n",
    "    (\"conv\",      10, 2, 20, \"SAME\", False),\n",
    "    (\"conv_bias\", 15, 5, 25, \"SAME\", False)\n",
    "]\n",
    "expand_layers = [\n",
    "    (5, 5, \"SAME\", True, False),\n",
    "    (2, 5, \"SAME\", True, False),\n",
    "    (2, 5, \"SAME\", True, False)\n",
    "]\n",
    "prototype = convevo.create_stack(conv_layers, expand_layers, False, [], 0.0, 0.01, 0.0)\n",
    "prototype.make_safe((batch_size,) + sample_size, (batch_size,) + depth_size)\n",
    "prototype.reseed(random.Random(24601))\n",
    "prototype_graph = setup_graph(batch_size, sample_size, depth_size, prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score, results = run_graph(prototype_graph, prototype_cross, 8, 4, True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(results[0][:,:,0])\n",
    "print(np.min(results[0]),np.max(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(results[1].reshape(sample_height,sample_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_width = 400\n",
    "test_height = 400\n",
    "images, depth = prepare_images(prototype_cross[\"train_files\"][:1], test_width, test_height, COLOR_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0])\n",
    "print(np.min(images[0][:,:,0]),np.max(images[0][:,:,0]))\n",
    "print(np.min(images[0][:,:,1]),np.max(images[0][:,:,1]))\n",
    "print(np.min(images[0][:,:,2]),np.max(images[0][:,:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(depth[0][:,:,0])\n",
    "print(np.min(depth[0]),np.max(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(images.shape)\n",
    "print(depth.shape)\n",
    "prediction_error(images[:,:,:,0:1], depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_error(np.zeros(shape=(1, test_width, test_height, 1)), depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
