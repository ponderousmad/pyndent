{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "import ipywidgets\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "import sklearn.metrics\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import outputer\n",
    "import improc\n",
    "import convnet\n",
    "import mutate\n",
    "import convevo\n",
    "import darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload (improc)\n",
    "reload (convnet)\n",
    "reload (mutate)\n",
    "reload (convevo)\n",
    "reload (darwin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate Images\n",
    "Image names are sequential, so add every tenth image to the validation set based on filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "test = []\n",
    "\n",
    "for root, dirs, files in os.walk('captures'):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        low_name = name.lower()\n",
    "        # Find all the image files, split into test and training.\n",
    "        if low_name.endswith(\".png\"):\n",
    "            if low_name.endswith(\"0.png\"):\n",
    "                test.append(path)\n",
    "            else:\n",
    "                training.append(path)\n",
    "\n",
    "print(\"Training:\", len(training), \"Test:\", len(test))\n",
    "print(training[:2])\n",
    "print(test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "Each image file contains a color image (top half), and an encoded depth image (bottom half)\n",
    "<img src=\"testing/IMG_2114.PNG\">\n",
    "* Note: The image may also contain the orientation data. If so it is encoded in the first two pixels of the depth image. If the first pixel of the depth image is red, the second has the x, y, z, w quaternion components encoded in the r,g,b,a values.\n",
    "\n",
    "The improc module contains functions for splitting the image, decoding the depth back into floating point millimeters, and for filling in gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Precomputed via compute_average_depth()\n",
    "MEAN_DEPTH = np.float32(1688.97)\n",
    "\n",
    "print(MEAN_DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth_image_cache_path = outputer.setup_directory(\"temp\", \"cache\")\n",
    "\n",
    "class ImageSampler(object):\n",
    "    \"\"\"Wrap an image for sampling.\"\"\"\n",
    "    def __init__(self, image_file):\n",
    "        # Process the image or grab it from the cache.\n",
    "        # image is normalized CIELAB, depth is not normalized.\n",
    "        self.image, self.depth = improc.process_cached(depth_image_cache_path, image_file)\n",
    "        self.depth /= improc.MAX_DEPTH\n",
    "\n",
    "    def sample(self, image_slot, depth_slot, height_offset=None, width_offset=None):\n",
    "        height = image_slot.shape[0]\n",
    "        spare_height = self.image.shape[0] - height\n",
    "        y = spare_height / 2 if height_offset is None else height_offset\n",
    "        \n",
    "        width = image_slot.shape[1]\n",
    "        spare_width = self.image.shape[1] - width\n",
    "        x = spare_width / 2 if width_offset is None else width_offset\n",
    "        \n",
    "        image_slot[:,:,:] = self.image[y : y + height, x : x + width, : image_slot.shape[-1]]\n",
    "        depth_slot[:,:,0] = self.depth[y : y + height, x : x + width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_images(image_paths, inputs, targets):\n",
    "    for i, sampler in enumerate([ImageSampler(path) for path in image_paths]):\n",
    "        sampler.sample(inputs[i], targets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_image, example_depth, example_attitude = improc.load_image(\"testing/IMG_2114.PNG\")\n",
    "plt.imshow(example_image)\n",
    "print(example_image.shape, example_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_depth)\n",
    "print(example_depth.shape, example_depth.dtype)\n",
    "print(example_attitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = ImageSampler(\"testing/IMG_2114.PNG\")\n",
    "sample_size = 100\n",
    "image_sample = np.zeros(shape=(sample_size, sample_size, 3))\n",
    "depth_sample = np.zeros(shape=(sample_size, sample_size, 1))\n",
    "sampler.sample(image_sample, depth_sample)\n",
    "\n",
    "print(image_sample.shape, image_sample.dtype)\n",
    "plt.imshow(image_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(depth_sample.reshape(sample_size, sample_size))\n",
    "print(depth_sample.shape, depth_sample.dtype)\n",
    "print(np.min(depth_sample), np.max(depth_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COLOR_CHANNELS = 3\n",
    "image_height = 480\n",
    "image_width = 640\n",
    "\n",
    "data_files = {\n",
    "    \"image_size\": (image_height, image_width, COLOR_CHANNELS),\n",
    "    \"depth_size\": (image_height, image_width, 1),\n",
    "    \"train_files\": np.array(sorted(training)),\n",
    "    \"test_files\": np.array(sorted(test))\n",
    "}\n",
    "\n",
    "del training\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_cross_validation(data, valid_count, test_count=None, chunk_size=None, entropy=random):\n",
    "    cross_data = data.copy()\n",
    "    \n",
    "    if chunk_size:\n",
    "        cross_data[\"image_size\"] = chunk_size\n",
    "        cross_data[\"depth_size\"] = chunk_size[:-1] + (1,)\n",
    "\n",
    "    paths = cross_data[\"train_files\"][:]\n",
    "    mutate.fisher_yates_shuffle(paths, entropy)\n",
    "\n",
    "    cross_data[\"train_files\"] = paths[:-valid_count]\n",
    "    cross_data[\"valid_files\"] = paths[-valid_count:]\n",
    "    \n",
    "    if test_count is None:\n",
    "        del cross_data[\"test_files\"]\n",
    "    else:\n",
    "        cross_data[\"test_files\"] = data[\"test_files\"][:test_count]\n",
    "    \n",
    "    return cross_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_graph(\n",
    "    batch_size,\n",
    "    image_shape,\n",
    "    target_shape,\n",
    "    layer_stack,\n",
    "    include_coords=False\n",
    "):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        input_shape = (batch_size,) + image_shape\n",
    "        output_shape = (batch_size,) + target_shape\n",
    "        train   = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        targets = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        verify  = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        \n",
    "        train_inputs = train\n",
    "        verify_inputs = verify\n",
    "        if include_coords:\n",
    "            y_size = image_shape[0]\n",
    "            x_size = image_shape[1]\n",
    "            coords = np.zeros(shape=(batch_size, y_size, x_size, 2), dtype=np.float32)\n",
    "            coords[:, :, :, 0] = np.linspace(-1, 1, num=y_size, dtype=np.float32).reshape((1, y_size, 1))\n",
    "            coords[:, :, :, 1] = np.linspace(-1, 1, num=x_size, dtype=np.float32).reshape((1, 1, x_size))\n",
    "            input_shape = input_shape[:-1] + (input_shape[-1] + coords.shape[-1],)\n",
    "            train_inputs = tf.concat(3, [train, tf.constant(coords)])\n",
    "            verify_inputs = tf.concat(3, [verify, coords])\n",
    "        \n",
    "        layers = layer_stack.construct(input_shape, output_shape)\n",
    "        l2_loss = convnet.setup_layers(layers)\n",
    "        \n",
    "        results = convnet.connect_model(train_inputs, layers, True)[-1]\n",
    "        \n",
    "        # Fill NaNs in target with values from results to\n",
    "        # eliminate any contribution to the gradient\n",
    "        valid_targets = tf.select(tf.is_nan(targets), results, targets)\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.squared_difference(results, valid_targets)) + l2_loss\n",
    "        \n",
    "        verify_predictions = convnet.connect_model(verify_inputs, layers, False)[-1]\n",
    "        verify_predictions = tf.maximum(verify_predictions, 0)\n",
    "        verify_predictions = tf.minimum(verify_predictions, 1)\n",
    "        \n",
    "        info = {\n",
    "            \"graph\": graph,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"train\": train,\n",
    "            \"targets\": targets,\n",
    "            \"loss\": loss,\n",
    "            \"optimizer\": layer_stack.construct_optimizer(loss),\n",
    "\n",
    "            # Predictions for training and verification (validation or test)\n",
    "            \"predictions\": results,\n",
    "            \"verify\": verify,\n",
    "            \"verify_predictions\": verify_predictions,\n",
    "            \"saver\": tf.train.Saver()\n",
    "        }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_error(predictions, targets):\n",
    "    is_finite = np.isfinite(targets)\n",
    "    where_valid = np.where(is_finite)\n",
    "    error = np.mean(np.absolute(predictions[where_valid] - targets[where_valid]))\n",
    "    return error, np.count_nonzero(is_finite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictor(session, graph_info):\n",
    "    def predict(inputs, targets):\n",
    "        feed_dict = {graph_info[\"verify\"]: inputs}\n",
    "        return session.run([graph_info[\"verify_predictions\"]], feed_dict=feed_dict)[0]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_prediction_error(predictor, files, inputs, targets, batch_size):\n",
    "    total_error = 0\n",
    "    total_count = 0\n",
    "    batch_count = len(files) / batch_size\n",
    "    for b in xrange(batch_count):\n",
    "        offset = b * batch_size\n",
    "        end = offset + batch_size\n",
    "        prepare_images(files[offset:end], inputs, targets)\n",
    "        predictions = predictor(inputs, targets)\n",
    "        error, count = prediction_error(predictions, targets)\n",
    "        total_error += error * count\n",
    "        total_count += count\n",
    "    return (total_error / np.float32(total_count)), predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def depth_mean_like(depths):\n",
    "    return np.ones_like(depths) * (MEAN_DEPTH / improc.MAX_DEPTH)\n",
    "\n",
    "def always_guess_mean_error(files, inputs, targets, batch_size):\n",
    "    def predict_mean(images, depths):\n",
    "        return depth_mean_like(depths)\n",
    "    return batch_prediction_error(predict_mean, files, inputs, targets, batch_size)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_input_shape(batch_size, data):\n",
    "    return (batch_size,) + data[\"image_size\"]\n",
    "\n",
    "def batch_output_shape(batch_size, data):\n",
    "    return (batch_size,) + data[\"depth_size\"]\n",
    "\n",
    "def score_run(guess_mean_error, valid_error):\n",
    "    return guess_mean_error - min(valid_error, 1)\n",
    "\n",
    "def run_graph(\n",
    "    graph_info,\n",
    "    data,\n",
    "    step_count,\n",
    "    report_every=50,\n",
    "    verbose=True,\n",
    "    progress=None,\n",
    "    tracker=None,\n",
    "    mean_error_cache=None,\n",
    "    error_maximum=None\n",
    "):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "\n",
    "        # Optionally restore graph parameters from disk.\n",
    "        convnet.restore_model(graph_info, session)\n",
    "        \n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        batch_inputs = np.empty(shape=batch_input_shape(batch_size, data), dtype=np.float32)\n",
    "        batch_targets = np.empty(shape=batch_output_shape(batch_size, data), dtype=np.float32)\n",
    "\n",
    "        # Validation and scoring bits.\n",
    "        valid_error = 1\n",
    "        \n",
    "        guess_mean_error = None\n",
    "        if mean_error_cache is not None:\n",
    "            guess_mean_error = mean_error_cache.get(\"cached\")\n",
    "        if not guess_mean_error:\n",
    "            guess_mean_error = always_guess_mean_error(\n",
    "                data[\"valid_files\"], batch_inputs, batch_targets, batch_size\n",
    "            )\n",
    "            print(\"Error if just guess mean:\", guess_mean_error)\n",
    "            \n",
    "            if mean_error_cache is not None:\n",
    "                mean_error_cache[\"cached\"] = guess_mean_error\n",
    "        predictor = make_predictor(session, graph_info)\n",
    "        \n",
    "        training_files = data[\"train_files\"]\n",
    "        try:\n",
    "            for step in xrange(step_count + 1):\n",
    "                # Update progress bar, if present\n",
    "                if progress:\n",
    "                    progress.value = step\n",
    "\n",
    "                # Generate a minibatch.\n",
    "                offset = (step * batch_size) % (training_files.shape[0] - batch_size)\n",
    "                batch_files = training_files[offset:(offset + batch_size)]\n",
    "                prepare_images(batch_files, batch_inputs, batch_targets)\n",
    "\n",
    "                # Graph evaluation targets:\n",
    "                targets = [\n",
    "                    graph_info[\"optimizer\"],\n",
    "                    graph_info[\"loss\"],\n",
    "                    graph_info[\"predictions\"]\n",
    "                ]\n",
    "                \n",
    "                # Graph inputs:\n",
    "                feed_dict = {\n",
    "                    graph_info[\"train\"] : batch_inputs,\n",
    "                    graph_info[\"targets\"] : batch_targets\n",
    "                }\n",
    "                \n",
    "                # Run the graph\n",
    "                _, loss, predictions = session.run(targets, feed_dict=feed_dict)\n",
    "                \n",
    "                # Capture last prediction\n",
    "                results = (predictions[-1], batch_targets[-1], batch_inputs[-1])\n",
    "                \n",
    "                # Update stats:\n",
    "                reporting = step % report_every == 0\n",
    "                if reporting or tracker:\n",
    "                    batch_error, _ = prediction_error(predictions, batch_targets)\n",
    "                    if tracker:\n",
    "                        tracker((loss, batch_error))\n",
    "                \n",
    "                if not np.isfinite(loss):\n",
    "                    print(\"Error computing loss:\", loss)\n",
    "                    print(np.sum(np.isnan(predictions)))\n",
    "                    return score_run(guess_mean_error, valid_error), results\n",
    "                \n",
    "                if reporting:\n",
    "                    if verbose:\n",
    "                        print(\"Minibatch loss at step\", step, \":\", loss)\n",
    "                        print(\"Minibatch error:\", batch_error)\n",
    "                    valid_error, _, _ = batch_prediction_error(\n",
    "                        predictor, data[\"valid_files\"],\n",
    "                        batch_inputs, batch_targets, batch_size\n",
    "                    )\n",
    "                    print(\"Validation error:\", valid_error)\n",
    "                    if error_maximum and step > 0 and valid_error < error_maximum:\n",
    "                        print(\"Early out.\")\n",
    "                        break\n",
    "            test_files = data.get(\"test_files\")\n",
    "            if test_files is not None:\n",
    "                test_results = batch_prediction_error(\n",
    "                    predictor, test_files,\n",
    "                    batch_inputs, batch_targets, batch_size\n",
    "                )\n",
    "                print(\"Test error:\", test_results[0])\n",
    "                results = results + test_results\n",
    "            return score_run(guess_mean_error, valid_error), results\n",
    "        finally:\n",
    "            # Optionally save out graph parameters to disk.\n",
    "            convnet.save_model(graph_info, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_BATCH = 1\n",
    "test_inputs = np.empty(shape=(TEST_BATCH, 480, 640, COLOR_CHANNELS), dtype=np.float32)\n",
    "test_depths = np.empty_like(test_inputs[:,:,:,:1])\n",
    "prepare_images(data_files[\"test_files\"][:TEST_BATCH], test_inputs, test_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_inputs[0,:,:,0], cmap='Greys_r')\n",
    "print(np.min(test_inputs[0,:,:,0]),np.max(test_inputs[0,:,:,0]))\n",
    "print(np.min(test_inputs[0,:,:,1]),np.max(test_inputs[0,:,:,1]))\n",
    "print(np.min(test_inputs[0,:,:,2]),np.max(test_inputs[0,:,:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_depths[0,:,:,0])\n",
    "depths_valid = np.where(np.isfinite(test_depths[0]))\n",
    "print(np.min(test_depths[0][depths_valid]),np.max(test_depths[0][depths_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(test_inputs.shape)\n",
    "print(test_depths.shape)\n",
    "prediction_error(test_inputs[:,:,:,0:1], test_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_error(np.zeros_like(test_depths), test_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_error(depth_mean_like(test_depths), test_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_error(test_depths, test_depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_BATCH = 1\n",
    "conv_layers = [\n",
    "    (\"conv\",       5, 2, 10, \"SAME\", False),\n",
    "    (\"conv\",      10, 2, 20, \"SAME\", False),\n",
    "    (\"conv_bias\", 15, 5, 25, \"SAME\", False)\n",
    "]\n",
    "expand_layers = [\n",
    "    (5, 5, \"SAME\", True, False),\n",
    "    (2, 5, \"SAME\", True, False),\n",
    "    (2, 5, \"SAME\", True, False)\n",
    "]\n",
    "test_stack = convevo.create_stack(conv_layers, expand_layers, False, [], 0.0, 0.01, 0.0)\n",
    "test_stack.make_safe((TEST_BATCH,) + data_files[\"image_size\"], (TEST_BATCH,) + data_files[\"depth_size\"])\n",
    "test_stack.reseed(random.Random(24601))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_size = data_files[\"image_size\"]\n",
    "depth_size = data_files[\"depth_size\"]\n",
    "\n",
    "test_graph = setup_graph(TEST_BATCH, sample_size, depth_size, test_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_cross = setup_cross_validation(data_files, 200, 200, sample_size)\n",
    "test_score, test_results = run_graph(test_graph, test_cross, 8, 4, True)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_results[0][:,:,0])\n",
    "print(np.min(test_results[0]),np.max(test_results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_results[1].reshape(sample_size[0],sample_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_results[2][:,:,0], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del test_stack\n",
    "del test_graph\n",
    "del test_cross\n",
    "del test_results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evolving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_path = outputer.setup_directory(\"temp\", \"pyndent_results\")\n",
    "\n",
    "def save_results(timestamp, results):\n",
    "    with open(os.path.join(results_path, timestamp + \".csv\"), \"w\") as text_file:\n",
    "        text_file.write(\"Loss,Depth Error\\n\")\n",
    "        for score in results:\n",
    "            text_file.write((\",\".join(str(v) for v in score)) + \"\\n\")\n",
    "    print(\"Saved results:\", timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_eval(batch_size, eval_steps, valid_size, reuse_cross, include_coords=False, entropy=random):\n",
    "    mean_error_cache = None\n",
    "    if reuse_cross:\n",
    "        redata = setup_cross_validation(\n",
    "            data_files, valid_size, entropy=entropy\n",
    "        )\n",
    "        mean_error_cache = {}\n",
    "\n",
    "    # Set up to show a progress bar so you some mesure of time required. Updated in run_graph above.\n",
    "    progress_bar = ipywidgets.FloatProgress(min=0, max=eval_steps, description=\"Graph Steps:\")\n",
    "    display(progress_bar)\n",
    "    \n",
    "    # Set up to show current training results as well as a running average. updated in record_score below. \n",
    "    def setup_label(title):\n",
    "        return ipywidgets.FloatText(value=0, description=title, disabled=True)\n",
    "    current_display = [setup_label(title) for title in [\"Loss\", \"Error\"]]\n",
    "    average_display = [setup_label(\" \") for _ in current_display]\n",
    "    display(ipywidgets.HBox([\n",
    "        ipywidgets.Box([ipywidgets.HTML(\"<div style=\"\"margin-left:90px\"\">Current</div>\")] + current_display),\n",
    "        ipywidgets.Box([ipywidgets.HTML(\"<div style=\"\"margin-left:90px\"\">Running Average</div>\")] + average_display)\n",
    "    ]))\n",
    "        \n",
    "    def evaluate(stack, eval_entropy):\n",
    "        # If not reusing data, generate training and validation sets\n",
    "        if not reuse_cross:\n",
    "            data = setup_cross_validation(\n",
    "                data_files, valid_size, entropy=eval_entropy\n",
    "            )\n",
    "        else:\n",
    "            data = redata\n",
    "\n",
    "        # Set up the Tensorflow graph\n",
    "        try:\n",
    "            evo_graph = setup_graph(batch_size, data[\"image_size\"], data[\"depth_size\"], stack, include_coords)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            # Record any errors and the stack that caused them.\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            lines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "            print(lines[-1])\n",
    "            convevo.output_error(stack, lines, \"temp\", outputer.timestamp(\"ERR~\", \"txt\"))\n",
    "            return -10\n",
    "\n",
    "        timestamp = outputer.timestamp()\n",
    "        with open(os.path.join(results_path, timestamp + \".xml\"), \"w\") as text_file:\n",
    "            text_file.write(convevo.serialize(stack))\n",
    "    \n",
    "        convnet.setup_save_model(evo_graph, os.path.join(results_path, timestamp + \".ckpt\"))\n",
    "        \n",
    "        # Record and display the results\n",
    "        results = []\n",
    "        def record_score(score):\n",
    "            results.append(score)\n",
    "            for display, value in zip(current_display, score):\n",
    "                display.value = value\n",
    "            \n",
    "            resultCount = min(len(results), 100)\n",
    "            averages = [sum(x)/resultCount for x in zip(*results[-resultCount:])]\n",
    "            for display, value in zip(average_display, averages):\n",
    "                display.value = value\n",
    "                \n",
    "        # Run the graph\n",
    "        try:\n",
    "            valid_error, _ = run_graph(\n",
    "                evo_graph,\n",
    "                data,\n",
    "                eval_steps,\n",
    "                report_every=eval_steps/4,\n",
    "                verbose=True,\n",
    "                progress=progress_bar,\n",
    "                tracker=record_score,\n",
    "                mean_error_cache=mean_error_cache\n",
    "            )\n",
    "            return valid_error\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            # Record any errors and the stack that caused them.\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            lines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "            print(lines[-1])\n",
    "            convevo.output_error(stack, lines, results_path, timestamp + \"~ERR.txt\")\n",
    "            return -1\n",
    "        finally:\n",
    "            save_results(timestamp, results)\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers = [\n",
    "    (\"conv\",       5, 2, 10, \"SAME\", False),\n",
    "    (\"conv\",      10, 2, 20, \"SAME\", False),\n",
    "    (\"conv_bias\", 15, 5, 25, \"SAME\", False)\n",
    "]\n",
    "expand_layers = [\n",
    "    (5, 5, \"SAME\", True, False),\n",
    "    (2, 5, \"SAME\", True, False),\n",
    "    (2, 5, \"SAME\", True, False)\n",
    "]\n",
    "prototype = convevo.create_stack(conv_layers, expand_layers, False, [], 0.0, 0.01, 0.0)\n",
    "\n",
    "prototypes = [prototype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population,_,_ = convevo.load_population(\"testing/pyndent_evolve_run.xml\", False)\n",
    "prototypes = population[:5]\n",
    "print(len(prototypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prototypes = [\n",
    "    convevo.load_stack(\"testing/pyndent1.xml\"),\n",
    "    convevo.load_stack(\"testing/pyndent2.xml\"),\n",
    "    convevo.load_stack(\"testing/pyndent3.xml\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prototypes = [\n",
    "    convevo.load_stack(\"testing/pyndent4.xml\")\n",
    "]\n",
    "print(convevo.serialize(prototypes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prototypes = [\n",
    "    convevo.load_stack(\"testing/pyndent5.xml\")\n",
    "]\n",
    "print(convevo.serialize(prototypes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with outputer.TeeOutput(os.path.join(\"temp\", outputer.timestamp(\"Pyndent_Evolve_\", \"txt\"))):\n",
    "    mutate_seed = random.randint(1, 100000)\n",
    "    print(\"Mutate Seed:\", mutate_seed)\n",
    "    mutate_entropy = random.Random(mutate_seed)\n",
    "    eval_seed = random.randint(1, 100000)\n",
    "    print(\"Eval Seed:\", eval_seed)\n",
    "    eval_entropy = random.Random(eval_seed)\n",
    "\n",
    "    population_size = 10\n",
    "    generations = 5\n",
    "    batch_size = 1\n",
    "\n",
    "    breed_options = {\n",
    "        \"input_shape\": batch_input_shape(batch_size, data_files),\n",
    "        \"output_shape\": batch_output_shape(batch_size, data_files)\n",
    "    }\n",
    "\n",
    "    for stack in prototypes:\n",
    "        stack.make_safe(breed_options[\"input_shape\"], breed_options[\"output_shape\"])\n",
    "\n",
    "    evaluator = make_eval(\n",
    "        batch_size=batch_size, eval_steps=80000, valid_size=400,\n",
    "        reuse_cross=True, entropy=eval_entropy\n",
    "    )\n",
    "    charles = darwin.Darwin(convevo.serialize, evaluator, convevo.rebreed)\n",
    "    charles.init_population(prototypes, population_size, False, breed_options, mutate_entropy)\n",
    "\n",
    "    try:\n",
    "        for g in range(generations):\n",
    "            print(\"Generation\", g)\n",
    "            results = charles.evaluate(eval_entropy)\n",
    "            convevo.output_results(results, \"temp\", outputer.timestamp() + \".xml\", mutate_seed, eval_seed)\n",
    "            charles.repopulate(population_size, 0.3, 3, results, breed_options, mutate_entropy)\n",
    "    finally:\n",
    "        results = darwin.descending_score(charles.history.values())\n",
    "        convevo.output_results(results, \"temp\", \"pyndent_candidate5_rebreed2.xml\", mutate_seed, eval_seed)\n",
    "        print(\"Evaluated\", len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Candidate Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_test_images(graph_info, data, output_path):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "\n",
    "        # restore graph parameters from disk.\n",
    "        convnet.restore_model(graph_info, session)\n",
    "        \n",
    "        # Set up space for graph inputs\n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        batch_inputs = np.empty(shape=batch_input_shape(batch_size, data), dtype=np.float32)\n",
    "        batch_targets = np.empty(shape=batch_output_shape(batch_size, data), dtype=np.float32)\n",
    "       \n",
    "        predictor = make_predictor(session, graph_info)\n",
    "        \n",
    "        # Set up progress bar\n",
    "        test_files = data[\"test_files\"]\n",
    "        eval_count = len(test_files) / batch_size\n",
    "        progress = ipywidgets.FloatProgress(min=0, max=eval_count, description=\"Evaluation Steps:\")\n",
    "        display(progress)\n",
    "        \n",
    "        # Only score the error on the same portion of the image as classydepth so we can compare.\n",
    "        input_image_size = batch_inputs.shape[1:]\n",
    "        classy_sample_size = (101, 101)\n",
    "        sample_start = tuple(s / 2 for s in classy_sample_size)\n",
    "        sample_end = tuple(\n",
    "            ss + iis - css for iis, css, ss in zip(input_image_size, classy_sample_size, sample_start)\n",
    "        )\n",
    "        classy_depth_start = (input_image_size[0] + sample_start[0], sample_start[1])\n",
    "        classy_depth_end = tuple(\n",
    "             cds + se - ss for cds, ss, se in zip(classy_depth_start, sample_start, sample_end)\n",
    "        )\n",
    "        def sample_patch(image, index):\n",
    "            return image[index, sample_start[0]:sample_end[0], sample_start[1]:sample_end[1], :]\n",
    "        \n",
    "        titles = [\"Name\", \"Error\", \"Count\"]\n",
    "        print(\",\".join(titles))\n",
    "        \n",
    "        all_scores = []\n",
    "        error_sum = 0\n",
    "        pixel_count = 0\n",
    "        for step in xrange(eval_count):\n",
    "            progress.value = step\n",
    "            offset = step * batch_size\n",
    "            end = offset + batch_size\n",
    "            batch_files = test_files[offset:end]\n",
    "            prepare_images(batch_files, batch_inputs, batch_targets)\n",
    "            predictions = predictor(batch_inputs, batch_targets)\n",
    "\n",
    "            for i in xrange(batch_size):\n",
    "                image_path = batch_files[i]\n",
    "                image_name, ext = os.path.splitext(os.path.basename(image_path))\n",
    "                image = ndimage.imread(image_path)\n",
    "                error, count = prediction_error(sample_patch(predictions, i), sample_patch(batch_targets, i))\n",
    "                encoded_depths = improc.encode_normalized_depths(predictions)\n",
    "\n",
    "                image[classy_depth_start[0] : classy_depth_end[0],\n",
    "                      classy_depth_start[1] : classy_depth_end[1], :] = sample_patch(encoded_depths, i)\n",
    "                \n",
    "                imsave(os.path.join(output_path, image_name + \".png\"), image)\n",
    "                \n",
    "                image[input_image_size[0]:,:,:] = encoded_depths[i]\n",
    "                imsave(os.path.join(output_path, image_name + \"_full.png\"), image)\n",
    "                results = [image_name, error, count]\n",
    "                error_sum += error * count\n",
    "                pixel_count += count\n",
    "                print(\",\".join(str(v) for v in results))\n",
    "                all_scores.append(results)\n",
    "                \n",
    "        print(\",\".join([\"Total\", str(error_sum / pixel_count), str(pixel_count)]))\n",
    "              \n",
    "        sorted_scores = sorted(all_scores, key=lambda l: l[1])\n",
    "        print(titles[1] + \" high\")\n",
    "        print(\",\".join([str(v) for v in sorted_scores[-1]]))\n",
    "        print(titles[1] + \" low\")\n",
    "        print(\",\".join([str(v) for v in sorted_scores[0]]))\n",
    "              \n",
    "        return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results_path = outputer.setup_directory(\"temp/pyndent6\")\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "with outputer.TeeOutput(os.path.join(test_results_path, \"pyndent6_test.txt\")):\n",
    "    candidate = convevo.load_stack(\"testing/pyndent6/2016-06-22~17_51_16_872.xml\")\n",
    "    test_data = setup_cross_validation(data_files, 0, 1123, entropy=random.Random(121))\n",
    "    candidate_graph = setup_graph(BATCH_SIZE, test_data[\"image_size\"], test_data[\"depth_size\"], candidate)\n",
    "    convnet.setup_restore_model(candidate_graph, \"testing/pyndent6/2016-06-22~17_51_16_872.ckpt\")\n",
    "    candidate_test_scores = compute_test_images(candidate_graph, test_data, test_results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
