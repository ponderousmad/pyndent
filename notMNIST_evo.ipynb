{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolving Convnets to Classify notMNIST Glyphs\n",
    "=============================================\n",
    "This notebook attempts to evolve graphs that optimially learn to classify notMNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import random\n",
    "import ipywidgets\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import outputer\n",
    "import convnet\n",
    "import mutate\n",
    "import convevo\n",
    "import darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For easy incorporation of module changes\n",
    "reload (convnet)\n",
    "reload (mutate)\n",
    "reload (convevo)\n",
    "reload (darwin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "## Note: Requires notMNIST_setup notebook to be run first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_data(pickle_file):\n",
    "    data = {\n",
    "        \"image_size\": 28,\n",
    "        \"label_count\": 10,\n",
    "        \"channel_count\": 1\n",
    "    }\n",
    "    data[\"total_image_size\"] = data[\"image_size\"] * data[\"image_size\"]\n",
    "    \n",
    "    with gzip.open(pickle_file, 'rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        inputs_train = save['train_dataset']\n",
    "        labels_train = save['train_labels']\n",
    "        inputs_test = save['test_dataset']\n",
    "        labels_test = save['test_labels']\n",
    "        print('Training set', inputs_train.shape, labels_train.shape)\n",
    "        print('Test set', inputs_test.shape, labels_test.shape)\n",
    "\n",
    "    def setup_data(inputs, labels, name):\n",
    "        shape = (-1, data[\"image_size\"], data[\"image_size\"], data[\"channel_count\"])\n",
    "        inputs = inputs.reshape(shape).astype(np.float32)\n",
    "        # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "        labels = (np.arange(data[\"label_count\"]) == labels[:,None]).astype(np.float32)\n",
    "        print(name + \" set\", inputs.shape, labels.shape)\n",
    "        return inputs, labels\n",
    "    data[\"train\"], data[\"train_labels\"] = setup_data(inputs_train, labels_train, \"Training\")\n",
    "    data[\"test\"], data[\"test_labels\"] = setup_data(inputs_test, labels_test, \"Test\")\n",
    "    return data\n",
    "\n",
    "full_data = setup_data('notMNIST/full.pickle')\n",
    "print(full_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training/validation split from the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_validate(data, train_count, validate_count, entropy=random):\n",
    "    def randomize(inputs, labels):\n",
    "        permutation = np.arange(labels.shape[0], dtype=np.int32)\n",
    "        mutate.fisher_yates_shuffle(permutation, entropy)\n",
    "        shuffled_inputs = inputs[permutation,:,:,:]\n",
    "        shuffled_labels = labels[permutation,:]\n",
    "        return shuffled_inputs, shuffled_labels\n",
    "\n",
    "    train_inputs = data[\"train\"][:]\n",
    "    train_labels = data[\"train_labels\"][:]\n",
    "    cross_data = copy.copy(data)\n",
    "\n",
    "    train_inputs, train_labels = randomize(train_inputs, train_labels)\n",
    "    cross_data[\"train\"] = train_inputs[:train_count]\n",
    "    cross_data[\"train_labels\"] = train_labels[:train_count]\n",
    "\n",
    "    cross_data[\"valid\"] = train_inputs[train_count:train_count + validate_count]\n",
    "    cross_data[\"valid_labels\"] = train_labels[train_count:train_count + validate_count]\n",
    "    return cross_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_setup_validate():\n",
    "    cross_data = setup_validate(full_data, 1000, 100)\n",
    "    print(cross_data[\"train_labels\"].shape)\n",
    "    print(cross_data[\"train_labels\"][0])\n",
    "    print(full_data[\"train_labels\"][0])\n",
    "    print(cross_data[\"valid\"].shape)\n",
    "\n",
    "test_setup_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Construction From convevo Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def graph_input_shape(batch_size, data):\n",
    "    image_size = data[\"image_size\"]\n",
    "    channel_count = data[\"channel_count\"]\n",
    "    return (batch_size, image_size, image_size, channel_count)\n",
    "\n",
    "def graph_output_shape(batch_size, data):\n",
    "    return (batch_size, data[\"label_count\"])\n",
    "\n",
    "def setup_graph(batch_size, data, stack):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Input data.\n",
    "        input_shape = graph_input_shape(batch_size, data)\n",
    "        output_shape = graph_output_shape(batch_size, data)\n",
    "        train = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        labels= tf.placeholder(tf.float32, shape=output_shape)\n",
    "        verify= tf.placeholder(tf.float32, shape=input_shape)\n",
    "\n",
    "        operations = stack.construct(input_shape, output_shape)\n",
    "        l2_loss = convnet.setup(operations)\n",
    "        \n",
    "        logits        = convnet.connect_model(train,  operations, True)[-1]\n",
    "        verify_logits = convnet.connect_model(verify, operations, False)[-1]\n",
    "        loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits,labels))+l2_loss\n",
    "        \n",
    "        info = {\n",
    "            \"graph\": graph,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"train\": train,\n",
    "            \"labels\": labels,\n",
    "            \"loss\": loss,\n",
    "            \"optimizer\": stack.construct_optimizer(loss),\n",
    "            \"predictions\": tf.nn.softmax(logits),\n",
    "            \"verify\": verify,\n",
    "            \"verify_predictions\": tf.nn.softmax(verify_logits),\n",
    "            \"saver\": tf.train.Saver()\n",
    "        }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    correct_predictions = np.argmax(predictions, 1) == np.argmax(labels, 1)\n",
    "    return (100.0 * np.sum(correct_predictions) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_accuracy(session, graph_info, inputs, labels, batch_size):\n",
    "    total_accuracy = 0\n",
    "    batch_count = len(inputs) / batch_size\n",
    "    for b in xrange(batch_count):\n",
    "        batch_data = inputs[b * batch_size: (b + 1) * batch_size]\n",
    "        feed_dict = { graph_info[\"verify\"] : batch_data }\n",
    "        predictions, = session.run([graph_info[\"verify_predictions\"]], feed_dict=feed_dict)\n",
    "        total_accuracy += accuracy(predictions, labels[b*batch_size : (b + 1)*batch_size])\n",
    "    return total_accuracy / float(batch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_graph(\n",
    "    graph_info,\n",
    "    data,\n",
    "    step_count,\n",
    "    report_every=50,\n",
    "    verbose=True,\n",
    "    eval_test=False,\n",
    "    accuracy_minimum=None,\n",
    "    tracker=None\n",
    "):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        \n",
    "        # Optionally restore graph parameters from disk.\n",
    "        convnet.restore_model(graph_info, session)\n",
    "        \n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        valid_accuracy = 0\n",
    "        last = step_count + 1 if step_count else 0\n",
    "        try:\n",
    "            for step in xrange(last):\n",
    "                if tracker:\n",
    "                    tracker.update_progress(step)\n",
    "\n",
    "                # Pick an offset within the training data, which has been randomized.\n",
    "                # Note: we could use better randomization across epochs.\n",
    "                offset = (step * batch_size) % (data[\"train_labels\"].shape[0] - batch_size)\n",
    "                # Generate a minibatch.\n",
    "                batch_data = data[\"train\"][offset:(offset + batch_size), :, :, :]\n",
    "                batch_labels = data[\"train_labels\"][offset:(offset + batch_size), :]\n",
    "                \n",
    "                # Graph evaluation targets:\n",
    "                targets = [\n",
    "                    graph_info[\"optimizer\"],\n",
    "                    graph_info[\"loss\"],\n",
    "                    graph_info[\"predictions\"]\n",
    "                ]\n",
    "                \n",
    "                # Graph inputs:\n",
    "                feed_dict = {\n",
    "                    graph_info[\"train\"] : batch_data,\n",
    "                    graph_info[\"labels\"] : batch_labels\n",
    "                }                \n",
    "                _, loss, predictions = session.run(targets, feed_dict=feed_dict)\n",
    "                \n",
    "                reporting = step % report_every == 0\n",
    "                if reporting or tracker:\n",
    "                    batch_score = (loss, accuracy(predictions, batch_labels))\n",
    "                    if tracker:\n",
    "                        tracker.record_score(batch_score)\n",
    "                    \n",
    "                if np.isnan(loss):\n",
    "                    print(\"Error computing loss\")\n",
    "                    return valid_accuracy\n",
    "                \n",
    "                if reporting:\n",
    "                    if verbose:\n",
    "                        print(\"Minibatch loss at step\", step, \":\", loss)\n",
    "                        print(\"Minibatch accuracy: %.1f%%\" % batch_score[1])\n",
    "                    valid_accuracy = batch_accuracy(\n",
    "                        session, graph_info, data[\"valid\"], data[\"valid_labels\"],batch_size\n",
    "                    )\n",
    "                    print(\"Validation accuracy: %.1f%%\" % valid_accuracy)\n",
    "                    if accuracy_minimum and step > 0 and valid_accuracy < accuracy_minimum:\n",
    "                        print(\"Early out.\")\n",
    "                        break\n",
    "            if eval_test:\n",
    "                test_accuracy = batch_accuracy(\n",
    "                    session, graph_info, data[\"test\"], data[\"test_labels\"], batch_size\n",
    "                )\n",
    "                print(\"Test accuracy: %.1f%%\" % test_accuracy)\n",
    "            return valid_accuracy\n",
    "        finally:\n",
    "            # Optionally save out graph parameters to disk.\n",
    "            convnet.save_model(graph_info, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up an evaluation function for use with Darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_path = outputer.setup_directory(\"temp\", \"notMNIST_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_eval(\n",
    "    batch_size=16,\n",
    "    eval_steps=100000,\n",
    "    valid_steps=5000,\n",
    "    eval_test=False\n",
    "):\n",
    "    progress_tracker = outputer.ProgressTracker(\n",
    "        [\"Loss\", \"Accuracy\"], eval_steps, results_path, convevo.serialize\n",
    "    )\n",
    "    \n",
    "    def evaluate(stack, entropy):   \n",
    "        data = setup_validate(full_data, eval_steps, valid_steps, entropy)\n",
    "        progress_tracker.setup_eval(stack)\n",
    "\n",
    "        # Set up the graph.\n",
    "        try:\n",
    "            graph_info = setup_graph(batch_size, data, stack)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            progress_tracker.error(sys.exc_info())\n",
    "            return -10\n",
    "\n",
    "        progress_tracker.start_eval(graph_info)\n",
    "       \n",
    "        # Run the graph\n",
    "        try:\n",
    "            return run_graph(\n",
    "                graph_info,\n",
    "                data,\n",
    "                eval_steps,\n",
    "                report_every=eval_steps/4,\n",
    "                verbose=False,\n",
    "                eval_test=eval_test,\n",
    "                accuracy_minimum=50,\n",
    "                tracker=progress_tracker\n",
    "            )\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            progress_tracker.error(sys.exc_info())\n",
    "            return -1\n",
    "        finally:\n",
    "            progress_tracker.output()\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify stack construction for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_stack(\n",
    "    patch_size, stride, depth, hidden_size, label_count, init_scale, optimizer_name=None\n",
    "):\n",
    "    if optimizer_name:\n",
    "        optimizer = convevo.Optimizer(optimizer_name, 0.05)\n",
    "        optimizer.default_parameters()\n",
    "    else:\n",
    "        optimizer = None\n",
    "        \n",
    "    conv_layers = [\n",
    "        (\"conv_bias\", patch_size, stride, depth, \"SAME\", True),\n",
    "        (\"conv_bias\", patch_size, stride, depth, \"SAME\", True)\n",
    "    ]\n",
    "\n",
    "    return convevo.create_stack(\n",
    "        conv_layers, [], True, [hidden_size, label_count], 0.0, init_scale, 0.0, optimizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test all the pieces (not required to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test optimizers\n",
    "def test_optimizers():\n",
    "    for optimizer in [\"GradientDescent\",\"Adadelta\",\"Adagrad\",\"Momentum\",\"Adam\",\"RMSProp\"]:\n",
    "        # As of this writing \"Ftrl\" is not supported on the GPU\n",
    "        batch_size = 16\n",
    "        eval_steps = 10000\n",
    "        test_stack = create_stack(5, 2, 64, 128, 10, 0.1, optimizer)\n",
    "        test_data = setup_validate(full_data, eval_steps * batch_size, 500)\n",
    "        test_graph = setup_graph(batch_size, test_data, test_stack)\n",
    "        result = run_graph(test_graph, test_data,\n",
    "                           eval_steps, report_every=eval_steps/4, verbose=False)\n",
    "        print(result)\n",
    "test_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test make_eval\n",
    "with outputer.TeeOutput(os.path.join(results_path, outputer.timestamp(\"Eval\", \"txt\"))):\n",
    "    test_stack = create_stack(5, 2, 64, 128, 10, 0.1)\n",
    "    print(convevo.serialize(test_stack))\n",
    "    make_eval()(test_stack, random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test darwin setup\n",
    "mutate_entropy = random.Random(42)\n",
    "scored_mutants = []\n",
    "breed_options = {\n",
    "    \"input_shape\": graph_input_shape(16, full_data),\n",
    "    \"output_shape\": graph_output_shape(16, full_data)\n",
    "}\n",
    "mutator = darwin.Darwin(convevo.serialize, lambda s,e: 0, convevo.breed)\n",
    "prototypes = [create_stack(5, 2, 64, 64, 10, 0.1)]\n",
    "for mutant in mutator.init_population(prototypes, 20, False, breed_options,mutate_entropy):\n",
    "    scored_mutants.append((mutant, 0.0))\n",
    "    \n",
    "convevo.output_results(scored_mutants, \"temp\", \"mutants.xml\", 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test mutation\n",
    "mutate_entropy = random.Random(42)\n",
    "mutant_children = []\n",
    "for _ in range(20):\n",
    "    mutant_a = mutate_entropy.choice(scored_mutants)[0]\n",
    "    mutant_b = mutate_entropy.choice(scored_mutants)[0]\n",
    "    mutant_children.append(\n",
    "        (convevo.breed([mutant_a, mutant_b], breed_options, mutate_entropy), 0.0)\n",
    "    )\n",
    "    \n",
    "convevo.output_results(mutant_children, \"temp\", \"mutant_offspring.xml\", 42, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolve notMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prototypes to seed the population\n",
    "prototypes = [\n",
    "    create_stack(5, 2, 64, 128, 10, 0.10, \"GradientDescent\"),\n",
    "    create_stack(6, 2, 128, 64, 10, 0.05, \"Adadelta\"),\n",
    "    create_stack(4, 2, 64, 128, 10, 0.10, \"Adagrad\"),\n",
    "    create_stack(5, 1, 32,  64, 10, 0.02, \"Adam\"),\n",
    "    create_stack(2, 2, 64, 128, 10, 0.20, \"RMSProp\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prototypes.append(convevo.load_stack(\"testing/notMNIST_optimized.xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evolve!\n",
    "BATCH_SIZE = 128\n",
    "with outputer.TeeOutput(os.path.join(\"temp\", outputer.timestamp(\"notMNIST_evo_\", \"txt\"))):\n",
    "    # Setup seeds and entropy\n",
    "    mutate_seed = random.randint(1, 100000)\n",
    "    print(\"Mutate Seed:\", mutate_seed)\n",
    "    mutate_entropy = random.Random(mutate_seed)\n",
    "    eval_seed = random.randint(1, 100000)\n",
    "    print(\"Eval Seed:\", eval_seed)\n",
    "    eval_entropy = random.Random(eval_seed)\n",
    "\n",
    "    # Number of stacks to test each generation\n",
    "    population_size = 20\n",
    "    # Number of generations to evaluate\n",
    "    generations = 10\n",
    "    \n",
    "    breed_options = {\n",
    "        \"input_shape\": graph_input_shape(BATCH_SIZE, full_data),\n",
    "        \"output_shape\": graph_output_shape(BATCH_SIZE, full_data)\n",
    "    }\n",
    "\n",
    "    # Ensure the prototypes have the correct structure (eg, output layer size)\n",
    "    for stack in prototypes:\n",
    "        stack.make_safe(breed_options[\"input_shape\"], breed_options[\"output_shape\"])\n",
    "\n",
    "    # Construct an evolver\n",
    "    charles = darwin.Darwin(\n",
    "        convevo.serialize,\n",
    "        make_eval(batch_size=BATCH_SIZE, eval_steps=100000),\n",
    "        convevo.breed\n",
    "    )\n",
    "    # Initialize the population (True to include the protototypes as population members)\n",
    "    charles.init_population(prototypes,population_size,True,breed_options,mutate_entropy)\n",
    "\n",
    "    # Evaluate, output, select and breed/mutate\n",
    "    for g in range(generations):\n",
    "        print(\"Generation\", g)\n",
    "        results = charles.evaluate(eval_entropy)\n",
    "        convevo.output_results(results, \"temp\", outputer.timestamp() + \".xml\")\n",
    "        charles.repopulate(population_size, 0.25, 4, results, breed_options,mutate_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the best result\n",
    "best = charles.best()\n",
    "print(\"Best score:\", best[1])\n",
    "print(convevo.serialize(best[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store all the results in one place. (note that each generation gets stored above too)\n",
    "results = darwin.descending_score(charles.history.values())\n",
    "convevo.output_results(\n",
    "    results, \"testing\", \"notminist_full_evolve_run_optimized.xml\", mutate_seed, eval_seed\n",
    ")\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If something went wrong, this helps to summarize error reports\n",
    "errors = []\n",
    "\n",
    "for root, dirs, files in os.walk('temp'):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        low_name = name.lower()\n",
    "        if low_name.startswith(\"err\"):\n",
    "            with open (path, \"r\") as error_file:\n",
    "                lines=error_file.readlines()\n",
    "                errors.append((path, lines[-1]))\n",
    "\n",
    "for path, error in sorted(errors, key=lambda e: e[0]):\n",
    "    print(path)\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show and re-run a stack (for debugging)\n",
    "rerun = 0\n",
    "print (convevo.serialize(charles.population[rerun]))\n",
    "make_eval()(charles.population[rerun], eval_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision of evolved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_eval = make_eval(batch_size=128, eval_steps=100000, valid_steps=10000, eval_test=True)\n",
    "\n",
    "results_file = os.path.join(\"temp\", outputer.timestamp(\"notMNIST_compare_\", \"txt\"))\n",
    "with outputer.TeeOutput(results_file):\n",
    "    seeds = [43214]\n",
    "    reseed = random.Random(seeds[0])\n",
    "    for _ in range(4):\n",
    "        seeds.append(reseed.randint(1, 100000))\n",
    "    print(\"Seeds:\", seeds)\n",
    "    \n",
    "    print(\"Baseline optimized network:\")\n",
    "    baseline = convevo.load_stack(\"testing/notMNIST_optimized.xml\")\n",
    "    print(convevo.serialize(baseline))\n",
    "    for seed in seeds:\n",
    "        full_eval(baseline, random.Random(seed))\n",
    "\n",
    "    print(\"\\n------------------------------------------------\")\n",
    "    print(\"Evolved from prototypes only:\")\n",
    "    population,_,_ = convevo.load_population(\n",
    "        \"testing/notMNIST_Evolve_2016-06-06~01_16_10_287.xml\", False\n",
    "    )\n",
    "    best = population[0]\n",
    "    print(convevo.serialize(best))    \n",
    "    for seed in seeds:\n",
    "        full_eval(best, random.Random(seed))\n",
    "    \n",
    "    print(\"\\n------------------------------------------------\")\n",
    "    print(\"Evolved from prototypes plus optimized baseline:\")\n",
    "    population,_,_ = convevo.load_population(\n",
    "        \"testing/notMNIST_full_evolve_run_optimized.xml\", False\n",
    "    )\n",
    "    best = population[0]\n",
    "    print(convevo.serialize(best))    \n",
    "    for seed in seeds:\n",
    "        full_eval(best, random.Random(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "with outputer.TeeOutput(os.path.join(\"temp\", outputer.timestamp(\"notMNIST_opt_\", \"txt\"))):\n",
    "    for stack, score in results[:5]:\n",
    "        stack_graph = setup_graph(BATCH_SIZE, full_data, stack)\n",
    "        checkpoint_path = stack.checkpoint_path()\n",
    "        if checkpoint_path:\n",
    "            convnet.setup_restore_model(stack_graph, checkpoint_path)\n",
    "            run_graph(stack_graph, test_data, 0, verbose=True, eval_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
