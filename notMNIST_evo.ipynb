{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolving Convnets to Classify notMNIST Glyphs\n",
    "=============================================\n",
    "This notebook attempts to evolve graphs that optimially learn to classify notMNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import random\n",
    "import traceback\n",
    "import ipywidgets\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import display\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import outputer\n",
    "import convnet\n",
    "import mutate\n",
    "import convevo\n",
    "import darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For easy incorporation of module changes\n",
    "reload (convnet)\n",
    "reload (mutate)\n",
    "reload (convevo)\n",
    "reload (darwin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "## Note: Requires notMNIST_setup notebook to be run first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_data(pickle_file):\n",
    "    data = {\n",
    "        \"image_size\": 28,\n",
    "        \"label_count\": 10,\n",
    "        \"channel_count\": 1\n",
    "    }\n",
    "    data[\"total_image_size\"] = data[\"image_size\"] * data[\"image_size\"]\n",
    "    \n",
    "    with gzip.open(pickle_file, 'rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        inputs_train = save['train_dataset']\n",
    "        labels_train = save['train_labels']\n",
    "        inputs_test = save['test_dataset']\n",
    "        labels_test = save['test_labels']\n",
    "        print('Training set', inputs_train.shape, labels_train.shape)\n",
    "        print('Test set', inputs_test.shape, labels_test.shape)\n",
    "\n",
    "    def setup_data(inputs, labels, name):\n",
    "        shape = (-1, data[\"image_size\"], data[\"image_size\"], data[\"channel_count\"])\n",
    "        inputs = inputs.reshape(shape).astype(np.float32)\n",
    "        # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "        labels = (np.arange(data[\"label_count\"]) == labels[:,None]).astype(np.float32)\n",
    "        print(name + \" set\", inputs.shape, labels.shape)\n",
    "        return inputs, labels\n",
    "    data[\"train\"], data[\"train_labels\"] = setup_data(inputs_train, labels_train, \"Training\")\n",
    "    data[\"test\"], data[\"test_labels\"] = setup_data(inputs_test, labels_test, \"Test\")\n",
    "    return data\n",
    "\n",
    "full_data = setup_data('notMNIST/full.pickle')\n",
    "print(full_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training/validation split from the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_validate(data, train_count, validate_count, seed=None):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def randomize(inputs, labels):\n",
    "        permutation = np.random.permutation(labels.shape[0])\n",
    "        shuffled_inputs = inputs[permutation,:,:,:]\n",
    "        shuffled_labels = labels[permutation,:]\n",
    "        return shuffled_inputs, shuffled_labels\n",
    "\n",
    "    train_inputs = data[\"train\"][:]\n",
    "    train_labels = data[\"train_labels\"][:]\n",
    "    cross_data = copy.copy(data)\n",
    "\n",
    "    train_inputs, train_labels = randomize(train_inputs, train_labels)\n",
    "    cross_data[\"train\"] = train_inputs[:train_count]\n",
    "    cross_data[\"train_labels\"] = train_labels[:train_count]\n",
    "\n",
    "    cross_data[\"valid\"] = train_inputs[train_count:train_count + validate_count]\n",
    "    cross_data[\"valid_labels\"] = train_labels[train_count:train_count + validate_count]\n",
    "    return cross_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_setup_validate():\n",
    "    cross_data = setup_validate(full_data, 1000, 100)\n",
    "    print(cross_data[\"train_labels\"].shape)\n",
    "    print(cross_data[\"train_labels\"][0])\n",
    "    print(full_data[\"train_labels\"][0])\n",
    "    print(cross_data[\"valid\"].shape)\n",
    "\n",
    "test_setup_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Construction From convevo Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def graph_input_shape(batch_size, data):\n",
    "    image_size = data[\"image_size\"]\n",
    "    channel_count = data[\"channel_count\"]\n",
    "    return (batch_size, image_size, image_size, channel_count)\n",
    "\n",
    "def graph_output_shape(batch_size, data):\n",
    "    return (batch_size, data[\"label_count\"])\n",
    "\n",
    "def setup_graph(batch_size, data, stack):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Input data.\n",
    "        input_shape = graph_input_shape(batch_size, data)\n",
    "        output_shape = graph_output_shape(batch_size, data)\n",
    "        train = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        labels= tf.placeholder(tf.float32, shape=output_shape)\n",
    "        verify= tf.placeholder(tf.float32, shape=input_shape)\n",
    "\n",
    "        operations = stack.construct(input_shape, output_shape)\n",
    "        l2_loss = convnet.setup(operations)\n",
    "        \n",
    "        logits        = convnet.connect_model(train,  operations, True)[-1]\n",
    "        verify_logits = convnet.connect_model(verify, operations, False)[-1]\n",
    "        loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits,labels))+l2_loss\n",
    "        \n",
    "        info = {\n",
    "            \"graph\": graph,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"train\": train,\n",
    "            \"labels\": labels,\n",
    "            \"loss\": loss,\n",
    "            \"optimizer\": stack.construct_optimizer(loss),\n",
    "\n",
    "            # Predictions for the training, validation, and test data.\n",
    "            \"predictions\": tf.nn.softmax(logits),\n",
    "            \"verify\": verify,\n",
    "            \"verify_predictions\": tf.nn.softmax(verify_logits),\n",
    "            \"saver\": tf.train.Saver()\n",
    "        }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    correct_predictions = np.argmax(predictions, 1) == np.argmax(labels, 1)\n",
    "    return (100.0 * np.sum(correct_predictions) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_accuracy(session, graph_info, inputs, labels, batch_size):\n",
    "    total_accuracy = 0\n",
    "    batch_count = len(inputs) / batch_size\n",
    "    for b in xrange(batch_count):\n",
    "        batch_data = inputs[b * batch_size: (b + 1) * batch_size]\n",
    "        feed_dict = { graph_info[\"verify\"] : batch_data }\n",
    "        predictions, = session.run([graph_info[\"verify_predictions\"]], feed_dict=feed_dict)\n",
    "        total_accuracy += accuracy(predictions, labels[b*batch_size : (b + 1)*batch_size])\n",
    "    return total_accuracy / float(batch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_graph(\n",
    "    graph_info,\n",
    "    data,\n",
    "    step_count,\n",
    "    report_every=50,\n",
    "    verbose=True,\n",
    "    eval_test=False,\n",
    "    accuracy_minimum=None,\n",
    "    progress=None,\n",
    "    tracker=None\n",
    "):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        \n",
    "        # Optionally restore graph parameters from disk.\n",
    "        convnet.restore_model(graph_info, session)\n",
    "        \n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        valid_accuracy = 0\n",
    "        last = step_count + 1 if step_count else 0\n",
    "        try:\n",
    "            for step in xrange(last):\n",
    "                # Update progress bar, if present\n",
    "                if progress:\n",
    "                    progress.value = step\n",
    "\n",
    "                # Pick an offset within the training data, which has been randomized.\n",
    "                # Note: we could use better randomization across epochs.\n",
    "                offset = (step * batch_size) % (data[\"train_labels\"].shape[0] - batch_size)\n",
    "                # Generate a minibatch.\n",
    "                batch_data = data[\"train\"][offset:(offset + batch_size), :, :, :]\n",
    "                batch_labels = data[\"train_labels\"][offset:(offset + batch_size), :]\n",
    "                \n",
    "                # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "                # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "                # and the value is the numpy array to feed to it.\n",
    "                targets = [\n",
    "                    graph_info[\"optimizer\"],\n",
    "                    graph_info[\"loss\"],\n",
    "                    graph_info[\"predictions\"]\n",
    "                ]\n",
    "                feed_dict = {\n",
    "                    graph_info[\"train\"] : batch_data,\n",
    "                    graph_info[\"labels\"] : batch_labels\n",
    "                }                \n",
    "                _, loss, predictions = session.run(targets, feed_dict=feed_dict)\n",
    "                \n",
    "                reporting = step % report_every == 0\n",
    "                if reporting or tracker:\n",
    "                    batch_score = (loss, accuracy(predictions, batch_labels))\n",
    "                    if tracker:\n",
    "                        tracker(batch_score)\n",
    "                    \n",
    "                if np.isnan(loss):\n",
    "                    print(\"Error computing loss\")\n",
    "                    return valid_accuracy\n",
    "                \n",
    "                if reporting:\n",
    "                    if verbose:\n",
    "                        print(\"Minibatch loss at step\", step, \":\", loss)\n",
    "                        print(\"Minibatch accuracy: %.1f%%\" % batch_score[1])\n",
    "                    valid_accuracy = batch_accuracy(\n",
    "                        session, graph_info, data[\"valid\"], data[\"valid_labels\"],batch_size\n",
    "                    )\n",
    "                    print(\"Validation accuracy: %.1f%%\" % valid_accuracy)\n",
    "                    if accuracy_minimum and step > 0 and valid_accuracy < accuracy_minimum:\n",
    "                        print(\"Early out.\")\n",
    "                        break\n",
    "            if eval_test:\n",
    "                test_accuracy = batch_accuracy(\n",
    "                    session, graph_info, data[\"test\"], data[\"test_labels\"], batch_size\n",
    "                )\n",
    "                print(\"Test accuracy: %.1f%%\" % test_accuracy)\n",
    "            return valid_accuracy\n",
    "        finally:\n",
    "            # Optionally save out graph parameters to disk.\n",
    "            convnet.save_model(graph_info, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up an evaluation function for use with Darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_path = outputer.setup_directory(\"temp\", \"notMNIST_results\")\n",
    "\n",
    "def save_results(timestamp, results):\n",
    "    with open(os.path.join(results_path, timestamp + \".csv\"), \"w\") as text_file:\n",
    "        text_file.write(\"Loss,Accuracy\\n\")\n",
    "        for score in results:\n",
    "            text_file.write((\",\".join(str(v) for v in score)) + \"\\n\")\n",
    "    print(\"Saved results:\", timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_eval(\n",
    "    batch_size=16,\n",
    "    eval_steps=100000,\n",
    "    valid_steps=5000,\n",
    "    eval_test=False\n",
    "):\n",
    "    # Set up to show a progress bar so you some mesure of time required.\n",
    "    # Updated in run_graph above.\n",
    "    progress_bar = ipywidgets.FloatProgress(min=0, max=eval_steps,\n",
    "                                            description=\"Graph Steps:\")\n",
    "    display(progress_bar)\n",
    "    \n",
    "    # Set up to show current training results as well as a running average.\n",
    "    # Updated in record_score below. \n",
    "    def setup_label(title):\n",
    "        return ipywidgets.FloatText(value=0, description=title, disabled=True)\n",
    "    current_display = [setup_label(title) for title in [\"Loss\", \"Accuracy\"]]\n",
    "    average_display = [setup_label(\" \") for _ in current_display]\n",
    "    current_title_html = \"<div style=\"\"margin-left:90px\"\">Current</div>\"\n",
    "    average_title_html = \"<div style=\"\"margin-left:90px\"\">Running Average</div>\"\n",
    "    display(ipywidgets.HBox([\n",
    "        ipywidgets.Box([ipywidgets.HTML(current_title_html)] + current_display),\n",
    "        ipywidgets.Box([ipywidgets.HTML(average_title_html)] + average_display)\n",
    "    ]))\n",
    "    \n",
    "    def evaluate(stack, entropy):   \n",
    "        data = setup_validate(full_data, eval_steps, valid_steps)\n",
    "\n",
    "        try:\n",
    "            evo_graph = setup_graph(batch_size, data, stack)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            lines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "            print(lines[-1])\n",
    "            convevo.output_error(stack, lines, \"temp\", outputer.timestamp(\"ERR~\", \"txt\"))\n",
    "            return -10\n",
    "\n",
    "        timestamp = outputer.timestamp()\n",
    "        stack.checkpoint_path(os.path.join(results_path, timestamp + \".ckpt\"))\n",
    "        with open(os.path.join(results_path, timestamp + \".xml\"), \"w\") as text_file:\n",
    "            text_file.write(convevo.serialize(stack))\n",
    "\n",
    "        # Record and display the results\n",
    "        results = []\n",
    "        def record_score(score):\n",
    "            results.append(score)\n",
    "            for display, value in zip(current_display, score):\n",
    "                display.value = value\n",
    "            \n",
    "            resultCount = min(len(results), 100)\n",
    "            averages = [sum(x)/resultCount for x in zip(*results[-resultCount:])]\n",
    "            for display, value in zip(average_display, averages):\n",
    "                display.value = value\n",
    "                \n",
    "        convnet.setup_save_model(evo_graph, stack.checkpoint_path())\n",
    "        \n",
    "        try:\n",
    "            return run_graph(\n",
    "                evo_graph,\n",
    "                data,\n",
    "                eval_steps,\n",
    "                report_every=eval_steps/4,\n",
    "                verbose=False,\n",
    "                eval_test=eval_test,\n",
    "                accuracy_minimum=50,\n",
    "                progress=progress_bar,\n",
    "                tracker=record_score\n",
    "            )\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            lines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "            print(lines[-1])\n",
    "            convevo.output_error(stack, lines, results_path, timestamp + \"~ERR.txt\")\n",
    "            return -1\n",
    "        finally:\n",
    "            save_results(timestamp, results)\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify stack construction for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_stack(\n",
    "    patch_size, stride, depth, hidden_size, label_count, init_scale, optimizer_name=None\n",
    "):\n",
    "    if optimizer_name:\n",
    "        optimizer = convevo.Optimizer(optimizer_name, 0.05)\n",
    "        optimizer.default_parameters()\n",
    "    else:\n",
    "        optimizer = None\n",
    "        \n",
    "    conv_layers = [\n",
    "        (\"conv_bias\", patch_size, stride, depth, \"SAME\", True),\n",
    "        (\"conv_bias\", patch_size, stride, depth, \"SAME\", True)\n",
    "    ]\n",
    "\n",
    "    return convevo.create_stack(\n",
    "        conv_layers, [], True, [hidden_size, label_count], 0.0, init_scale, 0.0, optimizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test all the pieces (not required to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test optimizers\n",
    "def test_optimizers():\n",
    "    for optimizer in [\"GradientDescent\",\"Adadelta\",\"Adagrad\",\"Momentum\",\"Adam\",\"RMSProp\"]:\n",
    "        # As of this writing \"Ftrl\" is not supported on the GPU\n",
    "        batch_size = 16\n",
    "        eval_steps = 10000\n",
    "        test_stack = create_stack(5, 2, 64, 128, 10, 0.1, optimizer)\n",
    "        test_data = setup_validate(full_data, eval_steps * batch_size, 500)\n",
    "        test_graph = setup_graph(batch_size, test_data, test_stack)\n",
    "        result = run_graph(test_graph, test_data,\n",
    "                           eval_steps, report_every=eval_steps/4, verbose=False)\n",
    "        print(result)\n",
    "test_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test make_eval\n",
    "with outputer.TeeOutput(os.path.join(results_path, outputer.timestamp(\"Eval\", \"txt\"))):\n",
    "    test_stack = create_stack(5, 2, 64, 128, 10, 0.1)\n",
    "    print(convevo.serialize(test_stack))\n",
    "    make_eval()(test_stack, random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test darwin setup\n",
    "mutate_entropy = random.Random(42)\n",
    "scored_mutants = []\n",
    "breed_options = {\n",
    "    \"input_shape\": graph_input_shape(16, full_data),\n",
    "    \"output_shape\": graph_output_shape(16, full_data)\n",
    "}\n",
    "mutator = darwin.Darwin(convevo.serialize, lambda s,e: 0, convevo.breed)\n",
    "prototypes = [create_stack(5, 2, 64, 64, 10, 0.1)]\n",
    "for mutant in mutator.init_population(prototypes, 20, False, breed_options,mutate_entropy):\n",
    "    scored_mutants.append((mutant, 0.0))\n",
    "    \n",
    "convevo.output_results(scored_mutants, \"temp\", \"mutants.xml\", 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test mutation\n",
    "mutate_entropy = random.Random(42)\n",
    "mutant_children = []\n",
    "for _ in range(20):\n",
    "    mutant_a = mutate_entropy.choice(scored_mutants)[0]\n",
    "    mutant_b = mutate_entropy.choice(scored_mutants)[0]\n",
    "    mutant_children.append(\n",
    "        (convevo.breed([mutant_a, mutant_b], breed_options, mutate_entropy), 0.0)\n",
    "    )\n",
    "    \n",
    "convevo.output_results(mutant_children, \"temp\", \"mutant_offspring.xml\", 42, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolve notMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prototypes to seed the population\n",
    "prototypes = [\n",
    "    create_stack(5, 2, 64, 128, 10, 0.10, \"GradientDescent\"),\n",
    "    create_stack(6, 2, 128, 64, 10, 0.05, \"Adadelta\"),\n",
    "    create_stack(4, 2, 64, 128, 10, 0.10, \"Adagrad\"),\n",
    "    create_stack(5, 1, 32,  64, 10, 0.02, \"Adam\"),\n",
    "    create_stack(2, 2, 64, 128, 10, 0.20, \"RMSProp\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prototypes.append(convevo.load_stack(\"testing/notMNIST_optimized.xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evolve!\n",
    "BATCH_SIZE = 128\n",
    "with outputer.TeeOutput(os.path.join(\"temp\", outputer.timestamp(\"notMNIST_evo_\", \"txt\"))):\n",
    "    # Setup seeds and entropy\n",
    "    mutate_seed = random.randint(1, 100000)\n",
    "    print(\"Mutate Seed:\", mutate_seed)\n",
    "    mutate_entropy = random.Random(mutate_seed)\n",
    "    eval_seed = random.randint(1, 100000)\n",
    "    print(\"Eval Seed:\", eval_seed)\n",
    "    eval_entropy = random.Random(eval_seed)\n",
    "\n",
    "    # Number of stacks to test each generation\n",
    "    population_size = 20\n",
    "    # Number of generations to evaluate\n",
    "    generations = 10\n",
    "    \n",
    "    breed_options = {\n",
    "        \"input_shape\": graph_input_shape(BATCH_SIZE, full_data),\n",
    "        \"output_shape\": graph_output_shape(BATCH_SIZE, full_data)\n",
    "    }\n",
    "\n",
    "    # Ensure the prototypes have the correct structure (eg, output layer size)\n",
    "    for stack in prototypes:\n",
    "        stack.make_safe(breed_options[\"input_shape\"], breed_options[\"output_shape\"])\n",
    "\n",
    "    # Construct an evolver\n",
    "    charles = darwin.Darwin(\n",
    "        convevo.serialize,\n",
    "        make_eval(batch_size=BATCH_SIZE, eval_steps=95000),\n",
    "        convevo.breed\n",
    "    )\n",
    "    # Initialize the population (True to include the protototypes as population members)\n",
    "    charles.init_population(prototypes,population_size,True,breed_options,mutate_entropy)\n",
    "\n",
    "    # Evaluate, output, select and breed/mutate\n",
    "    for g in range(generations):\n",
    "        print(\"Generation\", g)\n",
    "        results = charles.evaluate(eval_entropy)\n",
    "        convevo.output_results(results, \"temp\", outputer.timestamp() + \".xml\")\n",
    "        charles.repopulate(population_size, 0.25, 4, results, breed_options,mutate_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the best result\n",
    "best = charles.best()\n",
    "print(\"Best score:\", best[1])\n",
    "print(convevo.serialize(best[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store all the results in one place. (note that each generation gets stored above too)\n",
    "results = darwin.descending_score(charles.history.values())\n",
    "convevo.output_results(\n",
    "    results, \"testing\", \"notminist_full_evolve_run_optimized.xml\", mutate_seed, eval_seed\n",
    ")\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If something went wrong, this helps to summarize error reports\n",
    "errors = []\n",
    "\n",
    "for root, dirs, files in os.walk('temp'):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        low_name = name.lower()\n",
    "        if low_name.startswith(\"err\"):\n",
    "            with open (path, \"r\") as error_file:\n",
    "                lines=error_file.readlines()\n",
    "                errors.append((path, lines[-1]))\n",
    "\n",
    "for path, error in sorted(errors, key=lambda e: e[0]):\n",
    "    print(path)\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show and re-run a stack (for debugging)\n",
    "rerun = 0\n",
    "print (convevo.serialize(charles.population[rerun]))\n",
    "make_eval()(charles.population[rerun], eval_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population,_,_ = convevo.load_population(\n",
    "    \"testing/notMNIST_Evolve_2016-06-06~01_16_10_287.xml\", False\n",
    ")\n",
    "best = population[0]\n",
    "print(convevo.serialize(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_eval = make_eval(batch_size=16, eval_steps=200000, valid_steps=10000, eval_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with outputer.TeeOutput(os.path.join(\"temp\", outputer.timestamp(\"notMNIST_best_\", \"txt\"))):\n",
    "    full_eval(best, random.Random(43214))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "with outputer.TeeOutput(os.path.join(\"temp\", outputer.timestamp(\"notMNIST_opt_\", \"txt\"))):\n",
    "    for stack, score in results[:5]:\n",
    "        stack_graph = setup_graph(BATCH_SIZE, full_data, stack)\n",
    "        checkpoint_path = stack.checkpoint_path()\n",
    "        if checkpoint_path:\n",
    "            convnet.setup_restore_model(stack_graph, checkpoint_path)\n",
    "            run_graph(stack_graph, test_data, 0, verbose=True, eval_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
