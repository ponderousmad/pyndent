{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import errno\n",
    "import datetime\n",
    "import gc\n",
    "import gzip\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "import sklearn.metrics\n",
    "import skimage.color\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import improc\n",
    "import convnet\n",
    "import mutate\n",
    "import convevo\n",
    "import darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload (improc)\n",
    "reload (convnet)\n",
    "reload (mutate)\n",
    "reload (convevo)\n",
    "reload (darwin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/29772158/make-ipython-notebook-print-in-real-time\n",
    "oldsysstdout = sys.stdout\n",
    "class flushfile():\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __getattr__(self,name): \n",
    "        return object.__getattribute__(self.f, name)\n",
    "    def write(self, x):\n",
    "        self.f.write(x)\n",
    "        self.f.flush()\n",
    "    def flush(self):\n",
    "        self.f.flush()\n",
    "sys.stdout = flushfile(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate Images\n",
    "Image names are sequential, so add every tenth image to the validation set based on filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "test = []\n",
    "\n",
    "for root, dirs, files in os.walk('captures'):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        low_name = name.lower()\n",
    "        # Find all the image files, split into test and training.\n",
    "        if low_name.endswith(\".png\"):\n",
    "            if low_name.endswith(\"0.png\"):\n",
    "                test.append(path)\n",
    "            else:\n",
    "                training.append(path)\n",
    "\n",
    "print(\"Training:\", len(training), \"Test:\", len(test))\n",
    "print(training[:2])\n",
    "print(test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "Each image file contains a color image (top half), and an encoded depth image (bottom half)\n",
    "<img src=\"testing/IMG_2114.PNG\">\n",
    "* Note: The image may also contain the orientation data. If so it is encoded in the first two pixels of the depth image. If the first pixel of the depth image is red, the second has the x, y, z, w quaternion components encoded in the r,g,b,a values.\n",
    "\n",
    "The improc module contains functions for splitting the image, decoding the depth back into floating point millimeters, and for filling in gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLOR_CHANNELS = 3\n",
    "\n",
    "def load_image(image_path):\n",
    "    combined_image = ndimage.imread(image_path).astype(np.float32)\n",
    "    color_image, depth_image = improc.split(combined_image)\n",
    "    color_image = color_image[:, :, 0 : COLOR_CHANNELS] / improc.BYTE_MAX # Discard alpha and normalize\n",
    "    depths, attitude = improc.decode_depth(depth_image)\n",
    "    return (color_image, depths, attitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CIELAB image component scales:\n",
    "L_MAX = 100\n",
    "AB_SCALE_MAX = 127\n",
    "def rgb2lab_normalized(image):\n",
    "    lab_image = skimage.color.rgb2lab(image)\n",
    "    return (lab_image / [L_MAX / 2, AB_SCALE_MAX, AB_SCALE_MAX]) - [1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_image, example_depth, example_attitude = load_image(\"testing/IMG_2114.PNG\")\n",
    "plt.imshow(example_image)\n",
    "print(example_image.shape, example_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_depth)\n",
    "print(example_depth.shape, example_depth.dtype)\n",
    "print(example_attitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_lab = rgb2lab_normalized(example_image)\n",
    "plt.imshow(example_lab[:,:,0], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_lab[:,:,1], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Labels and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_average_depth():\n",
    "    depth_averages = []\n",
    "\n",
    "    for path in training:\n",
    "        _, depth, _ = load_image(path)\n",
    "        depth_averages.append(np.nanmean(depth))\n",
    "        if len(depth_averages) % 1000 == 0:\n",
    "            print(\"Image\", len(depth_averages))\n",
    "    return np.nanmean(depth_averages)\n",
    "\n",
    "# Precomputed via compute_average_depth()\n",
    "MEAN_DEPTH = np.float32(1688.97)\n",
    "\n",
    "print(MEAN_DEPTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want more precision for nearby things, so use progressively expanding buckets for labels, so if smallest bucket has size s and each succesive bucket is larger by a factor F then:\n",
    "\n",
    "improc.MAX_DEPTH == sF<sup>0</sup> + sF<sup>1</sup> + sF<sup>2</sup> + ... + sF<sup>label count - 1</sup>\n",
    "\n",
    "So, plug into sum of geometric series formula:\n",
    "\n",
    "improc.MAX_DEPTH == s * (1 - F<sup>label count</sup>) / (1 - F)\n",
    "\n",
    "Since there are two unknowns we can choose either the factor or the bucket size. A factor of 1.3 resulted in buckets that seemed about right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def size_for_factor(factor, buckets):\n",
    "    return improc.MAX_DEPTH * (1 - factor) / (1 - factor ** buckets)\n",
    "\n",
    "def depth_label_boundaries(factor, buckets):\n",
    "    boundaries = []\n",
    "    size_sum = 0\n",
    "    bucket_size = size_for_factor(factor, buckets)\n",
    "    for i in range(buckets):\n",
    "        size_sum += bucket_size\n",
    "        boundaries.append(size_sum)\n",
    "        bucket_size *= factor\n",
    "    return boundaries\n",
    "\n",
    "DEPTH_LABEL_COUNT = 20\n",
    "DEPTH_BUCKET_SCALE_FACTOR = 1.3\n",
    "DEPTH_BOUNDARIES = depth_label_boundaries(DEPTH_BUCKET_SCALE_FACTOR, DEPTH_LABEL_COUNT)\n",
    "print(DEPTH_BOUNDARIES[:5])\n",
    "\n",
    "def depth_label_index(depth):\n",
    "    for i, boundary in enumerate(DEPTH_BOUNDARIES):\n",
    "        if depth < boundary:\n",
    "            return i\n",
    "    return DEPTH_LABEL_COUNT - 1\n",
    "\n",
    "def depth_label(depth, labels=None):\n",
    "    if labels is None:\n",
    "        labels = np.zeros(shape=(DEPTH_LABEL_COUNT + 1), dtype=np.float32)\n",
    "    labels[depth_label_index(depth)] = 1\n",
    "    labels[DEPTH_LABEL_COUNT] = depth / improc.MAX_DEPTH\n",
    "    return labels\n",
    "\n",
    "def depth_label_image(depths):\n",
    "    labeled = depths.copy()\n",
    "    for y in xrange(depths.shape[0]):\n",
    "        for x in xrange(depths.shape[1]):\n",
    "            labeled[y,x] = depth_label_index(depths[y,x])\n",
    "    return labeled\n",
    "\n",
    "print(\"Mean depth label:\", depth_label(MEAN_DEPTH))\n",
    "print(\"Zero depth label:\", depth_label(0)[0], depth_label(0)[-1])\n",
    "print(\"Max depth label:\", depth_label(improc.MAX_DEPTH)[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth_image_cache_path = os.path.join(\"temp\", \"cache\")\n",
    "try:\n",
    "    os.makedirs(depth_image_cache_path)\n",
    "except OSError as e:\n",
    "    pass\n",
    "\n",
    "class ImageSampler(object):\n",
    "    \"\"\"Wrap an image for sampling.\"\"\"\n",
    "    def __init__(self, image_file, sample_height, sample_width, half_valid_check=2, tolerance=0):\n",
    "        cached = None\n",
    "        cache_path = os.path.join(depth_image_cache_path, os.path.split(image_file)[1]) + \".pickle\"\n",
    "        \n",
    "        try:\n",
    "            with gzip.open(cache_path, 'rb') as f:\n",
    "                cached = pickle.load(f)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.ENOENT:\n",
    "                print(\"OSError opening cached image:\", e.errno, e) \n",
    "        except IOError as e:\n",
    "            if e.errno != errno.ENOENT:\n",
    "                print(\"IOError opening cached image:\", e.errno, e) \n",
    "        except Exception as e:\n",
    "            print(\"Error opening cached image:\", e)\n",
    "            \n",
    "        if cached:\n",
    "            self.image = cached[\"image\"]\n",
    "            self.depth = cached[\"depth\"]\n",
    "        else:\n",
    "            self.image, self.depth, _ = load_image(image_file)\n",
    "            self.image = rgb2lab_normalized(self.image)\n",
    "        \n",
    "        if not cached:\n",
    "            try:\n",
    "                with gzip.open(cache_path, 'wb') as f:\n",
    "                    cache_data = { \"image\": self.image, \"depth\": self.depth}\n",
    "                    pickle.dump(cache_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "            except KeyboardInterrupt:\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                print(\"Error caching image:\", image_file, \"-\", e)\n",
    "        self.y = 0\n",
    "        self.x = 0\n",
    "        self.sample_height = sample_height\n",
    "        self.sample_width = sample_width\n",
    "        self.depth_offset_y = (sample_height + 1) / 2\n",
    "        self.depth_offset_x = (sample_width + 1) / 2\n",
    "        self.height = self.image.shape[0]        \n",
    "        self.width = self.image.shape[1]\n",
    "        self.half_valid_check = half_valid_check\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "    def depth_value(self, y_offset=0, x_offset=0):\n",
    "        return self.depth[self.y + self.depth_offset_y + y_offset, self.x + self.depth_offset_x + x_offset]\n",
    "        \n",
    "    def sample(self, inputs, labels, index):\n",
    "        patch = self.image[self.y : self.y + self.sample_height, self.x : self.x + self.sample_width, 0:1]\n",
    "        inputs[index] = patch\n",
    "        depth_label(self.depth_value(), labels[index])\n",
    "        self.advance()\n",
    "    \n",
    "    def advance(self):\n",
    "        self.x += 1\n",
    "        if self.x + self.sample_width >= self.width:\n",
    "            self.x = 0\n",
    "            self.y += 1\n",
    "            \n",
    "    def offset(self, offset):\n",
    "        self.x = offset % (self.width - self.sample_width - 1)\n",
    "        self.y = offset % (self.height - self.sample_height - 1)\n",
    "    \n",
    "    def next_sample(self):\n",
    "        c = self.half_valid_check\n",
    "        while self.y + self.sample_height < self.height:\n",
    "            depth_y = self.y + self.depth_offset_y\n",
    "            depth_x = self.x + self.depth_offset_x\n",
    "            # Check that the sample is from a clean part of the image.\n",
    "            sum = np.sum(np.isnan(self.depth[depth_y - c : depth_y + c, depth_x - c: depth_x + c]))\n",
    "            if sum <= self.tolerance:\n",
    "                return True\n",
    "            self.advance()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BatchSampler(object):\n",
    "    \"\"\"Created sample batches for a set of image files\"\"\"\n",
    "    def __init__(self, image_files, sample_height, sample_width, samplers_count=100):\n",
    "        self.files = image_files\n",
    "        self.samplers_count = samplers_count\n",
    "        self.sample_height = sample_height\n",
    "        self.sample_width = sample_width\n",
    "        self.reset()\n",
    "        \n",
    "    def sampler(self, index):\n",
    "        sampler = self.samplers[index]\n",
    "        if sampler and not sampler.next_sample():\n",
    "            sampler = None\n",
    "\n",
    "        while sampler is None:\n",
    "            path = self.files[self.file_index]\n",
    "            sampler = ImageSampler(path, self.sample_height, self.sample_width)\n",
    "            self.file_index = (self.file_index + 1) % len(self.files)\n",
    "            if not sampler.next_sample():\n",
    "                sampler = None\n",
    "                print (\"No samples in\", path)\n",
    "            else:\n",
    "                self.samplers[index] = sampler\n",
    "        return sampler\n",
    "        \n",
    "    def sample(self, inputs, labels, index):\n",
    "        sampler = self.sampler(self.sample_index)\n",
    "\n",
    "        self.sample_index = (self.sample_index + 1) % len(self.samplers)\n",
    "        sampler.sample(inputs, labels, index)\n",
    "        \n",
    "    def sample_batch(self, inputs, labels, batch_size):\n",
    "        labels.fill(0)\n",
    "        for b in xrange(batch_size):\n",
    "            self.sample(inputs, labels, b)\n",
    "            \n",
    "    def reset(self):\n",
    "        self.sample_index = 0\n",
    "        self.file_index = 0\n",
    "        self.samplers = [None] * self.samplers_count\n",
    "        \n",
    "    def fill_and_pickle(self, path, offset=True):\n",
    "        for i in range(self.samplers_count):\n",
    "            sampler = self.sampler(i)\n",
    "            sampler.offset(i)\n",
    "\n",
    "        try:\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(self, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to', path, ':', e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth label and batching examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(depth_label_image(example_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 101\n",
    "batcher = BatchSampler([\"testing/IMG_2114.PNG\", \"testing/IMG_3410.PNG\"], SAMPLE_SIZE, SAMPLE_SIZE, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "inputs = np.ones(shape=(BATCH_SIZE, SAMPLE_SIZE, SAMPLE_SIZE, COLOR_CHANNELS), dtype=np.float32)\n",
    "labels = np.zeros(shape=(BATCH_SIZE, DEPTH_LABEL_COUNT + 1), dtype=np.float32)\n",
    "\n",
    "for _ in xrange(100):\n",
    "    batcher.sample_batch(inputs, labels, BATCH_SIZE)\n",
    "    \n",
    "del example_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(inputs[1,:,:,0], cmap='Greys_r')\n",
    "print(inputs[1].shape)\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"image_size\": (101, 101, 1),\n",
    "    \"depth_labels\": DEPTH_LABEL_COUNT,\n",
    "    \"train_files\": np.array(training),\n",
    "    \"test_files\": np.array(test)\n",
    "}\n",
    "\n",
    "del training\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_cross_validation(data, train_count, valid_count, test_count=None, label_count=None, seed=None):\n",
    "    cross_data = data.copy()\n",
    "\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    if label_count:\n",
    "        cross_data[\"depth_labels\"] = label_count\n",
    "\n",
    "    paths = cross_data[\"train_files\"][:]\n",
    "    permutation = np.random.permutation(paths.shape[0])\n",
    "    paths = paths[permutation]\n",
    "\n",
    "    cross_data[\"train_files\"] = paths[:train_count]\n",
    "    cross_data[\"valid_files\"] = paths[train_count:train_count + valid_count]\n",
    "\n",
    "    if test_count is not None:\n",
    "        cross_data[\"test_files\"] = data[\"test_files\"][:test_count]\n",
    "\n",
    "    return cross_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_batch(data, set_name, samplers):\n",
    "    path = os.path.join(\"temp\", set_name + \".pickle\")\n",
    "    #files = data[set_name + \"_files\"]\n",
    "    #image_size = data[\"image_size\"]\n",
    "    #batcher = BatchSampler(files, image_size[0], image_size[1], samplers)\n",
    "    #batcher.fill_and_pickle(path)\n",
    "    #del batcher\n",
    "    #gc.collect()\n",
    "    return path\n",
    "\n",
    "def load_batcher(pickle_batches, set_name):\n",
    "    if pickle_batches:\n",
    "        path = pickle_batches.get(set_name)\n",
    "        if path:\n",
    "            with open(path, 'rb') as f:\n",
    "                print(\"Loading \" + path)\n",
    "                return pickle.load(f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_data = setup_cross_validation(\n",
    "    data_files, 0, 100, None,\n",
    "    label_count=DEPTH_LABEL_COUNT, seed=random.randint(0,24601)\n",
    ")\n",
    "pickle_size = pickle_data[\"image_size\"]\n",
    "pickle_files = pickle_data[\"valid_files\"]\n",
    "pickle_sampler = BatchSampler(pickle_files, pickle_size[0], pickle_size[1], len(pickle_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_sampler.fill_and_pickle(\"temp/depth_valid.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"temp/depth_valid.pickle\", 'rb') as f:\n",
    "    loaded_sampler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "inputs = np.ones(shape=(BATCH_SIZE, pickle_size[0], pickle_size[1], 1), dtype=np.float32)\n",
    "labels = np.zeros(shape=(BATCH_SIZE, DEPTH_LABEL_COUNT + 1), dtype=np.float32)\n",
    "\n",
    "for _ in xrange(500):\n",
    "    loaded_sampler.sample_batch(inputs, labels, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del pickle_data\n",
    "del pickle_files\n",
    "del pickle_sampler\n",
    "del loaded_sampler\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_input_shape(batch_size, image_shape):\n",
    "    return (batch_size,) + image_shape\n",
    "\n",
    "def setup_graph(\n",
    "    batch_size,\n",
    "    image_shape,\n",
    "    label_count,\n",
    "    regress_factor,\n",
    "    layer_stack\n",
    "):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        input_shape = batch_input_shape(batch_size, image_shape)\n",
    "        output_shape = (batch_size, label_count + 1)\n",
    "        train   = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        targets = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        verify  = tf.placeholder(tf.float32, shape=input_shape)\n",
    "\n",
    "        layers = layer_stack.construct(input_shape)\n",
    "        l2_loss = 0\n",
    "        \n",
    "        for layer in layers:\n",
    "            layer.setup_parameters()\n",
    "            l2_loss = layer.update_loss(l2_loss)\n",
    "        \n",
    "        def model(nodes, train):\n",
    "            for layer in layers:\n",
    "                nodes.append(layer.connect(nodes[-1], train))\n",
    "            return nodes[-1]\n",
    "\n",
    "        result = model([train], True)\n",
    "        \n",
    "        depth_label = tf.slice(targets, [0, label_count], [batch_size, 1])\n",
    "        depths      = tf.slice(result, [0, label_count], [batch_size, 1])\n",
    "        labels = tf.slice(targets, [0, 0], [batch_size, label_count])\n",
    "        logits = tf.slice(result, [0, 0], [batch_size, label_count])\n",
    "\n",
    "        global_step = tf.Variable(1)\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels)) + l2_loss\n",
    "        if regress_factor > 0:\n",
    "            loss += regress_factor * tf.reduce_mean(tf.squared_difference(depths, depth_label))\n",
    "        \n",
    "        optimizer = layer_stack.construct_optimizer(global_step)\n",
    "        \n",
    "        verify_result = model([verify], False)\n",
    "        verify_logits = tf.slice(verify_result, [0, 0], [batch_size, label_count])\n",
    "        verify_depths = tf.slice(verify_result, [0, label_count], [batch_size, 1])\n",
    "\n",
    "        verify_depths = tf.maximum(verify_depths, -1)\n",
    "        verify_depths = tf.minimum(verify_depths, 1)\n",
    "        \n",
    "        info = {\n",
    "            \"graph\": graph,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"train\": train,\n",
    "            \"targets\": targets,\n",
    "            \"depths\": depths,\n",
    "            \"loss\": loss,\n",
    "            \"optimizer\": optimizer.minimize(loss, global_step=global_step),\n",
    "\n",
    "            # Predictions for training and verification (validation or test)\n",
    "            \"predictions\": tf.nn.softmax(logits),\n",
    "            \"verify\": verify,\n",
    "            \"verify_predictions\": tf.nn.softmax(verify_logits),\n",
    "            \"verify_depths\": verify_depths\n",
    "        }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_accuracy(context, session, graph_info, batcher, inputs, labels, batch_size, batch_count, verbose):\n",
    "    total_accuracy = 0\n",
    "    for b in xrange(batch_count):\n",
    "        batcher.sample_batch(inputs, labels, batch_size)\n",
    "        targets = [graph_info[\"verify_predictions\"], graph_info[\"verify_depths\"]]\n",
    "        predictions, depths = session.run(targets, feed_dict={graph_info[\"verify\"] : inputs})\n",
    "        total_accuracy += accuracy(predictions, labels) / float(batch_count)\n",
    "    print_batch_info(context, (0, total_accuracy), predictions, depths, labels, verbose)\n",
    "    return total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_depth_error(depths, labels):\n",
    "    return np.mean(np.absolute(depths - labels[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_result(loss, predictions, depths, labels):\n",
    "    return (loss, accuracy(predictions, labels[:,0:-1]), mean_depth_error(depths, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_batch_info(context, score, predictions, depths, labels, verbose=True, print_count=20):\n",
    "    if score:\n",
    "        accuracy_score = score[1]\n",
    "    else:\n",
    "        accuracy_score = accuracy(predictions, labels[:,0:-1])\n",
    "    print(context, \"accuracy: %.1f%%\" % accuracy_score)\n",
    "    if verbose:\n",
    "        print(np.argmax(predictions[0:print_count],1))\n",
    "        print(np.argmax(labels[0:print_count,0:-1],1))\n",
    "        if score and len(score) > 2:\n",
    "            depth_error = score[2]\n",
    "        else:\n",
    "            depth_error = mean_depth_error(depths, labels)\n",
    "        print(context, \"average depth error:\", depth_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_graph(\n",
    "    graph_info,\n",
    "    data,\n",
    "    step_count,\n",
    "    valid_count,\n",
    "    test_count=0,\n",
    "    batch_sampler_count=1000,\n",
    "    report_every=50,\n",
    "    verbose=True,\n",
    "    accuracy_minimum=None,\n",
    "    pickle_batches=None,\n",
    "    progress=None,\n",
    "    tracker=None\n",
    "):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        depth_labels = data[\"depth_labels\"]\n",
    "        height, width, _ = data[\"image_size\"]\n",
    "\n",
    "        inputs = np.ones(shape=batch_input_shape(batch_size, data[\"image_size\"]), dtype=np.float32)\n",
    "        labels = np.zeros(shape=(batch_size, depth_labels + 1), dtype=np.float32)\n",
    "\n",
    "        train_batcher = load_batcher(pickle_batches, \"train\")\n",
    "        if not train_batcher:\n",
    "            train_batcher = BatchSampler(data[\"train_files\"], height, width, batch_sampler_count)\n",
    "\n",
    "        valid_files = data[\"valid_files\"]\n",
    "        score = 0\n",
    "\n",
    "        for step in xrange(step_count + 1):\n",
    "            if progress:\n",
    "                progress.value = step\n",
    "            # Generate a minibatch.\n",
    "            train_batcher.sample_batch(inputs, labels, batch_size)\n",
    "            # Run the minibatch through the optimizer\n",
    "            run_targets = [\n",
    "                graph_info[\"optimizer\"],\n",
    "                graph_info[\"loss\"],\n",
    "                graph_info[\"predictions\"],\n",
    "                graph_info[\"depths\"]\n",
    "            ]\n",
    "            feed_dict = {graph_info[\"train\"] : inputs, graph_info[\"targets\"] : labels}\n",
    "            _, loss, predictions, depths = session.run(run_targets, feed_dict=feed_dict)\n",
    "            batch_score = score_result(loss, predictions, depths, labels)\n",
    "            if tracker:\n",
    "                tracker(batch_score)\n",
    "            if np.isnan(loss):\n",
    "                print(\"Error computing loss at step\", step)\n",
    "                print_batch_info(\"Minibatch\", batch_score, predictions, depths, labels, True)\n",
    "                return 0\n",
    "            if (step % report_every == 0):\n",
    "                if verbose:\n",
    "                    print(\"Minibatch loss at step\", step, \":\", loss)\n",
    "                    print_batch_info(\"Minibatch\", batch_score, predictions, depths, labels, True)\n",
    "\n",
    "                valid_batcher = load_batcher(pickle_batches, \"valid\")\n",
    "                if not valid_batcher:\n",
    "                    valid_batcher = BatchSampler(valid_files, height, width, len(valid_files))\n",
    "                valid_accuracy = batch_accuracy(\n",
    "                    \"Validation\", session, graph_info, valid_batcher,\n",
    "                    inputs, labels, batch_size, valid_count, verbose\n",
    "                )\n",
    "                del valid_batcher\n",
    "                score = valid_accuracy\n",
    "                if accuracy_minimum and step > 0 and valid_accuracy < accuracy_minimum:\n",
    "                    print(\"Early out.\")\n",
    "                    break\n",
    "\n",
    "        if test_count > 0:\n",
    "            test_batcher = BatchSampler(data[\"test_files\"], height, width)\n",
    "            valid_accuracy = batch_accuracy(\n",
    "                \"Test\", session, graph_info, test_batcher,\n",
    "                inputs, labels, batch_size, test_count, verbose\n",
    "            )\n",
    "\n",
    "        return score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_path = os.path.join(\"temp\", \"results\")\n",
    "try:\n",
    "    os.makedirs(results_path)\n",
    "except OSError as e:\n",
    "    pass\n",
    "\n",
    "def save_results(stack, results):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d~%H_%M_%S_%f\")\n",
    "    with open(os.path.join(results_path, timestamp + \".xml\"), \"w\") as text_file:\n",
    "        text_file.write(convevo.serialize(stack))\n",
    "    with open(os.path.join(results_path, timestamp + \".csv\"), \"w\") as text_file:\n",
    "        text_file.write(\"Loss,Accuracy,Depth Error\\n\")\n",
    "        for score in results:\n",
    "            text_file.write((\",\".join(str(v) for v in score)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_eval(batch_size=20, eval_steps=10000, valid_steps=500, regress_factor=1.0, reuse_cross=False, metric=None):\n",
    "    pickle_batches = {}\n",
    "    train_count = 9700\n",
    "    valid_count = 400\n",
    "    batch_sampler_count = min(1000, eval_steps * batch_size)\n",
    "    test_count = None\n",
    "    if reuse_cross:\n",
    "        redata = setup_cross_validation(\n",
    "            data_files, train_count, valid_count, test_count,\n",
    "            label_count=DEPTH_LABEL_COUNT, seed=random.randint(0,24601)\n",
    "        )\n",
    "        pickle_batches[\"valid\"] = pickle_batch(redata, \"valid\", len(redata[\"valid_files\"]))\n",
    "        pickle_batches[\"train\"] = pickle_batch(redata, \"train\", batch_sampler_count)\n",
    "                            \n",
    "    progress_bar = ipywidgets.FloatProgress(min=0, max=eval_steps,description=\"Graph Steps:\")\n",
    "    display(progress_bar)\n",
    "\n",
    "    def evaluate(stack, entropy):\n",
    "        stack.reseed(entropy)\n",
    "\n",
    "        if not reuse_cross:\n",
    "            data = setup_cross_validation(\n",
    "                data_files, train_count, valid_count, test_count,\n",
    "                label_count=DEPTH_LABEL_COUNT, seed=entropy.randint(0,24601)\n",
    "            )\n",
    "        else:\n",
    "            data = redata\n",
    "\n",
    "        try:\n",
    "            evo_graph = setup_graph(batch_size, data[\"image_size\"], data[\"depth_labels\"], regress_factor, stack)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            lines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "            print(lines[-1])\n",
    "            convevo.output_error(stack, lines, \"temp\")\n",
    "            return -10\n",
    "\n",
    "        results = []\n",
    "        try:\n",
    "            valid_accuracy = run_graph(\n",
    "                evo_graph,\n",
    "                data,\n",
    "                eval_steps,\n",
    "                valid_count=valid_steps,\n",
    "                batch_sampler_count=batch_sampler_count,\n",
    "                report_every=eval_steps/4,\n",
    "                verbose=True,\n",
    "                accuracy_minimum=10.0,\n",
    "                pickle_batches=pickle_batches,\n",
    "                progress=progress_bar,\n",
    "                tracker = lambda score: results.append(score)\n",
    "            )\n",
    "            if metric:\n",
    "                return metric(valid_accuracy, results)\n",
    "            return valid_accuracy\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            lines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "            print(lines[-1])\n",
    "            convevo.output_error(stack, lines, \"temp\")\n",
    "            return -1\n",
    "        finally:\n",
    "            save_results(stack, results)\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_metric(valid_accuracy, train_results):\n",
    "    result_count = min(len(train_results), 100)\n",
    "    return sum(accuracy for loss, accuracy, depth_error in train_results[-result_count:]) / result_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_stack(convolutions, flatten, hidden_sizes, output_size, init_mean, init_scale, l2, optimizer=None):\n",
    "    stack = convevo.LayerStack(flatten=flatten, optimizer=optimizer)\n",
    "    default_init = lambda: convevo.Initializer(\"normal\", mean=init_mean, scale=init_scale)\n",
    "\n",
    "    for operation, patch_size, stride, depth, padding, relu in convolutions:\n",
    "        layer = convevo.ImageLayer(operation, patch_size, stride, depth, \"SAME\", default_init(), l2_factor=l2)\n",
    "        stack.add_layer(layer, relu=relu)\n",
    "    for hidden_size in hidden_sizes:\n",
    "        layer = convevo.HiddenLayer(hidden_size, bias=True, initializer=default_init(), l2_factor=l2)\n",
    "        stack.add_layer(layer, relu=True)\n",
    "    if output_size is not None:\n",
    "        layer = convevo.HiddenLayer(output_size, bias=True, initializer=default_init(), l2_factor=l2)\n",
    "        stack.add_layer(layer, relu=False)\n",
    "    \n",
    "    return stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of components in isoloation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_data = setup_cross_validation(data_files, 9700, 400, 1000, label_count=DEPTH_LABEL_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "conv_layers = [\n",
    "    (\"conv_bias\", 20, 2, 10, \"SAME\", True),\n",
    "    (\"conv_bias\", 10, 5, 20, \"SAME\", True),\n",
    "    (\"conv_bias\",  5, 2, 40, \"SAME\", True)\n",
    "]\n",
    "hidden_sizes = [400,100]\n",
    "optimizer = convevo.Optimizer(\"GradientDescent\", 0.01)\n",
    "optimizer.default_parameters()\n",
    "prototype = create_stack(conv_layers, True, hidden_sizes, cross_data[\"depth_labels\"] + 1, 0.0, 0.05, 0.0, optimizer)\n",
    "prototype.reseed(random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prototype_graph = setup_graph(batch_size, cross_data[\"image_size\"], cross_data[\"depth_labels\"], 1.0, prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    prototype_graph, cross_data, 10000,\n",
    "    valid_count=2000, report_every=1000, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(convevo.serialize(prototype))\n",
    "prototype_eval = make_eval(batch_size=100, eval_steps=100, valid_steps=20, regress_factor=1.0, reuse_cross=True)\n",
    "prototype_eval(prototype, random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del cross_data\n",
    "del conv_layers\n",
    "del hidden_sizes\n",
    "del prototype_graph\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving Convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prototypes = [prototype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prototypes,_,_ = convevo.load_population(\"testing/best_minibatch.xml\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mutate_seed = random.randint(1, 100000)\n",
    "print(\"Mutate Seed:\", mutate_seed)\n",
    "mutate_entropy = random.Random(mutate_seed)\n",
    "eval_seed = random.randint(1, 100000)\n",
    "print(\"Eval Seed:\", eval_seed)\n",
    "eval_entropy = random.Random(eval_seed)\n",
    "\n",
    "population_size = 20\n",
    "generations = 10\n",
    "batch_size = 100\n",
    "\n",
    "breed_options = {\n",
    "    \"input_shape\": batch_input_shape(batch_size, data_files[\"image_size\"])\n",
    "}\n",
    "\n",
    "evaluator = make_eval(batch_size=batch_size, eval_steps=10000, valid_steps=500, reuse_cross=True, metric=train_metric)\n",
    "charles = darwin.Darwin(convevo.serialize, evaluator, convevo.breed)\n",
    "charles.init_population(prototypes, population_size, False, breed_options, mutate_entropy)\n",
    "\n",
    "for g in range(generations):\n",
    "    print(\"Generation\", g)\n",
    "    results = charles.evaluate(eval_entropy)\n",
    "    convevo.output_results(results, \"temp\")\n",
    "    charles.repopulate(population_size, 0.25, 4, results, breed_options, mutate_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history,_,_ = convevo.load_population(\"testing/depth_restart4.xml\", True)\n",
    "print(len(history))\n",
    "results,_,_ = convevo.load_population(\"temp/2016-05-21~12_09_54_779.xml\", True)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mutate_seed = random.randint(1, 100000)\n",
    "print(\"Mutate Seed:\", mutate_seed)\n",
    "mutate_entropy = random.Random(mutate_seed)\n",
    "eval_seed = random.randint(1, 100000)\n",
    "print(\"Eval Seed:\", eval_seed)\n",
    "eval_entropy = random.Random(eval_seed)\n",
    "\n",
    "population_size = 20\n",
    "generations = 10\n",
    "batch_size = 100\n",
    "\n",
    "breed_options = {\n",
    "    \"input_shape\": batch_input_shape(batch_size, data_files[\"image_size\"])\n",
    "}\n",
    "\n",
    "evaluator = make_eval(batch_size=batch_size, eval_steps=2000000, valid_steps=5000, reuse_cross=True)\n",
    "charles = darwin.Darwin(convevo.serialize, evaluator, convevo.breed)\n",
    "charles.load_history(history)\n",
    "\n",
    "for g in range(generations):\n",
    "    print(\"Generation\", g)\n",
    "    restart_darwin.repopulate(population_size, 0.25, 4, results, breed_options, mutate_entropy)\n",
    "    results = restart_darwin.evaluate(eval_entropy)\n",
    "    convevo.output_results(results, \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = darwin.descending_score(charles.history.values())\n",
    "convevo.output_results(results, \"testing\", \"depth_minibatch.xml\", mutate_seed, eval_seed)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
