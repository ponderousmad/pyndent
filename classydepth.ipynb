{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import errno\n",
    "import datetime\n",
    "import gc\n",
    "import gzip\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import improc\n",
    "import convnet\n",
    "import mutate\n",
    "import convevo\n",
    "import darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload (improc)\n",
    "reload (convnet)\n",
    "reload (mutate)\n",
    "reload (convevo)\n",
    "reload (darwin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/29772158/make-ipython-notebook-print-in-real-time\n",
    "oldsysstdout = sys.stdout\n",
    "class flushfile():\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __getattr__(self,name): \n",
    "        return object.__getattribute__(self.f, name)\n",
    "    def write(self, x):\n",
    "        self.f.write(x)\n",
    "        self.f.flush()\n",
    "    def flush(self):\n",
    "        self.f.flush()\n",
    "sys.stdout = flushfile(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate Images\n",
    "Image names are sequential, so add every tenth image to the validation set based on filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "test = []\n",
    "\n",
    "for root, dirs, files in os.walk('captures'):\n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        low_name = name.lower()\n",
    "        # Find all the image files, split into test and training.\n",
    "        if low_name.endswith(\".png\"):\n",
    "            if low_name.endswith(\"0.png\"):\n",
    "                test.append(path)\n",
    "            else:\n",
    "                training.append(path)\n",
    "\n",
    "print(\"Training:\", len(training), \"Test:\", len(test))\n",
    "print(training[:2])\n",
    "print(test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "Each image file contains a color image (top half), and an encoded depth image (bottom half)\n",
    "<img src=\"testing/IMG_2114.PNG\">\n",
    "* Note: The image may also contain the orientation data. If so it is encoded in the first two pixels of the depth image. If the first pixel of the depth image is red, the second has the x, y, z, w quaternion components encoded in the r,g,b,a values.\n",
    "\n",
    "The improc module contains functions for splitting the image, decoding the depth back into floating point millimeters, and for filling in gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_image, example_depth, example_attitude = improc.load_image(\"testing/IMG_2114.PNG\")\n",
    "plt.imshow(example_image)\n",
    "print(example_image.shape, example_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_depth)\n",
    "print(example_depth.shape, example_depth.dtype)\n",
    "print(example_attitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_lab = improc.rgb2lab_normalized(example_image)\n",
    "plt.imshow(example_lab[:,:,0], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_lab[:,:,1], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Labels and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_average_depth():\n",
    "    depth_averages = []\n",
    "\n",
    "    for path in training:\n",
    "        _, depth, _ = improc.load_image(path)\n",
    "        depth_averages.append(np.nanmean(depth))\n",
    "        if len(depth_averages) % 1000 == 0:\n",
    "            print(\"Image\", len(depth_averages))\n",
    "    return np.nanmean(depth_averages)\n",
    "\n",
    "# Precomputed via compute_average_depth()\n",
    "MEAN_DEPTH = np.float32(1688.97)\n",
    "\n",
    "print(MEAN_DEPTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covert depth to classification labels.\n",
    "Want more precision for nearby things, so use progressively expanding buckets for labels, so if smallest bucket has size s and each succesive bucket is larger by a factor F then:\n",
    "\n",
    "improc.MAX_DEPTH == sF<sup>0</sup> + sF<sup>1</sup> + sF<sup>2</sup> + ... + sF<sup>label count - 1</sup>\n",
    "\n",
    "So, plug into sum of geometric series formula:\n",
    "\n",
    "improc.MAX_DEPTH == s * (1 - F<sup>label count</sup>) / (1 - F)\n",
    "\n",
    "Since there are two unknowns we can choose either the factor or the bucket size. A factor of 1.3 resulted in buckets that seemed about right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def size_for_factor(factor, buckets):\n",
    "    return improc.MAX_DEPTH * (1 - factor) / (1 - factor ** buckets)\n",
    "\n",
    "def depth_label_boundaries(factor, buckets):\n",
    "    boundaries = []\n",
    "    size_sum = 0\n",
    "    bucket_size = size_for_factor(factor, buckets)\n",
    "    for i in range(buckets):\n",
    "        size_sum += bucket_size\n",
    "        boundaries.append(size_sum)\n",
    "        bucket_size *= factor\n",
    "    return boundaries\n",
    "\n",
    "DEPTH_LABEL_COUNT = 20\n",
    "DEPTH_BUCKET_SCALE_FACTOR = 1.3\n",
    "DEPTH_BOUNDARIES = [(i + 1) * improc.MAX_DEPTH / DEPTH_LABEL_COUNT for i in xrange(DEPTH_LABEL_COUNT)]\n",
    "print(DEPTH_BOUNDARIES[:5])\n",
    "\n",
    "def depth_label_index(depth):\n",
    "    for i, boundary in enumerate(DEPTH_BOUNDARIES):\n",
    "        if depth < boundary:\n",
    "            return i\n",
    "    return DEPTH_LABEL_COUNT - 1\n",
    "\n",
    "def depth_label(depth, labels=None):\n",
    "    if labels is None:\n",
    "        labels = np.zeros(shape=(DEPTH_LABEL_COUNT + 1), dtype=np.float32)\n",
    "    labels[depth_label_index(depth)] = 1\n",
    "    labels[DEPTH_LABEL_COUNT] = depth / improc.MAX_DEPTH\n",
    "    return labels\n",
    "\n",
    "def depth_label_image(depths):\n",
    "    labeled = depths.copy()\n",
    "    for y in xrange(depths.shape[0]):\n",
    "        for x in xrange(depths.shape[1]):\n",
    "            labeled[y,x] = depth_label_index(depths[y,x])\n",
    "    return labeled\n",
    "\n",
    "print(\"Mean depth label:\", depth_label(MEAN_DEPTH))\n",
    "print(\"Zero depth label:\", depth_label(0)[0], depth_label(0)[-1])\n",
    "print(\"Max depth label:\", depth_label(improc.MAX_DEPTH)[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fisher_yates_shuffle(items, entropy):\n",
    "    \"\"\"Based on https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle\"\"\"\n",
    "    i = len(items)\n",
    "    while i > 1:\n",
    "        i = i - 1\n",
    "        j = entropy.randint(0, i)\n",
    "        items[j], items[i] = items[i], items[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up cache directory.\n",
    "depth_image_cache_path = os.path.join(\"temp\", \"cache\")\n",
    "try:\n",
    "    os.makedirs(depth_image_cache_path)\n",
    "except OSError as e:\n",
    "    pass\n",
    "\n",
    "class ImageSampler(object):\n",
    "    \"\"\"Wrap an image for sampling.\"\"\"\n",
    "    def __init__(self, image_file, sample_height, sample_width, half_valid_check=2, tolerance=0):\n",
    "        # See if the image has already been processed and cached\n",
    "        cached = None\n",
    "        cache_path = os.path.join(depth_image_cache_path, os.path.split(image_file)[1]) + \".pickle\"\n",
    "\n",
    "        try:\n",
    "            with gzip.open(cache_path, 'rb') as f:\n",
    "                cached = pickle.load(f)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.ENOENT:\n",
    "                print(\"OSError opening cached image:\", e.errno, e) \n",
    "        except IOError as e:\n",
    "            if e.errno != errno.ENOENT:\n",
    "                print(\"IOError opening cached image:\", e.errno, e) \n",
    "        except Exception as e:\n",
    "            print(\"Error opening cached image:\", e)\n",
    "            \n",
    "        if cached:\n",
    "            self.image = cached[\"image\"]\n",
    "            self.depth = cached[\"depth\"]\n",
    "        else:\n",
    "            # Load and process the image.\n",
    "            self.image, self.depth, _ = improc.load_image(image_file)\n",
    "            # Convert from rgb to CIE LAB format.\n",
    "            self.image = improc.rgb2lab_normalized(self.image)\n",
    "        \n",
    "        if not cached:\n",
    "            try:\n",
    "                with gzip.open(cache_path, 'wb') as f:\n",
    "                    cache_data = { \"image\": self.image, \"depth\": self.depth}\n",
    "                    pickle.dump(cache_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "            except KeyboardInterrupt:\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                print(\"Error caching image:\", image_file, \"-\", e)\n",
    "        self.index = 0\n",
    "        self.pixel_index = (0, 0)\n",
    "        self.sample_height = sample_height\n",
    "        self.sample_width = sample_width\n",
    "        self.depth_offset_y = (sample_height + 1) / 2\n",
    "        self.depth_offset_x = (sample_width + 1) / 2\n",
    "        self.height = self.image.shape[0]        \n",
    "        self.width = self.image.shape[1]\n",
    "        self.half_valid_check = half_valid_check\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "    def depth_value(self, y, x):\n",
    "        return self.depth[y + self.depth_offset_y, x + self.depth_offset_x]\n",
    "        \n",
    "    def sample(self, inputs, labels, index):\n",
    "        y, x = self.pixel_index\n",
    "        patch = self.image[y : y + self.sample_height, x : x + self.sample_width]\n",
    "        inputs[index] = patch\n",
    "        depth_label(self.depth_value(y, x), labels[index])\n",
    "        self.advance()\n",
    "\n",
    "    def setup_sample_order(self, sample_orders, entropy):\n",
    "        height_span = self.height - self.sample_height\n",
    "        width_span = self.width - self.sample_width\n",
    "        cached = sample_orders.get((height_span, width_span))\n",
    "        if cached:\n",
    "            return cached\n",
    "\n",
    "        pixel_indices = []\n",
    "        for y in range(height_span):\n",
    "            for x in range(width_span):\n",
    "                pixel_indices.append((y, x))\n",
    "                \n",
    "        fisher_yates_shuffle(pixel_indices, entropy)\n",
    "        sample_orders[(height_span, width_span)] = pixel_indices\n",
    "        return pixel_indices\n",
    "        \n",
    "    def advance(self):\n",
    "        self.index += 1\n",
    "    \n",
    "    def next_sample(self, sample_orders, entropy):\n",
    "        c = self.half_valid_check\n",
    "        order = self.setup_sample_order(sample_orders, entropy)\n",
    "        while self.index < len(order):\n",
    "            self.pixel_index = order[self.index]\n",
    "            depth_y = self.pixel_index[0] + self.depth_offset_y\n",
    "            depth_x = self.pixel_index[1] + self.depth_offset_x\n",
    "            # Check that the sample is from a clean part of the image.\n",
    "            sum = np.sum(np.isnan(self.depth[depth_y - c : depth_y + c, depth_x - c: depth_x + c]))\n",
    "            if sum <= self.tolerance:\n",
    "                return True\n",
    "            self.advance()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BatchSampler(object):\n",
    "    \"\"\"Created sample batches for a set of image files\"\"\"\n",
    "    def __init__(self, image_files, sample_height, sample_width, samplers_count=100):\n",
    "        self.files = image_files\n",
    "        self.samplers_count = samplers_count\n",
    "        self.sample_height = sample_height\n",
    "        self.sample_width = sample_width\n",
    "        self.sample_orders = {}\n",
    "        self.reset()\n",
    "    \n",
    "    # Access or initialize the specified sampler.\n",
    "    def sampler(self, index, entropy):\n",
    "        sampler = self.samplers[index]\n",
    "        if sampler and not sampler.next_sample(self.sample_orders, entropy):\n",
    "            sampler = None\n",
    "\n",
    "        while sampler is None:\n",
    "            path = self.files[self.file_index]\n",
    "            sampler = ImageSampler(path, self.sample_height, self.sample_width)\n",
    "            self.file_index = (self.file_index + 1) % len(self.files)\n",
    "            if not sampler.next_sample(self.sample_orders, entropy):\n",
    "                sampler = None\n",
    "                print (\"No samples in\", path)\n",
    "            else:\n",
    "                self.samplers[index] = sampler\n",
    "        return sampler\n",
    "    \n",
    "    # Get the next single sample.\n",
    "    def sample(self, inputs, labels, index, entropy):\n",
    "        sampler = self.sampler(self.sample_index, entropy)\n",
    "\n",
    "        self.sample_index = (self.sample_index + 1) % len(self.samplers)\n",
    "        sampler.sample(inputs, labels, index)\n",
    "    \n",
    "    # Get the next batch of samples.\n",
    "    def sample_batch(self, inputs, labels, batch_size, entropy):\n",
    "        labels.fill(0)\n",
    "        for b in xrange(batch_size):\n",
    "            self.sample(inputs, labels, b, entropy)\n",
    "            \n",
    "    def reset(self):\n",
    "        self.sample_index = 0\n",
    "        self.file_index = 0\n",
    "        self.samplers = [None] * self.samplers_count\n",
    "    \n",
    "    # Force load all the samplers.\n",
    "    def fill_and_pickle(self, path, entropy):\n",
    "        for i in range(self.samplers_count):\n",
    "            sampler = self.sampler(i, entropy)\n",
    "\n",
    "        try:\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(self, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to', path, ':', e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth label and batching examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(depth_label_image(example_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del example_image\n",
    "del example_depth\n",
    "del example_lab\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 101\n",
    "batcher = BatchSampler([\"testing/IMG_2114.PNG\", \"testing/IMG_3410.PNG\"], SAMPLE_SIZE, SAMPLE_SIZE, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "inputs = np.ones(shape=(BATCH_SIZE, SAMPLE_SIZE, SAMPLE_SIZE, improc.COLOR_CHANNELS), dtype=np.float32)\n",
    "labels = np.zeros(shape=(BATCH_SIZE, DEPTH_LABEL_COUNT + 1), dtype=np.float32)\n",
    "\n",
    "for _ in xrange(100):\n",
    "    batcher.sample_batch(inputs, labels, BATCH_SIZE, random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(inputs[1,:,:,0], cmap='Greys_r')\n",
    "print(inputs[1].shape)\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"image_size\": (101, 101, improc.COLOR_CHANNELS),\n",
    "    \"depth_labels\": DEPTH_LABEL_COUNT,\n",
    "    \"train_files\": np.array(training),\n",
    "    \"test_files\": np.array(test)\n",
    "}\n",
    "\n",
    "del training\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_cross_validation(data, train_count, valid_count, test_count=None, label_count=None, entropy=random):\n",
    "    \"\"\"Shuffle the data and split off training, validation and test sets.\"\"\"\n",
    "    cross_data = data.copy()\n",
    "    \n",
    "    if label_count:\n",
    "        cross_data[\"depth_labels\"] = label_count\n",
    "\n",
    "    paths = cross_data[\"train_files\"][:]\n",
    "    fisher_yates_shuffle(paths, entropy)\n",
    "\n",
    "    cross_data[\"train_files\"] = paths[:train_count]\n",
    "    cross_data[\"valid_files\"] = paths[train_count:train_count + valid_count]\n",
    "\n",
    "    if test_count is not None:\n",
    "        cross_data[\"test_files\"] = data[\"test_files\"][:test_count]\n",
    "\n",
    "    return cross_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batcher Caching\n",
    "The evolutionary process will involve running many graphs with the same data. To make this as efficent as possible, these are used cache and restore the processed batch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_batch(data, set_name, samplers, entropy):\n",
    "    path = os.path.join(\"temp\", set_name + \".pickle\")\n",
    "    files = data[set_name + \"_files\"]\n",
    "    image_size = data[\"image_size\"]\n",
    "    batcher = BatchSampler(files, image_size[0], image_size[1], samplers)\n",
    "    batcher.fill_and_pickle(path, entropy)\n",
    "    del batcher\n",
    "    gc.collect()\n",
    "    return path\n",
    "\n",
    "def load_batcher(pickle_batches, set_name):\n",
    "    if pickle_batches:\n",
    "        path = pickle_batches.get(set_name)\n",
    "        if path:\n",
    "            with open(path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_data = setup_cross_validation(\n",
    "    data_files, 0, 100, None,\n",
    "    label_count=DEPTH_LABEL_COUNT, entropy=random.Random(24601)\n",
    ")\n",
    "pickle_size = pickle_data[\"image_size\"]\n",
    "pickle_files = pickle_data[\"valid_files\"]\n",
    "pickle_sampler = BatchSampler(pickle_files, pickle_size[0], pickle_size[1], len(pickle_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_sampler.fill_and_pickle(\"temp/depth_valid.pickle\", random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"temp/depth_valid.pickle\", 'rb') as f:\n",
    "    loaded_sampler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "inputs = np.ones(shape=(BATCH_SIZE, pickle_size[0], pickle_size[1], improc.COLOR_CHANNELS), dtype=np.float32)\n",
    "labels = np.zeros(shape=(BATCH_SIZE, DEPTH_LABEL_COUNT + 1), dtype=np.float32)\n",
    "\n",
    "for _ in xrange(500):\n",
    "    loaded_sampler.sample_batch(inputs, labels, BATCH_SIZE, random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del pickle_data\n",
    "del pickle_files\n",
    "del pickle_sampler\n",
    "del loaded_sampler\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_input_shape(batch_size, image_shape):\n",
    "    return (batch_size,) + image_shape\n",
    "\n",
    "def setup_graph(\n",
    "    batch_size,\n",
    "    image_shape,\n",
    "    label_count,\n",
    "    regress_factor,\n",
    "    layer_stack\n",
    "):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        input_shape = batch_input_shape(batch_size, image_shape)\n",
    "        output_shape = (batch_size, label_count + 1)\n",
    "        train   = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        targets = tf.placeholder(tf.float32, shape=output_shape)\n",
    "        verify  = tf.placeholder(tf.float32, shape=input_shape)\n",
    "\n",
    "        layers = layer_stack.construct(input_shape)\n",
    "        l2_loss = 0\n",
    "        \n",
    "        for layer in layers:\n",
    "            layer.setup_parameters()\n",
    "            l2_loss = layer.update_loss(l2_loss)\n",
    "        \n",
    "        def model(nodes, train):\n",
    "            for layer in layers:\n",
    "                nodes.append(layer.connect(nodes[-1], train))\n",
    "            return nodes[-1]\n",
    "\n",
    "        result = model([train], True)\n",
    "        \n",
    "        depth_label = tf.slice(targets, [0, label_count], [batch_size, 1])\n",
    "        depths      = tf.slice(result, [0, label_count], [batch_size, 1])\n",
    "        labels = tf.slice(targets, [0, 0], [batch_size, label_count])\n",
    "        logits = tf.slice(result, [0, 0], [batch_size, label_count])\n",
    "\n",
    "        global_step = tf.Variable(1)\n",
    "        \n",
    "        loss = l2_loss\n",
    "        if regress_factor >= 0:\n",
    "            loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))\n",
    "        else:\n",
    "            regress_factor = -regress_factor\n",
    "\n",
    "        if regress_factor > 0:\n",
    "            loss += regress_factor * tf.reduce_mean(tf.squared_difference(depths, depth_label))\n",
    "        \n",
    "        optimizer = layer_stack.construct_optimizer(global_step)\n",
    "        \n",
    "        verify_result = model([verify], False)\n",
    "        verify_logits = tf.slice(verify_result, [0, 0], [batch_size, label_count])\n",
    "        verify_depths = tf.slice(verify_result, [0, label_count], [batch_size, 1])\n",
    "\n",
    "        verify_depths = tf.maximum(verify_depths, -1)\n",
    "        verify_depths = tf.minimum(verify_depths, 1)\n",
    "        \n",
    "        info = {\n",
    "            \"graph\": graph,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"train\": train,\n",
    "            \"targets\": targets,\n",
    "            \"depths\": depths,\n",
    "            \"loss\": loss,\n",
    "            \"optimizer\": optimizer.minimize(loss, global_step=global_step),\n",
    "\n",
    "            # Predictions for training and verification (validation or test)\n",
    "            \"predictions\": tf.nn.softmax(logits),\n",
    "            \"verify\": verify,\n",
    "            \"verify_predictions\": tf.nn.softmax(verify_logits),\n",
    "            \"verify_depths\": verify_depths,\n",
    "            \"saver\": tf.train.Saver()\n",
    "        }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_save_model(graph_info, path):\n",
    "    \"\"\"Set up option to tell run_graph to save the graph after training.\"\"\"\n",
    "    graph_info[\"save_to\"] = path\n",
    "    \n",
    "def setup_restore_model(graph_info, path):\n",
    "    \"\"\"Set up option to tell run_graph to restore graph values.\"\"\"\n",
    "    graph_info[\"restore_from\"] = path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_depth_error(depths, labels):\n",
    "    return np.mean(np.absolute(depths - labels[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_result(loss, predictions, depths, labels):\n",
    "    return (loss, accuracy(predictions, labels[:,0:-1]), mean_depth_error(depths, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_batch_info(context, score, predictions, depths, labels, verbose=True, print_count=20, depth_print=10):\n",
    "    print(context, \"accuracy: %.1f%%\" % score[1])\n",
    "    if verbose:\n",
    "        print(np.argmax(predictions[0:print_count],1))\n",
    "        print(np.argmax(labels[0:print_count,0:-1],1))\n",
    "        print(context, \"average depth error:\", score[2])\n",
    "        print(depths[0:depth_print,0])\n",
    "        print(labels[0:depth_print,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_accuracy(context, session, graph_info, batcher, entropy, inputs, labels, batch_size, count, verbose):\n",
    "    total_accuracy = 0\n",
    "    total_depth = 0\n",
    "    for b in xrange(count):\n",
    "        batcher.sample_batch(inputs, labels, batch_size, entropy)\n",
    "        targets = [graph_info[\"verify_predictions\"], graph_info[\"verify_depths\"]]\n",
    "        predictions, depths = session.run(targets, feed_dict={graph_info[\"verify\"] : inputs})\n",
    "        total_accuracy += accuracy(predictions, labels) / float(count)\n",
    "        total_depth += mean_depth_error(depths, labels) / float(count)\n",
    "    \n",
    "    score = (0, total_accuracy, total_depth)\n",
    "    print_batch_info(context, score, predictions, depths, labels, verbose)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_graph(\n",
    "    graph_info,\n",
    "    data,\n",
    "    step_count,\n",
    "    valid_count,\n",
    "    test_count=0,\n",
    "    batch_sampler_count=1000,\n",
    "    report_every=50,\n",
    "    verbose=True,\n",
    "    accuracy_minimum=None, # Minimimum validation percent accuracy for early abort\n",
    "    pickle_batches=None, # pickle files for training and validation batchers\n",
    "    progress=None, # A progress bar widget\n",
    "    tracker=None, # A function for result tracking\n",
    "    entropy=random\n",
    "):\n",
    "    with tf.Session(graph=graph_info[\"graph\"]) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "\n",
    "        # Optionally restore graph parameters from disk.\n",
    "        restore_from = graph_info.get(\"restore_from\")\n",
    "        if restore_from:\n",
    "            graph_info[\"saver\"].restore(session, restore_from)\n",
    "            print(\"Restored model from\", restore_from)\n",
    "            \n",
    "        print(\"Initialized\")\n",
    "\n",
    "        # Set up space for graph inputs / feed values\n",
    "        batch_size = graph_info[\"batch_size\"]\n",
    "        depth_labels = data[\"depth_labels\"]\n",
    "        height, width, _ = data[\"image_size\"]\n",
    "        inputs = np.ones(shape=batch_input_shape(batch_size, data[\"image_size\"]), dtype=np.float32)\n",
    "        labels = np.zeros(shape=(batch_size, depth_labels + 1), dtype=np.float32)\n",
    "\n",
    "        # Construct or unpickle training batcher.\n",
    "        train_batcher = load_batcher(pickle_batches, \"train\")\n",
    "        if not train_batcher:\n",
    "            train_batcher = BatchSampler(data[\"train_files\"], height, width, batch_sampler_count)\n",
    "\n",
    "        score = 0\n",
    "\n",
    "        try:\n",
    "            for step in xrange(step_count + 1):\n",
    "                # Update progress bar, if present\n",
    "                if progress:\n",
    "                    progress.value = step\n",
    "\n",
    "                # Generate a batch and run the graph\n",
    "                train_batcher.sample_batch(inputs, labels, batch_size, entropy)\n",
    "                run_targets = [\n",
    "                    graph_info[\"optimizer\"],\n",
    "                    graph_info[\"loss\"],\n",
    "                    graph_info[\"predictions\"],\n",
    "                    graph_info[\"depths\"]\n",
    "                ]\n",
    "                feed_dict = {graph_info[\"train\"] : inputs, graph_info[\"targets\"] : labels}\n",
    "                _, loss, predictions, depths = session.run(run_targets, feed_dict=feed_dict)\n",
    "                \n",
    "                # Keep track of and possibly display score.\n",
    "                batch_score = score_result(loss, predictions, depths, labels)\n",
    "                if tracker:\n",
    "                    tracker(batch_score)\n",
    "\n",
    "                if np.isnan(loss):\n",
    "                    print(\"Error computing loss at step\", step)\n",
    "                    print_batch_info(\"Minibatch\", batch_score, predictions, depths, labels, True)\n",
    "                    return 0\n",
    "                if (step % report_every == 0):\n",
    "                    if verbose:\n",
    "                        print(\"Minibatch loss at step\", step, \":\", loss)\n",
    "                        print_batch_info(\"Minibatch\", batch_score, predictions, depths, labels, True)\n",
    "\n",
    "                    # Evaluate the validation data.\n",
    "                    valid_batcher = load_batcher(pickle_batches, \"valid\")\n",
    "                    if not valid_batcher:\n",
    "                        valid_files = data[\"valid_files\"]\n",
    "                        valid_batcher = BatchSampler(valid_files, height, width, len(valid_files))\n",
    "                    valid_score = batch_accuracy(\n",
    "                        \"Validation\", session, graph_info, valid_batcher, entropy,\n",
    "                        inputs, labels, batch_size, valid_count, verbose\n",
    "                    )\n",
    "                    del valid_batcher\n",
    "                    score = valid_score[1]\n",
    "                    if accuracy_minimum and step > 0 and valid_score[1] < accuracy_minimum:\n",
    "                        print(\"Early out.\")\n",
    "                        break\n",
    "\n",
    "            # Evaluate the test data, if any.\n",
    "            if test_count > 0:\n",
    "                test_batcher = BatchSampler(data[\"test_files\"], height, width)\n",
    "                valid_accuracy = batch_accuracy(\n",
    "                    \"Test\", session, graph_info, test_batcher, entropy,\n",
    "                    inputs, labels, batch_size, test_count, verbose\n",
    "                )\n",
    "\n",
    "            return score\n",
    "        finally:\n",
    "            # Optionally save out graph parameters to disk.\n",
    "            save_to = graph_info.get(\"save_to\")\n",
    "            if save_to:\n",
    "                graph_info[\"saver\"].save(session, save_to)\n",
    "                print(\"Saved model to\", save_to)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_path = os.path.join(\"temp\", \"results\")\n",
    "try:\n",
    "    os.makedirs(results_path)\n",
    "except OSError as e:\n",
    "    pass\n",
    "\n",
    "def save_results(timestamp, results):\n",
    "    with open(os.path.join(results_path, timestamp + \".csv\"), \"w\") as text_file:\n",
    "        text_file.write(\"Loss,Accuracy,Depth Error\\n\")\n",
    "        for score in results:\n",
    "            text_file.write((\",\".join(str(v) for v in score)) + \"\\n\")\n",
    "    print(\"Saved results:\", timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_eval(\n",
    "    batch_size=20,\n",
    "    eval_steps=10000,\n",
    "    valid_steps=500,\n",
    "    regress_factor=1.0,\n",
    "    reuse_cross=False,\n",
    "    metric=None,\n",
    "    entropy=random\n",
    "):\n",
    "    pickle_batches = {}\n",
    "    train_count = 9700\n",
    "    valid_count = 400\n",
    "    batch_sampler_count = min(1000, eval_steps * batch_size)\n",
    "    test_count = None\n",
    "    \n",
    "    #if reusing data, set up training and test data, and pickle batchers for efficiency.\n",
    "    if reuse_cross:\n",
    "        redata = setup_cross_validation(\n",
    "            data_files, train_count, valid_count, test_count,\n",
    "            label_count=DEPTH_LABEL_COUNT, entropy=entropy\n",
    "        )\n",
    "        pickle_batches[\"valid\"] = pickle_batch(redata, \"valid\", len(redata[\"valid_files\"]), entropy)\n",
    "        print(\"Pickled Validation\")\n",
    "        pickle_batches[\"train\"] = pickle_batch(redata, \"train\", batch_sampler_count, entropy)\n",
    "        print(\"Pickled Training\")\n",
    "\n",
    "    # Set up to show a progress bar so you some mesure of time required. Updated in run_graph above.\n",
    "    progress_bar = ipywidgets.FloatProgress(min=0, max=eval_steps, description=\"Graph Steps:\")\n",
    "    display(progress_bar)\n",
    "    \n",
    "    # Set up to show current training results as well as a running average. updated in record_score below. \n",
    "    def setup_label(title):\n",
    "        return ipywidgets.FloatText(value=0, description=title, disabled=True)\n",
    "    current_display = [setup_label(title) for title in [\"Loss\", \"Accuracy\", \"Error\"]]\n",
    "    average_display = [setup_label(\" \") for _ in current_display]\n",
    "    display(ipywidgets.HBox([\n",
    "        ipywidgets.Box([ipywidgets.HTML(\"<div style=\"\"margin-left:90px\"\">Current</div>\")] + current_display),\n",
    "        ipywidgets.Box([ipywidgets.HTML(\"<div style=\"\"margin-left:90px\"\">Running Average</div>\")] + average_display)\n",
    "    ]))\n",
    "  \n",
    "    def evaluate(stack, entropy):\n",
    "        # If not reusing data, generate training and validation sets\n",
    "        if not reuse_cross:\n",
    "            data = setup_cross_validation(\n",
    "                data_files, train_count, valid_count, test_count,\n",
    "                label_count=DEPTH_LABEL_COUNT, entropy=entropy\n",
    "            )\n",
    "        else:\n",
    "            data = redata\n",
    "\n",
    "        # Set up the Tensorflow graph\n",
    "        try:\n",
    "            evo_graph = setup_graph(batch_size, data[\"image_size\"], data[\"depth_labels\"], regress_factor, stack)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            # Record any errors and the stack that caused them.\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            lines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "            print(lines[-1])\n",
    "            convevo.output_error(stack, lines, \"temp\")\n",
    "            return -10\n",
    "\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d~%H_%M_%S_%f\")\n",
    "        with open(os.path.join(results_path, timestamp + \".xml\"), \"w\") as text_file:\n",
    "            text_file.write(convevo.serialize(stack))\n",
    "        \n",
    "        setup_save_model(evo_graph, os.path.join(results_path, timestamp + \".ckpt\"))\n",
    "        \n",
    "        # Record and display the results\n",
    "        results = []\n",
    "        def record_score(score):\n",
    "            results.append(score)\n",
    "            for display, value in zip(current_display, score):\n",
    "                display.value = value\n",
    "            \n",
    "            resultCount = min(len(results), 100)\n",
    "            averages = [sum(x)/resultCount for x in zip(*results[-resultCount:])]\n",
    "            for display, value in zip(average_display, averages):\n",
    "                display.value = value\n",
    "\n",
    "        # Run the graph\n",
    "        try:\n",
    "            valid_accuracy = run_graph(\n",
    "                evo_graph,\n",
    "                data,\n",
    "                eval_steps,\n",
    "                valid_count=valid_steps,\n",
    "                batch_sampler_count=batch_sampler_count,\n",
    "                report_every=eval_steps/4,\n",
    "                verbose=True,\n",
    "                accuracy_minimum=None,\n",
    "                pickle_batches=pickle_batches,\n",
    "                progress=progress_bar,\n",
    "                tracker=record_score,\n",
    "                entropy=entropy\n",
    "            )\n",
    "            if metric:\n",
    "                return metric(valid_accuracy, results)\n",
    "            return valid_accuracy\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            # Record any errors and the stack that caused them.\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            lines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "            print(lines[-1])\n",
    "            convevo.output_error(stack, lines, \"temp\")\n",
    "            return -1\n",
    "        finally:\n",
    "            save_results(timestamp, results)\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_accuracy_metric(valid_accuracy, train_results):\n",
    "    result_count = min(len(train_results), 1000)\n",
    "    return sum(accuracy for loss, accuracy, depth_error in train_results[-result_count:]) / result_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_depth_error_metric(valid_accuracy, train_results):\n",
    "    result_count = min(len(train_results), 1000)\n",
    "    error = sum(depth_error for loss, accuracy, depth_error in train_results[-result_count:]) / result_count\n",
    "    return max(0, 1 - error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_stack(convolutions, flatten, hidden_sizes, output_size, init_mean, init_scale, l2, optimizer=None):\n",
    "    stack = convevo.LayerStack(flatten=flatten, optimizer=optimizer)\n",
    "    default_init = lambda: convevo.Initializer(\"normal\", mean=init_mean, scale=init_scale)\n",
    "\n",
    "    for operation, patch_size, stride, depth, padding, relu in convolutions:\n",
    "        layer = convevo.ImageLayer(operation, patch_size, stride, depth, \"SAME\", default_init(), l2_factor=l2)\n",
    "        stack.add_layer(layer, relu=relu)\n",
    "    for hidden_size in hidden_sizes:\n",
    "        layer = convevo.HiddenLayer(hidden_size, bias=True, initializer=default_init(), l2_factor=l2)\n",
    "        stack.add_layer(layer, relu=True)\n",
    "    if output_size is not None:\n",
    "        layer = convevo.HiddenLayer(output_size, bias=True, initializer=default_init(), l2_factor=l2)\n",
    "        stack.add_layer(layer, relu=False)\n",
    "    \n",
    "    return stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of components in isoloation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_data = setup_cross_validation(data_files, 9700, 400, 1000, label_count=DEPTH_LABEL_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "conv_layers = [\n",
    "    (\"conv_bias\", 20, 2, 10, \"SAME\", True),\n",
    "    (\"conv_bias\", 10, 5, 20, \"SAME\", True),\n",
    "    (\"conv_bias\",  5, 2, 40, \"SAME\", True)\n",
    "]\n",
    "hidden_sizes = [400,100]\n",
    "optimizer = convevo.Optimizer(\"GradientDescent\", 0.01)\n",
    "optimizer.default_parameters()\n",
    "prototype = create_stack(conv_layers, True, hidden_sizes, cross_data[\"depth_labels\"] + 1, 0.0, 0.05, 0.0, optimizer)\n",
    "prototype.reseed(random.Random(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prototype_graph = setup_graph(batch_size, cross_data[\"image_size\"], cross_data[\"depth_labels\"], 1.0, prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    prototype_graph, cross_data, 10000,\n",
    "    valid_count=2000, report_every=1000, verbose=True, entropy=random.Random(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(convevo.serialize(prototype))\n",
    "prototype_entropy = random.Random(42)\n",
    "prototype_eval = make_eval(\n",
    "    batch_size=100, eval_steps=100, valid_steps=20, regress_factor=1.0, reuse_cross=True, entropy=prototype_entropy\n",
    ")\n",
    "prototype_eval(prototype, prototype_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del cross_data\n",
    "del conv_layers\n",
    "del hidden_sizes\n",
    "del prototype_graph\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving Convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prototypes = [prototype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population,_,_ = convevo.load_population(\"testing/color_quad_run.xml\", False)\n",
    "prototypes = population[:5]\n",
    "print(len(prototypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mutate_seed = random.randint(1, 100000)\n",
    "print(\"Mutate Seed:\", mutate_seed)\n",
    "mutate_entropy = random.Random(mutate_seed)\n",
    "eval_seed = random.randint(1, 100000)\n",
    "print(\"Eval Seed:\", eval_seed)\n",
    "eval_entropy = random.Random(eval_seed)\n",
    "\n",
    "population_size = 5\n",
    "generations = 1\n",
    "batch_size = 100\n",
    "\n",
    "breed_options = {\n",
    "    \"input_shape\": batch_input_shape(batch_size, data_files[\"image_size\"])\n",
    "}\n",
    "\n",
    "evaluator = make_eval(\n",
    "    batch_size=batch_size, eval_steps=40000, valid_steps=1000, regress_factor=1000.0,\n",
    "    reuse_cross=True, metric=train_accuracy_metric, entropy=eval_entropy\n",
    ")\n",
    "charles = darwin.Darwin(convevo.serialize, evaluator, convevo.breed)\n",
    "charles.init_population(prototypes, population_size, True, breed_options, mutate_entropy)\n",
    "\n",
    "for g in range(generations):\n",
    "    print(\"Generation\", g)\n",
    "    results = charles.evaluate(eval_entropy)\n",
    "    convevo.output_results(results, \"temp\")\n",
    "    charles.repopulate(population_size, 0.7, 3, results, breed_options, mutate_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history,_,_ = convevo.load_population(\"testing/depth_restart4.xml\", True)\n",
    "print(len(history))\n",
    "results,_,_ = convevo.load_population(\"temp/2016-05-21~12_09_54_779.xml\", True)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mutate_seed = random.randint(1, 100000)\n",
    "print(\"Mutate Seed:\", mutate_seed)\n",
    "mutate_entropy = random.Random(mutate_seed)\n",
    "eval_seed = random.randint(1, 100000)\n",
    "print(\"Eval Seed:\", eval_seed)\n",
    "eval_entropy = random.Random(eval_seed)\n",
    "\n",
    "population_size = 20\n",
    "generations = 10\n",
    "batch_size = 100\n",
    "\n",
    "breed_options = {\n",
    "    \"input_shape\": batch_input_shape(batch_size, data_files[\"image_size\"])\n",
    "}\n",
    "\n",
    "evaluator = make_eval(\n",
    "    batch_size=batch_size, eval_steps=2000000, valid_steps=5000,\n",
    "    reuse_cross=True, metric=train_accuracy_metric, entropy=eval_entropy\n",
    ")\n",
    "charles = darwin.Darwin(convevo.serialize, evaluator, convevo.breed)\n",
    "charles.load_history(history)\n",
    "\n",
    "for g in range(generations):\n",
    "    print(\"Generation\", g)\n",
    "    restart_darwin.repopulate(population_size, 0.25, 4, results, breed_options, mutate_entropy)\n",
    "    results = restart_darwin.evaluate(eval_entropy)\n",
    "    convevo.output_results(results, \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = darwin.descending_score(charles.history.values())\n",
    "convevo.output_results(results, \"testing\", \"linear_buckets_run.xml\", mutate_seed, eval_seed)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
